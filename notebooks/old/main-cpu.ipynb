{"cells":[{"cell_type":"markdown","metadata":{"id":"A1bIc0ZAumSJ"},"source":["# Google Drive"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31598,"status":"ok","timestamp":1668683011020,"user":{"displayName":"Matheus Vanzan","userId":"02191216176553053689"},"user_tz":180},"id":"eckl1rAzruSX","outputId":"b58d312a-163d-43dc-c72c-ee36387fd562"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["####################################\n","#\n","#  ADD THIS TO EVERY COLAB FILE!\n","#\n","####################################\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import drive.Shareddrives.GPTJ.project.settings as settings\n","\n","PATH_PROJECT = settings.PATH_PROJECT\n","PATH_DATA = settings.PATH_DATA"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49830,"status":"ok","timestamp":1668683060816,"user":{"displayName":"Matheus Vanzan","userId":"02191216176553053689"},"user_tz":180},"id":"L5zLhAxca2u4","outputId":"3ee9c4b7-02fa-46cb-8662-5cbd522c6bd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 143 kB 4.8 MB/s \n","\u001b[K     |████████████████████████████████| 55.9 MB 234 kB/s \n","\u001b[K     |████████████████████████████████| 85 kB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 42.8 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 60.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 59.8 MB/s \n","\u001b[K     |████████████████████████████████| 451 kB 3.2 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 62.8 MB/s \n","\u001b[K     |████████████████████████████████| 115 kB 63.2 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 62.0 MB/s \n","\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! cd $PATH_PROJECT && pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"JuIxLRfousPd"},"source":["# Processamento dos arquivos\n","\n","Filtro de opcodes -> mantemos apenas as palavras que são opcodes ou adjacentes a um opcode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30324,"status":"ok","timestamp":1667101831118,"user":{"displayName":"Matheus Vanzan","userId":"15834607519873191987"},"user_tz":180},"id":"PU15VTwqFzwN","outputId":"e129dcac-fdb4-4388-e1d7-f027fa53ccb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch=None, cache=False, check=False, complete=False, epochs=None, label=None, limit=None, metrics=False, model=None, multi=False, path=None, process=True, test=False, train=False)\n","pid: 399\n","Traceback (most recent call last):\n","  File \"main.py\", line 240, in <module>\n","    main(args)\n","  File \"main.py\", line 40, in main\n","    proc.sanity_check()\n","  File \"/content/drive/Shareddrives/GPTJ/project/processor.py\", line 161, in sanity_check\n","    with open(new_path, 'r') as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1/01kcPWA9K2BOxQeS5Rju.asm'\n"]}],"source":["! cd $PATH_PROJECT && python main.py --process"]},{"cell_type":"markdown","metadata":{"id":"ZZdJjTltuR4z"},"source":["# Cache local do Dataset\n","\n","Como o dataset tem um tamanho grande e está no Google Drive distribuído em vários arquivos, queremos carregar todos em um único arquivo já tokenizado pelo *tokenizer* da GPT.\n","\n","Para evitar problemas de sincronização, vamos copiar os arquivos para /content/tmp/, depois copiar de volta os arquivos resultantes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5sYLF6MicevF","outputId":"90dfd056-b0f8-4c4b-c5fb-5fa63d358d2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["model 0\n","\n","real\t1m7.935s\n","user\t0m0.029s\n","sys\t0m2.559s\n","model 1\n","\n","real\t1m49.951s\n","user\t0m0.047s\n","sys\t0m2.417s\n","model 2\n","\n","real\t1m27.989s\n","user\t0m0.057s\n","sys\t0m1.067s\n","model 3\n","\n","real\t0m9.085s\n","user\t0m0.013s\n","sys\t0m0.185s\n","model 4\n","\n","real\t0m32.889s\n","user\t0m0.007s\n","sys\t0m0.017s\n","model 5\n","\n","real\t0m16.938s\n","user\t0m0.008s\n","sys\t0m0.347s\n","model 6\n","\n","real\t0m9.975s\n","user\t0m0.008s\n","sys\t0m0.185s\n","model 7\n","\n","real\t0m43.156s\n","user\t0m0.027s\n","sys\t0m0.627s\n","model 8\n","\n","real\t0m43.172s\n","user\t0m0.018s\n","sys\t0m0.733s\n"]}],"source":["! mkdir -p \"/content/tmp/\"\n","! for i in {0..8}; do echo \"model $i\" && time cp -r /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/$i /content/tmp/; done"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1668130903372,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"QOECcvyLJbg6","outputId":"2e984b7c-bc90-4a72-d1d5-7ec90d4e98f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["model 0\n","1.3G\t/content/tmp/0\n","1541\n","model 1\n","989M\t/content/tmp/1\n","2478\n","model 2\n","76M\t/content/tmp/2\n","2942\n","model 3\n","16M\t/content/tmp/3\n","475\n","model 4\n","1.8M\t/content/tmp/4\n","42\n","model 5\n","67M\t/content/tmp/5\n","751\n","model 6\n","28M\t/content/tmp/6\n","398\n","model 7\n","141M\t/content/tmp/7\n","1228\n","model 8\n","137M\t/content/tmp/8\n","1013\n"]}],"source":["\n","# ! ls \"$PATH_DATA/kaggle/proc-1/$LABEL/\" | wc -l\n","# ! ls \"/content/tmp/$LABEL/\" | wc -l\n","\n","! for i in {0..8}; do echo \"model $i\" && du -sh \"/content/tmp/$i\" && ls \"/content/tmp/$i\" | wc -l; done"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRqayGhgy5eg","outputId":"3278d0f3-ef1c-4024-f74f-8efa70e7675e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch=None, cache=True, check=False, complete=False, epochs=None, fold='1', label=None, limit='10240', metrics=False, model='gpt2', multi=False, path='/content/tmp/', process=False, test=False, train=False)\n","pid: 10827\n","Args: limit 10240\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/tmp/\n","Args: model_name gpt2\n","Args: multi False\n","Args: fold 1\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","-----\n","label 0\n","-----\n","label 1\n","-----\n","label 2\n","-----\n","label 3\n","-----\n","label 4\n","-----\n","label 5\n","-----\n","label 6\n","-----\n","label 7\n","-----\n","label 8\n","Dataset: label 0 - train - in model as torch.tensor(0)\n","Dataset: label 0 - train - creating from /content/tmp/0 ...\n","Dataset: label 0 - train - 1233 files\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3013 > 1024). Running this sequence through the model will result in indexing errors\n","Dataset: label 0 - train - 0%\n","Dataset: label 0 - train - 9%\n","Dataset: label 0 - train - 19%\n","Dataset: label 0 - train - 29%\n","Traceback (most recent call last):\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 165, in _create_csv\n","    input_id_chunks, mask_chunks = self._tokenize_chunks(content, filename)\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 98, in _tokenize_chunks\n","    tokens = self.tokenizer(content)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 2488, in __call__\n","    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 2612, in _call_one\n","    **kwargs,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 2685, in encode_plus\n","    **kwargs,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 649, in _encode_plus\n","    first_ids = get_input_ids(text)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 616, in get_input_ids\n","    tokens = self.tokenize(text, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 547, in tokenize\n","    tokenized_text.extend(self._tokenize(token))\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/tokenization_gpt2.py\", line 301, in _tokenize\n","    self.byte_encoder[b] for b in token.encode(\"utf-8\")\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/tokenization_gpt2.py\", line 301, in <genexpr>\n","    self.byte_encoder[b] for b in token.encode(\"utf-8\")\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"main.py\", line 265, in <module>\n","    main(args)\n","  File \"main.py\", line 107, in main\n","    train_dataset = helper.get_train()\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 295, in get_train\n","    return self._get_dataset('train')\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 284, in _get_dataset\n","    use_cache = self.use_cache\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 90, in __init__\n","    self._create_csv() # if not in file already\n","  File \"/content/drive/Shareddrives/GPTJ/project/dataset.py\", line 165, in _create_csv\n","    input_id_chunks, mask_chunks = self._tokenize_chunks(content, filename)\n","KeyboardInterrupt\n"]}],"source":["! cd $PATH_PROJECT && python main.py --cache --model='gpt2' --limit='10240' --fold='1' --path='/content/tmp/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54375,"status":"ok","timestamp":1667364080281,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"2B4hadbyJeiO","outputId":"666ab76c-b3c1-4373-ccc7-a67f493d5398"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","real\t0m54.296s\n","user\t0m0.120s\n","sys\t0m8.505s\n"]}],"source":["# copy files back\n","! time cp /content/tmp/*.csv \"/content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/\""]},{"cell_type":"markdown","metadata":{"id":"KLYL5KtG59QR"},"source":["# Cache"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"a7MNeFoci9Bw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89f11bf9-7c0a-4389-f55f-a10596b04cd9","executionInfo":{"status":"ok","timestamp":1668696540221,"user_tz":180,"elapsed":13071417,"user":{"displayName":"Matheus Vanzan","userId":"02191216176553053689"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch=None, cache=True, check=False, complete=False, epochs=None, fold='9', label=None, limit='102400', metrics=False, model='gpt2', multi=False, path=None, process=False, test=False, train=False)\n","pid: 387\n","Args: limit 102400\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi False\n","Args: fold 9\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: downloading tokenizer...\n","Downloading: 100% 1.04M/1.04M [00:00<00:00, 9.79MB/s]\n","Downloading: 100% 456k/456k [00:00<00:00, 4.80MB/s]\n","Downloading: 100% 665/665 [00:00<00:00, 542kB/s]\n","Model: saving tokenizer...\n","Model: tokenizer saved!\n","-----\n","label 0\n","-----\n","label 1\n","-----\n","label 2\n","-----\n","label 3\n","-----\n","label 4\n","-----\n","label 5\n","-----\n","label 6\n","-----\n","label 7\n","-----\n","label 8\n","Dataset: label 0 - train - in model as torch.tensor(0)\n","Dataset: label 0 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - train - 1233 files\n","Token indices sequence length is longer than the specified maximum sequence length for this model (42524 > 1024). Running this sequence through the model will result in indexing errors\n","Dataset: label 0 - train - 0%\n","Dataset: label 0 - train - 9%\n","Dataset: label 0 - train - 19%\n","Dataset: label 0 - train - 29%\n","Dataset: label 0 - train - 39%\n","Dataset: label 0 - train - 49%\n","Dataset: label 0 - train - 59%\n","Dataset: label 0 - train - 69%\n","Dataset: label 0 - train - 79%\n","Dataset: label 0 - train - 89%\n","Dataset: label 0 - train - 99%\n","Dataset: label 0 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 0 - train - 3047342 chunks - 25.55 Gb\n","Dataset: label 1 - train - in model as torch.tensor(1)\n","Dataset: label 1 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - train - 1984 files\n","Dataset: label 1 - train - 0%\n","Dataset: label 1 - train - 9%\n","Dataset: label 1 - train - 19%\n","Dataset: label 1 - train - 29%\n","Dataset: label 1 - train - 39%\n","Dataset: label 1 - train - 49%\n","Dataset: label 1 - train - 59%\n","Dataset: label 1 - train - 69%\n","Dataset: label 1 - train - 79%\n","Dataset: label 1 - train - 89%\n","Dataset: label 1 - train - 99%\n","Dataset: label 1 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 1 - train - 3345054 chunks - 25.55 Gb\n","Dataset: label 2 - train - in model as torch.tensor(1)\n","Dataset: label 2 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - train - 2354 files\n","Dataset: label 2 - train - 0%\n","Dataset: label 2 - train - 9%\n","Dataset: label 2 - train - 19%\n","Dataset: label 2 - train - 29%\n","Dataset: label 2 - train - 39%\n","Dataset: label 2 - train - 49%\n","Dataset: label 2 - train - 59%\n","Dataset: label 2 - train - 69%\n","Dataset: label 2 - train - 79%\n","Dataset: label 2 - train - 89%\n","Dataset: label 2 - train - 99%\n","Dataset: label 2 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 2 - train - 699156 chunks - 5.53 Gb\n","Dataset: label 3 - train - in model as torch.tensor(1)\n","Dataset: label 3 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - train - 381 files\n","Dataset: label 3 - train - 0%\n","Dataset: label 3 - train - 9%\n","Dataset: label 3 - train - 19%\n","Dataset: label 3 - train - 29%\n","Dataset: label 3 - train - 39%\n","Dataset: label 3 - train - 49%\n","Dataset: label 3 - train - 59%\n","Dataset: label 3 - train - 69%\n","Dataset: label 3 - train - 79%\n","Dataset: label 3 - train - 89%\n","Dataset: label 3 - train - 99%\n","Dataset: label 3 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 3 - train - 142298 chunks - 1.19 Gb\n","Dataset: label 4 - train - in model as torch.tensor(1)\n","Dataset: label 4 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - train - 34 files\n","Dataset: label 4 - train - 0%\n","Dataset: label 4 - train - 8%\n","Dataset: label 4 - train - 17%\n","Dataset: label 4 - train - 26%\n","Dataset: label 4 - train - 35%\n","Dataset: label 4 - train - 44%\n","Dataset: label 4 - train - 52%\n","Dataset: label 4 - train - 61%\n","Dataset: label 4 - train - 70%\n","Dataset: label 4 - train - 79%\n","Dataset: label 4 - train - 88%\n","Dataset: label 4 - train - 97%\n","Dataset: label 4 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 4 - train - 18140 chunks - 0.14 Gb\n","Dataset: label 5 - train - in model as torch.tensor(1)\n","Dataset: label 5 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - train - 601 files\n","Dataset: label 5 - train - 0%\n","Dataset: label 5 - train - 9%\n","Dataset: label 5 - train - 19%\n","Dataset: label 5 - train - 29%\n","Dataset: label 5 - train - 39%\n","Dataset: label 5 - train - 49%\n","Dataset: label 5 - train - 59%\n","Dataset: label 5 - train - 69%\n","Dataset: label 5 - train - 79%\n","Dataset: label 5 - train - 89%\n","Dataset: label 5 - train - 99%\n","Dataset: label 5 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 5 - train - 603914 chunks - 4.91 Gb\n","Dataset: label 6 - train - in model as torch.tensor(1)\n","Dataset: label 6 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - train - 320 files\n","Dataset: label 6 - train - 0%\n","Dataset: label 6 - train - 10%\n","Dataset: label 6 - train - 20%\n","Dataset: label 6 - train - 30%\n","Dataset: label 6 - train - 40%\n","Dataset: label 6 - train - 50%\n","Dataset: label 6 - train - 60%\n","Dataset: label 6 - train - 70%\n","Dataset: label 6 - train - 80%\n","Dataset: label 6 - train - 90%\n","Dataset: label 6 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 6 - train - 75196 chunks - 0.59 Gb\n","Dataset: label 7 - train - in model as torch.tensor(1)\n","Dataset: label 7 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - train - 984 files\n","Dataset: label 7 - train - 0%\n","Dataset: label 7 - train - 9%\n","Dataset: label 7 - train - 19%\n","Dataset: label 7 - train - 29%\n","Dataset: label 7 - train - 39%\n","Dataset: label 7 - train - 49%\n","Dataset: label 7 - train - 59%\n","Dataset: label 7 - train - 69%\n","Dataset: label 7 - train - 79%\n","Dataset: label 7 - train - 89%\n","Dataset: label 7 - train - 99%\n","Dataset: label 7 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 7 - train - 1016247 chunks - 7.87 Gb\n","Dataset: label 8 - train - in model as torch.tensor(1)\n","Dataset: label 8 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - train - 811 files\n","Dataset: label 8 - train - 0%\n","Dataset: label 8 - train - 9%\n","Dataset: label 8 - train - 19%\n","Dataset: label 8 - train - 29%\n","Dataset: label 8 - train - 39%\n","Dataset: label 8 - train - 49%\n","Dataset: label 8 - train - 59%\n","Dataset: label 8 - train - 69%\n","Dataset: label 8 - train - 79%\n","Dataset: label 8 - train - 89%\n","Dataset: label 8 - train - 99%\n","Dataset: label 8 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-9.chunk-32.train.csv\n","Dataset: label 8 - train - 1299066 chunks - 9.96 Gb\n","Dataset: label 0 - eval - in model as torch.tensor(0)\n","Dataset: label 0 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - eval - 154 files\n","Dataset: label 0 - eval - 0%\n","Dataset: label 0 - eval - 9%\n","Dataset: label 0 - eval - 19%\n","Dataset: label 0 - eval - 29%\n","Dataset: label 0 - eval - 38%\n","Dataset: label 0 - eval - 48%\n","Dataset: label 0 - eval - 58%\n","Dataset: label 0 - eval - 68%\n","Dataset: label 0 - eval - 77%\n","Dataset: label 0 - eval - 87%\n","Dataset: label 0 - eval - 97%\n","Dataset: label 0 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 0 - eval - 390396 chunks - 3.07 Gb\n","Dataset: label 1 - eval - in model as torch.tensor(1)\n","Dataset: label 1 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - eval - 247 files\n","Dataset: label 1 - eval - 0%\n","Dataset: label 1 - eval - 9%\n","Dataset: label 1 - eval - 19%\n","Dataset: label 1 - eval - 29%\n","Dataset: label 1 - eval - 38%\n","Dataset: label 1 - eval - 48%\n","Dataset: label 1 - eval - 58%\n","Dataset: label 1 - eval - 68%\n","Dataset: label 1 - eval - 77%\n","Dataset: label 1 - eval - 87%\n","Dataset: label 1 - eval - 97%\n","Dataset: label 1 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 1 - eval - 406215 chunks - 3.45 Gb\n","Dataset: label 2 - eval - in model as torch.tensor(1)\n","Dataset: label 2 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - eval - 294 files\n","Dataset: label 2 - eval - 0%\n","Dataset: label 2 - eval - 9%\n","Dataset: label 2 - eval - 19%\n","Dataset: label 2 - eval - 29%\n","Dataset: label 2 - eval - 39%\n","Dataset: label 2 - eval - 49%\n","Dataset: label 2 - eval - 59%\n","Dataset: label 2 - eval - 69%\n","Dataset: label 2 - eval - 78%\n","Dataset: label 2 - eval - 88%\n","Dataset: label 2 - eval - 98%\n","Dataset: label 2 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 2 - eval - 87144 chunks - 0.75 Gb\n","Dataset: label 3 - eval - in model as torch.tensor(1)\n","Dataset: label 3 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - eval - 47 files\n","Dataset: label 3 - eval - 0%\n","Dataset: label 3 - eval - 8%\n","Dataset: label 3 - eval - 17%\n","Dataset: label 3 - eval - 25%\n","Dataset: label 3 - eval - 34%\n","Dataset: label 3 - eval - 42%\n","Dataset: label 3 - eval - 51%\n","Dataset: label 3 - eval - 59%\n","Dataset: label 3 - eval - 68%\n","Dataset: label 3 - eval - 76%\n","Dataset: label 3 - eval - 85%\n","Dataset: label 3 - eval - 93%\n","Dataset: label 3 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 3 - eval - 20345 chunks - 0.16 Gb\n","Dataset: label 4 - eval - in model as torch.tensor(1)\n","Dataset: label 4 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - eval - 4 files\n","Dataset: label 4 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 4 - eval - 2100 chunks - 0.02 Gb\n","Dataset: label 5 - eval - in model as torch.tensor(1)\n","Dataset: label 5 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - eval - 75 files\n","Dataset: label 5 - eval - 0%\n","Dataset: label 5 - eval - 9%\n","Dataset: label 5 - eval - 18%\n","Dataset: label 5 - eval - 28%\n","Dataset: label 5 - eval - 37%\n","Dataset: label 5 - eval - 46%\n","Dataset: label 5 - eval - 56%\n","Dataset: label 5 - eval - 65%\n","Dataset: label 5 - eval - 74%\n","Dataset: label 5 - eval - 84%\n","Dataset: label 5 - eval - 93%\n","Dataset: label 5 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 5 - eval - 75032 chunks - 0.59 Gb\n","Dataset: label 6 - eval - in model as torch.tensor(1)\n","Dataset: label 6 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - eval - 39 files\n","Dataset: label 6 - eval - 0%\n","Dataset: label 6 - eval - 7%\n","Dataset: label 6 - eval - 15%\n","Dataset: label 6 - eval - 23%\n","Dataset: label 6 - eval - 30%\n","Dataset: label 6 - eval - 38%\n","Dataset: label 6 - eval - 46%\n","Dataset: label 6 - eval - 53%\n","Dataset: label 6 - eval - 61%\n","Dataset: label 6 - eval - 69%\n","Dataset: label 6 - eval - 76%\n","Dataset: label 6 - eval - 84%\n","Dataset: label 6 - eval - 92%\n","Dataset: label 6 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 6 - eval - 12067 chunks - 0.1 Gb\n","Dataset: label 7 - eval - in model as torch.tensor(1)\n","Dataset: label 7 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - eval - 122 files\n","Dataset: label 7 - eval - 0%\n","Dataset: label 7 - eval - 9%\n","Dataset: label 7 - eval - 19%\n","Dataset: label 7 - eval - 29%\n","Dataset: label 7 - eval - 39%\n","Dataset: label 7 - eval - 49%\n","Dataset: label 7 - eval - 59%\n","Dataset: label 7 - eval - 68%\n","Dataset: label 7 - eval - 78%\n","Dataset: label 7 - eval - 88%\n","Dataset: label 7 - eval - 98%\n","Dataset: label 7 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 7 - eval - 125606 chunks - 1.06 Gb\n","Dataset: label 8 - eval - in model as torch.tensor(1)\n","Dataset: label 8 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - eval - 101 files\n","Dataset: label 8 - eval - 0%\n","Dataset: label 8 - eval - 9%\n","Dataset: label 8 - eval - 19%\n","Dataset: label 8 - eval - 29%\n","Dataset: label 8 - eval - 39%\n","Dataset: label 8 - eval - 49%\n","Dataset: label 8 - eval - 59%\n","Dataset: label 8 - eval - 69%\n","Dataset: label 8 - eval - 79%\n","Dataset: label 8 - eval - 89%\n","Dataset: label 8 - eval - 99%\n","Dataset: label 8 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-9.chunk-32.eval.csv\n","Dataset: label 8 - eval - 153309 chunks - 1.19 Gb\n","Dataset: label 0 - test - in model as torch.tensor(0)\n","Dataset: label 0 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - test - 154 files\n","Dataset: label 0 - test - 0%\n","Dataset: label 0 - test - 9%\n","Dataset: label 0 - test - 19%\n","Dataset: label 0 - test - 29%\n","Dataset: label 0 - test - 38%\n","Dataset: label 0 - test - 48%\n","Dataset: label 0 - test - 58%\n","Dataset: label 0 - test - 68%\n","Dataset: label 0 - test - 77%\n","Dataset: label 0 - test - 87%\n","Dataset: label 0 - test - 97%\n","Dataset: label 0 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 0 - test - 365208 chunks - 3.07 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - test - 247 files\n","Dataset: label 1 - test - 0%\n","Dataset: label 1 - test - 9%\n","Dataset: label 1 - test - 19%\n","Dataset: label 1 - test - 29%\n","Dataset: label 1 - test - 38%\n","Dataset: label 1 - test - 48%\n","Dataset: label 1 - test - 58%\n","Dataset: label 1 - test - 68%\n","Dataset: label 1 - test - 77%\n","Dataset: label 1 - test - 87%\n","Dataset: label 1 - test - 97%\n","Dataset: label 1 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 1 - test - 444290 chunks - 3.45 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - test - 294 files\n","Dataset: label 2 - test - 0%\n","Dataset: label 2 - test - 9%\n","Dataset: label 2 - test - 19%\n","Dataset: label 2 - test - 29%\n","Dataset: label 2 - test - 39%\n","Dataset: label 2 - test - 49%\n","Dataset: label 2 - test - 59%\n","Dataset: label 2 - test - 69%\n","Dataset: label 2 - test - 78%\n","Dataset: label 2 - test - 88%\n","Dataset: label 2 - test - 98%\n","Dataset: label 2 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 2 - test - 89391 chunks - 0.75 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - test - 47 files\n","Dataset: label 3 - test - 0%\n","Dataset: label 3 - test - 8%\n","Dataset: label 3 - test - 17%\n","Dataset: label 3 - test - 25%\n","Dataset: label 3 - test - 34%\n","Dataset: label 3 - test - 42%\n","Dataset: label 3 - test - 51%\n","Dataset: label 3 - test - 59%\n","Dataset: label 3 - test - 68%\n","Dataset: label 3 - test - 76%\n","Dataset: label 3 - test - 85%\n","Dataset: label 3 - test - 93%\n","Dataset: label 3 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 3 - test - 18183 chunks - 0.14 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - test - 4 files\n","Dataset: label 4 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 4 - test - 1744 chunks - 0.01 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - test - 75 files\n","Dataset: label 5 - test - 0%\n","Dataset: label 5 - test - 9%\n","Dataset: label 5 - test - 18%\n","Dataset: label 5 - test - 28%\n","Dataset: label 5 - test - 37%\n","Dataset: label 5 - test - 46%\n","Dataset: label 5 - test - 56%\n","Dataset: label 5 - test - 65%\n","Dataset: label 5 - test - 74%\n","Dataset: label 5 - test - 84%\n","Dataset: label 5 - test - 93%\n","Dataset: label 5 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 5 - test - 68437 chunks - 0.52 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - test - 39 files\n","Dataset: label 6 - test - 0%\n","Dataset: label 6 - test - 7%\n","Dataset: label 6 - test - 15%\n","Dataset: label 6 - test - 23%\n","Dataset: label 6 - test - 30%\n","Dataset: label 6 - test - 38%\n","Dataset: label 6 - test - 46%\n","Dataset: label 6 - test - 53%\n","Dataset: label 6 - test - 61%\n","Dataset: label 6 - test - 69%\n","Dataset: label 6 - test - 76%\n","Dataset: label 6 - test - 84%\n","Dataset: label 6 - test - 92%\n","Dataset: label 6 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 6 - test - 12652 chunks - 0.1 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - test - 122 files\n","Dataset: label 7 - test - 0%\n","Dataset: label 7 - test - 9%\n","Dataset: label 7 - test - 19%\n","Dataset: label 7 - test - 29%\n","Dataset: label 7 - test - 39%\n","Dataset: label 7 - test - 49%\n","Dataset: label 7 - test - 59%\n","Dataset: label 7 - test - 68%\n","Dataset: label 7 - test - 78%\n","Dataset: label 7 - test - 88%\n","Dataset: label 7 - test - 98%\n","Dataset: label 7 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 7 - test - 120569 chunks - 0.94 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - test - 101 files\n","Dataset: label 8 - test - 0%\n","Dataset: label 8 - test - 9%\n","Dataset: label 8 - test - 19%\n","Dataset: label 8 - test - 29%\n","Dataset: label 8 - test - 39%\n","Dataset: label 8 - test - 49%\n","Dataset: label 8 - test - 59%\n","Dataset: label 8 - test - 69%\n","Dataset: label 8 - test - 79%\n","Dataset: label 8 - test - 89%\n","Dataset: label 8 - test - 99%\n","Dataset: label 8 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-9.chunk-32.test.csv\n","Dataset: label 8 - test - 164299 chunks - 1.34 Gb\n","2:15:31\n","Namespace(batch=None, cache=True, check=False, complete=False, epochs=None, fold='10', label=None, limit='102400', metrics=False, model='gpt2', multi=False, path=None, process=False, test=False, train=False)\n","pid: 2740\n","Args: limit 102400\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi False\n","Args: fold 10\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: downloading tokenizer...\n","Model: saving tokenizer...\n","Model: tokenizer saved!\n","-----\n","label 0\n","-----\n","label 1\n","-----\n","label 2\n","-----\n","label 3\n","-----\n","label 4\n","-----\n","label 5\n","-----\n","label 6\n","-----\n","label 7\n","-----\n","label 8\n","Dataset: label 0 - train - in model as torch.tensor(0)\n","Dataset: label 0 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - train - 1233 files\n","Token indices sequence length is longer than the specified maximum sequence length for this model (8591 > 1024). Running this sequence through the model will result in indexing errors\n","Dataset: label 0 - train - 0%\n","Dataset: label 0 - train - 9%\n","Dataset: label 0 - train - 19%\n","Dataset: label 0 - train - 29%\n","Dataset: label 0 - train - 39%\n","Dataset: label 0 - train - 49%\n","Dataset: label 0 - train - 59%\n","Dataset: label 0 - train - 69%\n","Dataset: label 0 - train - 79%\n","Dataset: label 0 - train - 89%\n","Dataset: label 0 - train - 99%\n","Dataset: label 0 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 0 - train - 3060095 chunks - 25.55 Gb\n","Dataset: label 1 - train - in model as torch.tensor(1)\n","Dataset: label 1 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - train - 1984 files\n","Dataset: label 1 - train - 0%\n","Dataset: label 1 - train - 9%\n","Dataset: label 1 - train - 19%\n","Dataset: label 1 - train - 29%\n","Dataset: label 1 - train - 39%\n","Dataset: label 1 - train - 49%\n","Dataset: label 1 - train - 59%\n","Dataset: label 1 - train - 69%\n","Dataset: label 1 - train - 79%\n","Dataset: label 1 - train - 89%\n","Dataset: label 1 - train - 99%\n","Dataset: label 1 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 1 - train - 3329232 chunks - 25.55 Gb\n","Dataset: label 2 - train - in model as torch.tensor(1)\n","Dataset: label 2 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - train - 2354 files\n","Dataset: label 2 - train - 0%\n","Dataset: label 2 - train - 9%\n","Dataset: label 2 - train - 19%\n","Dataset: label 2 - train - 29%\n","Dataset: label 2 - train - 39%\n","Dataset: label 2 - train - 49%\n","Dataset: label 2 - train - 59%\n","Dataset: label 2 - train - 69%\n","Dataset: label 2 - train - 79%\n","Dataset: label 2 - train - 89%\n","Dataset: label 2 - train - 99%\n","Dataset: label 2 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 2 - train - 695080 chunks - 5.53 Gb\n","Dataset: label 3 - train - in model as torch.tensor(1)\n","Dataset: label 3 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - train - 381 files\n","Dataset: label 3 - train - 0%\n","Dataset: label 3 - train - 9%\n","Dataset: label 3 - train - 19%\n","Dataset: label 3 - train - 29%\n","Dataset: label 3 - train - 39%\n","Dataset: label 3 - train - 49%\n","Dataset: label 3 - train - 59%\n","Dataset: label 3 - train - 69%\n","Dataset: label 3 - train - 79%\n","Dataset: label 3 - train - 89%\n","Dataset: label 3 - train - 99%\n","Dataset: label 3 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 3 - train - 144478 chunks - 1.19 Gb\n","Dataset: label 4 - train - in model as torch.tensor(1)\n","Dataset: label 4 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - train - 34 files\n","Dataset: label 4 - train - 0%\n","Dataset: label 4 - train - 8%\n","Dataset: label 4 - train - 17%\n","Dataset: label 4 - train - 26%\n","Dataset: label 4 - train - 35%\n","Dataset: label 4 - train - 44%\n","Dataset: label 4 - train - 52%\n","Dataset: label 4 - train - 61%\n","Dataset: label 4 - train - 70%\n","Dataset: label 4 - train - 79%\n","Dataset: label 4 - train - 88%\n","Dataset: label 4 - train - 97%\n","Dataset: label 4 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 4 - train - 17115 chunks - 0.14 Gb\n","Dataset: label 5 - train - in model as torch.tensor(1)\n","Dataset: label 5 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - train - 601 files\n","Dataset: label 5 - train - 0%\n","Dataset: label 5 - train - 9%\n","Dataset: label 5 - train - 19%\n","Dataset: label 5 - train - 29%\n","Dataset: label 5 - train - 39%\n","Dataset: label 5 - train - 49%\n","Dataset: label 5 - train - 59%\n","Dataset: label 5 - train - 69%\n","Dataset: label 5 - train - 79%\n","Dataset: label 5 - train - 89%\n","Dataset: label 5 - train - 99%\n","Dataset: label 5 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 5 - train - 603939 chunks - 4.91 Gb\n","Dataset: label 6 - train - in model as torch.tensor(1)\n","Dataset: label 6 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - train - 320 files\n","Dataset: label 6 - train - 0%\n","Dataset: label 6 - train - 10%\n","Dataset: label 6 - train - 20%\n","Dataset: label 6 - train - 30%\n","Dataset: label 6 - train - 40%\n","Dataset: label 6 - train - 50%\n","Dataset: label 6 - train - 60%\n","Dataset: label 6 - train - 70%\n","Dataset: label 6 - train - 80%\n","Dataset: label 6 - train - 90%\n","Dataset: label 6 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 6 - train - 76907 chunks - 0.59 Gb\n","Dataset: label 7 - train - in model as torch.tensor(1)\n","Dataset: label 7 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - train - 984 files\n","Dataset: label 7 - train - 0%\n","Dataset: label 7 - train - 9%\n","Dataset: label 7 - train - 19%\n","Dataset: label 7 - train - 29%\n","Dataset: label 7 - train - 39%\n","Dataset: label 7 - train - 49%\n","Dataset: label 7 - train - 59%\n","Dataset: label 7 - train - 69%\n","Dataset: label 7 - train - 79%\n","Dataset: label 7 - train - 89%\n","Dataset: label 7 - train - 99%\n","Dataset: label 7 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 7 - train - 1030687 chunks - 7.87 Gb\n","Dataset: label 8 - train - in model as torch.tensor(1)\n","Dataset: label 8 - train - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - train - 811 files\n","Dataset: label 8 - train - 0%\n","Dataset: label 8 - train - 9%\n","Dataset: label 8 - train - 19%\n","Dataset: label 8 - train - 29%\n","Dataset: label 8 - train - 39%\n","Dataset: label 8 - train - 49%\n","Dataset: label 8 - train - 59%\n","Dataset: label 8 - train - 69%\n","Dataset: label 8 - train - 79%\n","Dataset: label 8 - train - 89%\n","Dataset: label 8 - train - 99%\n","Dataset: label 8 - train - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-10.chunk-32.train.csv\n","Dataset: label 8 - train - 1301468 chunks - 9.96 Gb\n","Dataset: label 0 - eval - in model as torch.tensor(0)\n","Dataset: label 0 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - eval - 154 files\n","Dataset: label 0 - eval - 0%\n","Dataset: label 0 - eval - 9%\n","Dataset: label 0 - eval - 19%\n","Dataset: label 0 - eval - 29%\n","Dataset: label 0 - eval - 38%\n","Dataset: label 0 - eval - 48%\n","Dataset: label 0 - eval - 58%\n","Dataset: label 0 - eval - 68%\n","Dataset: label 0 - eval - 77%\n","Dataset: label 0 - eval - 87%\n","Dataset: label 0 - eval - 97%\n","Dataset: label 0 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 0 - eval - 365208 chunks - 3.07 Gb\n","Dataset: label 1 - eval - in model as torch.tensor(1)\n","Dataset: label 1 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - eval - 247 files\n","Dataset: label 1 - eval - 0%\n","Dataset: label 1 - eval - 9%\n","Dataset: label 1 - eval - 19%\n","Dataset: label 1 - eval - 29%\n","Dataset: label 1 - eval - 38%\n","Dataset: label 1 - eval - 48%\n","Dataset: label 1 - eval - 58%\n","Dataset: label 1 - eval - 68%\n","Dataset: label 1 - eval - 77%\n","Dataset: label 1 - eval - 87%\n","Dataset: label 1 - eval - 97%\n","Dataset: label 1 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 1 - eval - 444290 chunks - 3.45 Gb\n","Dataset: label 2 - eval - in model as torch.tensor(1)\n","Dataset: label 2 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - eval - 294 files\n","Dataset: label 2 - eval - 0%\n","Dataset: label 2 - eval - 9%\n","Dataset: label 2 - eval - 19%\n","Dataset: label 2 - eval - 29%\n","Dataset: label 2 - eval - 39%\n","Dataset: label 2 - eval - 49%\n","Dataset: label 2 - eval - 59%\n","Dataset: label 2 - eval - 69%\n","Dataset: label 2 - eval - 78%\n","Dataset: label 2 - eval - 88%\n","Dataset: label 2 - eval - 98%\n","Dataset: label 2 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 2 - eval - 89391 chunks - 0.75 Gb\n","Dataset: label 3 - eval - in model as torch.tensor(1)\n","Dataset: label 3 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - eval - 47 files\n","Dataset: label 3 - eval - 0%\n","Dataset: label 3 - eval - 8%\n","Dataset: label 3 - eval - 17%\n","Dataset: label 3 - eval - 25%\n","Dataset: label 3 - eval - 34%\n","Dataset: label 3 - eval - 42%\n","Dataset: label 3 - eval - 51%\n","Dataset: label 3 - eval - 59%\n","Dataset: label 3 - eval - 68%\n","Dataset: label 3 - eval - 76%\n","Dataset: label 3 - eval - 85%\n","Dataset: label 3 - eval - 93%\n","Dataset: label 3 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 3 - eval - 18183 chunks - 0.14 Gb\n","Dataset: label 4 - eval - in model as torch.tensor(1)\n","Dataset: label 4 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - eval - 4 files\n","Dataset: label 4 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 4 - eval - 1744 chunks - 0.01 Gb\n","Dataset: label 5 - eval - in model as torch.tensor(1)\n","Dataset: label 5 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - eval - 75 files\n","Dataset: label 5 - eval - 0%\n","Dataset: label 5 - eval - 9%\n","Dataset: label 5 - eval - 18%\n","Dataset: label 5 - eval - 28%\n","Dataset: label 5 - eval - 37%\n","Dataset: label 5 - eval - 46%\n","Dataset: label 5 - eval - 56%\n","Dataset: label 5 - eval - 65%\n","Dataset: label 5 - eval - 74%\n","Dataset: label 5 - eval - 84%\n","Dataset: label 5 - eval - 93%\n","Dataset: label 5 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 5 - eval - 68437 chunks - 0.52 Gb\n","Dataset: label 6 - eval - in model as torch.tensor(1)\n","Dataset: label 6 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - eval - 39 files\n","Dataset: label 6 - eval - 0%\n","Dataset: label 6 - eval - 7%\n","Dataset: label 6 - eval - 15%\n","Dataset: label 6 - eval - 23%\n","Dataset: label 6 - eval - 30%\n","Dataset: label 6 - eval - 38%\n","Dataset: label 6 - eval - 46%\n","Dataset: label 6 - eval - 53%\n","Dataset: label 6 - eval - 61%\n","Dataset: label 6 - eval - 69%\n","Dataset: label 6 - eval - 76%\n","Dataset: label 6 - eval - 84%\n","Dataset: label 6 - eval - 92%\n","Dataset: label 6 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 6 - eval - 12652 chunks - 0.1 Gb\n","Dataset: label 7 - eval - in model as torch.tensor(1)\n","Dataset: label 7 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - eval - 122 files\n","Dataset: label 7 - eval - 0%\n","Dataset: label 7 - eval - 9%\n","Dataset: label 7 - eval - 19%\n","Dataset: label 7 - eval - 29%\n","Dataset: label 7 - eval - 39%\n","Dataset: label 7 - eval - 49%\n","Dataset: label 7 - eval - 59%\n","Dataset: label 7 - eval - 68%\n","Dataset: label 7 - eval - 78%\n","Dataset: label 7 - eval - 88%\n","Dataset: label 7 - eval - 98%\n","Dataset: label 7 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 7 - eval - 120569 chunks - 0.94 Gb\n","Dataset: label 8 - eval - in model as torch.tensor(1)\n","Dataset: label 8 - eval - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - eval - 101 files\n","Dataset: label 8 - eval - 0%\n","Dataset: label 8 - eval - 9%\n","Dataset: label 8 - eval - 19%\n","Dataset: label 8 - eval - 29%\n","Dataset: label 8 - eval - 39%\n","Dataset: label 8 - eval - 49%\n","Dataset: label 8 - eval - 59%\n","Dataset: label 8 - eval - 69%\n","Dataset: label 8 - eval - 79%\n","Dataset: label 8 - eval - 89%\n","Dataset: label 8 - eval - 99%\n","Dataset: label 8 - eval - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-10.chunk-32.eval.csv\n","Dataset: label 8 - eval - 164299 chunks - 1.34 Gb\n","Dataset: label 0 - test - in model as torch.tensor(0)\n","Dataset: label 0 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0 ...\n","Dataset: label 0 - test - 154 files\n","Dataset: label 0 - test - 0%\n","Dataset: label 0 - test - 9%\n","Dataset: label 0 - test - 19%\n","Dataset: label 0 - test - 29%\n","Dataset: label 0 - test - 38%\n","Dataset: label 0 - test - 48%\n","Dataset: label 0 - test - 58%\n","Dataset: label 0 - test - 68%\n","Dataset: label 0 - test - 77%\n","Dataset: label 0 - test - 87%\n","Dataset: label 0 - test - 97%\n","Dataset: label 0 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 0 - test - 377643 chunks - 3.07 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1 ...\n","Dataset: label 1 - test - 247 files\n","Dataset: label 1 - test - 0%\n","Dataset: label 1 - test - 9%\n","Dataset: label 1 - test - 19%\n","Dataset: label 1 - test - 29%\n","Dataset: label 1 - test - 38%\n","Dataset: label 1 - test - 48%\n","Dataset: label 1 - test - 58%\n","Dataset: label 1 - test - 68%\n","Dataset: label 1 - test - 77%\n","Dataset: label 1 - test - 87%\n","Dataset: label 1 - test - 97%\n","Dataset: label 1 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 1 - test - 422037 chunks - 3.45 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2 ...\n","Dataset: label 2 - test - 294 files\n","Dataset: label 2 - test - 0%\n","Dataset: label 2 - test - 9%\n","Dataset: label 2 - test - 19%\n","Dataset: label 2 - test - 29%\n","Dataset: label 2 - test - 39%\n","Dataset: label 2 - test - 49%\n","Dataset: label 2 - test - 59%\n","Dataset: label 2 - test - 69%\n","Dataset: label 2 - test - 78%\n","Dataset: label 2 - test - 88%\n","Dataset: label 2 - test - 98%\n","Dataset: label 2 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 2 - test - 91220 chunks - 0.75 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3 ...\n","Dataset: label 3 - test - 47 files\n","Dataset: label 3 - test - 0%\n","Dataset: label 3 - test - 8%\n","Dataset: label 3 - test - 17%\n","Dataset: label 3 - test - 25%\n","Dataset: label 3 - test - 34%\n","Dataset: label 3 - test - 42%\n","Dataset: label 3 - test - 51%\n","Dataset: label 3 - test - 59%\n","Dataset: label 3 - test - 68%\n","Dataset: label 3 - test - 76%\n","Dataset: label 3 - test - 85%\n","Dataset: label 3 - test - 93%\n","Dataset: label 3 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 3 - test - 18165 chunks - 0.14 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4 ...\n","Dataset: label 4 - test - 4 files\n","Dataset: label 4 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 4 - test - 3125 chunks - 0.02 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5 ...\n","Dataset: label 5 - test - 75 files\n","Dataset: label 5 - test - 0%\n","Dataset: label 5 - test - 9%\n","Dataset: label 5 - test - 18%\n","Dataset: label 5 - test - 28%\n","Dataset: label 5 - test - 37%\n","Dataset: label 5 - test - 46%\n","Dataset: label 5 - test - 56%\n","Dataset: label 5 - test - 65%\n","Dataset: label 5 - test - 74%\n","Dataset: label 5 - test - 84%\n","Dataset: label 5 - test - 93%\n","Dataset: label 5 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 5 - test - 75007 chunks - 0.59 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6 ...\n","Dataset: label 6 - test - 39 files\n","Dataset: label 6 - test - 0%\n","Dataset: label 6 - test - 7%\n","Dataset: label 6 - test - 15%\n","Dataset: label 6 - test - 23%\n","Dataset: label 6 - test - 30%\n","Dataset: label 6 - test - 38%\n","Dataset: label 6 - test - 46%\n","Dataset: label 6 - test - 53%\n","Dataset: label 6 - test - 61%\n","Dataset: label 6 - test - 69%\n","Dataset: label 6 - test - 76%\n","Dataset: label 6 - test - 84%\n","Dataset: label 6 - test - 92%\n","Dataset: label 6 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 6 - test - 10356 chunks - 0.08 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7 ...\n","Dataset: label 7 - test - 122 files\n","Dataset: label 7 - test - 0%\n","Dataset: label 7 - test - 9%\n","Dataset: label 7 - test - 19%\n","Dataset: label 7 - test - 29%\n","Dataset: label 7 - test - 39%\n","Dataset: label 7 - test - 49%\n","Dataset: label 7 - test - 59%\n","Dataset: label 7 - test - 68%\n","Dataset: label 7 - test - 78%\n","Dataset: label 7 - test - 88%\n","Dataset: label 7 - test - 98%\n","Dataset: label 7 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 7 - test - 111166 chunks - 0.94 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - creating from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8 ...\n","Dataset: label 8 - test - 101 files\n","Dataset: label 8 - test - 0%\n","Dataset: label 8 - test - 9%\n","Dataset: label 8 - test - 19%\n","Dataset: label 8 - test - 29%\n","Dataset: label 8 - test - 39%\n","Dataset: label 8 - test - 49%\n","Dataset: label 8 - test - 59%\n","Dataset: label 8 - test - 69%\n","Dataset: label 8 - test - 79%\n","Dataset: label 8 - test - 89%\n","Dataset: label 8 - test - 99%\n","Dataset: label 8 - test - saved at /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-10.chunk-32.test.csv\n","Dataset: label 8 - test - 150907 chunks - 1.19 Gb\n","1:28:26\n"]}],"source":["# cache dataset\n","! cd $PATH_PROJECT && python main.py --cache --model='gpt2' --limit='102400' --fold='9'\n","! cd $PATH_PROJECT && python main.py --cache --model='gpt2' --limit='102400' --fold='10'"]},{"cell_type":"markdown","metadata":{"id":"bVjnEhgiB83l"},"source":["# Treino"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12430,"status":"ok","timestamp":1667138364509,"user":{"displayName":"Matheus Vanzan","userId":"15834607519873191987"},"user_tz":180},"id":"6j94wuJsP2a7","outputId":"4acbd78b-850d-412c-d15e-f4bf97638fdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch='160', cache=False, check=False, complete=False, epochs='2', label=None, limit='102400', metrics=False, model='gpt2', multi=True, path=None, process=False, test=False, train=True)\n","pid: 351\n","Args: limit 102400\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","START all\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","END all\n","{}\n","0:00:01\n"]}],"source":["! cd $PATH_PROJECT && python main.py --train --multi --model='gpt2' --limit='102400' --epochs='2' --batch='160'"]},{"cell_type":"markdown","metadata":{"id":"RbEbL0qHKTLe"},"source":["# Test Binary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mx-sB9ZHlUfn","outputId":"e7882b7d-c763-4db4-ebd0-0bd616b8731f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch='16', cache=False, check=False, complete=False, epochs=None, label=None, limit='1024', metrics=False, model='gpt2', multi=False, path=None, process=False, test=True, train=False)\n","pid: 17025\n","Args: limit 1024\n","Args: epochs 2\n","Args: batch 16\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi False\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(0)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/0.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [01:59<00:00, 36.15it/s]\n","[[144  10]\n"," [  2 926]]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 3.78MB/s]\n","Downloading builder script: 100% 6.77k/6.77k [00:00<00:00, 3.44MB/s]\n","[[144  10]\n"," [  2 926]]\n","Model: name gpt2\n","Model: label '1'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(0)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:01<00:00, 35.40it/s]\n","[[243   3]\n"," [  0 836]]\n","[[243   3]\n"," [  0 836]]\n","Model: name gpt2\n","Model: label '2'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(0)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.17it/s]\n","[[294   0]\n"," [  0 788]]\n","[[294   0]\n"," [  0 788]]\n","Model: name gpt2\n","Model: label '3'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(0)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.26it/s]\n","[[  46    1]\n"," [   0 1035]]\n","[[  46    1]\n"," [   0 1035]]\n","Model: name gpt2\n","Model: label '4'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(0)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.28it/s]\n","[[   2    2]\n"," [   0 1078]]\n","[[   2    2]\n"," [   0 1078]]\n","Model: name gpt2\n","Model: label '5'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(0)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.14it/s]\n","[[  71    4]\n"," [   0 1007]]\n","[[  71    4]\n"," [   0 1007]]\n","Model: name gpt2\n","Model: label '6'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(0)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.22it/s]\n","[[  38    1]\n"," [   0 1043]]\n","[[  38    1]\n"," [   0 1043]]\n"]}],"source":["! cd $PATH_PROJECT && python main.py --test --model='gpt2' --limit='1024' --batch='16'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDsk5vqClUmG"},"outputs":[],"source":["! cd $PATH_PROJECT && python main.py --metrics --model='gpt2' --limit='512' --batch='16'"]},{"cell_type":"markdown","metadata":{"id":"wAk9iqMClea1"},"source":["# Test Multi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUFIB0p9t0bG"},"outputs":[],"source":["! cd $PATH_PROJECT && python main.py --test --multi --model='gpt2' --limit='102400' --epochs='2' --batch='160'"]},{"cell_type":"markdown","metadata":{"id":"cAEtHDMAj-1Z"},"source":["# Metrics Multi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50778,"status":"ok","timestamp":1667145687793,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"MsGKURDMj--D","outputId":"77b01205-1675-4f89-be12-f6cd4bb2f013"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch='160', cache=False, check=False, complete=False, epochs='1', label=None, limit='10240', metrics=True, model='gpt2', multi=True, path=None, process=False, test=False, train=False)\n","pid: 986\n","Args: limit 10240\n","Args: epochs 1\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","/content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-10240.chunk-32.epochs-1.batch-160/results.csv\n","GOOD: 1069\n","BAD: 14\n","[[150   2   0   0   0   0   0   2   0]\n"," [  1 246   0   0   0   0   0   0   0]\n"," [  0   0 294   0   0   0   0   0   0]\n"," [  0   0   0  47   0   0   0   0   0]\n"," [  0   1   0   0   3   0   0   0   0]\n"," [  0   0   0   0   0  75   0   0   0]\n"," [  1   0   1   0   0   0  37   0   0]\n"," [  5   0   0   0   0   0   0 117   0]\n"," [  0   0   0   0   0   0   0   1 100]]\n","{'all': {'accuracy': 0.987072945521699,\n","         'f1': array([0.96463023, 0.99193548, 0.99830221, 1.        , 0.85714286,\n","       1.        , 0.97368421, 0.96694215, 0.99502488])}}\n","0:00:03\n","Namespace(batch='160', cache=False, check=False, complete=False, epochs='2', label=None, limit='10240', metrics=True, model='gpt2', multi=True, path=None, process=False, test=False, train=False)\n","pid: 999\n","Args: limit 10240\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","/content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-10240.chunk-32.epochs-2.batch-160/results.csv\n","GOOD: 1072\n","BAD: 11\n","[[151   2   0   0   0   0   0   1   0]\n"," [  0 246   0   0   0   1   0   0   0]\n"," [  0   0 294   0   0   0   0   0   0]\n"," [  0   0   0  47   0   0   0   0   0]\n"," [  0   0   0   0   4   0   0   0   0]\n"," [  0   0   0   0   0  75   0   0   0]\n"," [  1   0   0   0   0   0  37   1   0]\n"," [  5   0   0   0   0   0   0 117   0]\n"," [  0   0   0   0   0   0   0   0 101]]\n","{'all': {'accuracy': 0.989843028624192,\n","         'f1': array([0.97106109, 0.99393939, 1.        , 1.        , 1.        ,\n","       0.99337748, 0.97368421, 0.97095436, 1.        ])}}\n","0:00:03\n","Namespace(batch='160', cache=False, check=False, complete=False, epochs='3', label=None, limit='10240', metrics=True, model='gpt2', multi=True, path=None, process=False, test=False, train=False)\n","pid: 1012\n","Args: limit 10240\n","Args: epochs 3\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","/content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-10240.chunk-32.epochs-3.batch-160/results.csv\n","GOOD: 1072\n","BAD: 11\n","[[152   1   0   0   0   0   0   1   0]\n"," [  1 245   0   0   0   1   0   0   0]\n"," [  0   0 294   0   0   0   0   0   0]\n"," [  0   0   0  47   0   0   0   0   0]\n"," [  0   0   0   0   4   0   0   0   0]\n"," [  0   0   0   0   0  75   0   0   0]\n"," [  1   0   0   0   0   0  37   1   0]\n"," [  5   0   0   0   0   0   0 117   0]\n"," [  0   0   0   0   0   0   0   0 101]]\n","{'all': {'accuracy': 0.989843028624192,\n","         'f1': array([0.97124601, 0.99391481, 1.        , 1.        , 1.        ,\n","       0.99337748, 0.97368421, 0.97095436, 1.        ])}}\n","0:00:03\n","Namespace(batch='160', cache=False, check=False, complete=False, epochs='1', label=None, limit='102400', metrics=True, model='gpt2', multi=True, path=None, process=False, test=False, train=False)\n","pid: 1025\n","Args: limit 102400\n","Args: epochs 1\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","/content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.chunk-32.epochs-1.batch-160/results.csv\n","GOOD: 1075\n","BAD: 8\n","[[154   0   0   0   0   0   0   0   0]\n"," [  1 246   0   0   0   0   0   0   0]\n"," [  0   0 294   0   0   0   0   0   0]\n"," [  0   0   0  47   0   0   0   0   0]\n"," [  0   1   0   0   3   0   0   0   0]\n"," [  0   0   0   0   0  75   0   0   0]\n"," [  1   0   0   0   0   0  37   1   0]\n"," [  2   1   0   0   0   0   0 118   1]\n"," [  0   0   0   0   0   0   0   0 101]]\n","{'all': {'accuracy': 0.9926131117266851,\n","         'f1': array([0.98717949, 0.99393939, 1.        , 1.        , 0.85714286,\n","       1.        , 0.97368421, 0.97925311, 0.99507389])}}\n","0:00:03\n","Namespace(batch='160', cache=False, check=False, complete=False, epochs='2', label=None, limit='102400', metrics=True, model='gpt2', multi=True, path=None, process=False, test=False, train=False)\n","pid: 1038\n","Args: limit 102400\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","/content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.chunk-32.epochs-2.batch-160/results.csv\n","GOOD: 1076\n","BAD: 7\n","[[154   0   0   0   0   0   0   0   0]\n"," [  1 246   0   0   0   0   0   0   0]\n"," [  0   0 294   0   0   0   0   0   0]\n"," [  0   0   0  47   0   0   0   0   0]\n"," [  0   1   0   0   3   0   0   0   0]\n"," [  0   0   0   0   0  75   0   0   0]\n"," [  1   0   0   0   0   0  37   1   0]\n"," [  1   1   0   0   0   0   0 119   1]\n"," [  0   0   0   0   0   0   0   0 101]]\n","{'all': {'accuracy': 0.9935364727608494,\n","         'f1': array([0.9903537 , 0.99393939, 1.        , 1.        , 0.85714286,\n","       1.        , 0.97368421, 0.98347107, 0.99507389])}}\n","0:00:03\n"]}],"source":["\n","! cd $PATH_PROJECT && python main.py --metrics --multi --model='gpt2' --limit='10240' --epochs='1' --batch='160'\n","! cd $PATH_PROJECT && python main.py --metrics --multi --model='gpt2' --limit='10240' --epochs='2' --batch='160'\n","! cd $PATH_PROJECT && python main.py --metrics --multi --model='gpt2' --limit='10240' --epochs='3' --batch='160'\n","\n","\n","! cd $PATH_PROJECT && python main.py --metrics --multi --model='gpt2' --limit='102400' --epochs='1' --batch='160'\n","! cd $PATH_PROJECT && python main.py --metrics --multi --model='gpt2' --limit='102400' --epochs='2' --batch='160'"]},{"cell_type":"markdown","metadata":{"id":"n483Ij76Ra17"},"source":["# Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KInTwB233ev"},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir /content/drive/Shareddrives/GPTJ/data/gpt2/7.limit-256.chunk-32.epochs-5.batch-16/logs"]},{"cell_type":"markdown","metadata":{"id":"aHWiFkWTcjS0"},"source":["# Temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfgonH76CGVG"},"outputs":[],"source":["from statistics import mean\n","\n","l1 = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n","print(mean(l1), round(mean(l1)))\n","\n","l2 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n","print(mean(l2), round(mean(l2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxm69BpeWsIS"},"outputs":[],"source":["from collections import Counter\n","\n","L = [1,   1, 3, 5, 6, 6, 6, 7]\n","W = [2.5, 2, 1, 1, 1, 1, 1, 1]\n","\n","def WeightedCounter(L, W):\n","    c = {}\n","    for l, w in zip(L, W):\n","        if not l in c:\n","            c.update({l:0})\n","        c[l] += w\n","    return Counter(c)\n","\n","c1 = Counter(L).most_common()[0][0]\n","c2 = WeightedCounter(L, W).most_common()[0][0]\n","\n","print(c1)\n","print(c2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1668125968641,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"4bx0wgg0DREd","outputId":"2c4dbb1a-b7f2-45f4-fa86-188c9fe3313c"},"outputs":[{"data":{"text/plain":["set()"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["s1 = set(['a', 'b', 'c'])\n","s2 = set(['a', 'd', 'e'])\n","s3 = set(['b', 'c', 'e'])\n","\n","s = set.intersection(s1, s2, s3)\n","s"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1668126615269,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"KuY2W8MEFJSE","outputId":"6b3cf72b-f5ee-49aa-e74e-efd3aedc9274"},"outputs":[{"data":{"text/plain":["[1, 2, 3, 4, 5, 6]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import itertools\n","\n","l = 3*[None]\n","l[0] = [1, 2, 3]\n","l[1] = [4, 5, 6]\n","l[2] = [7, 8, 9]\n","\n","list(itertools.chain.from_iterable( [ l[i] for i in range(2) ] ))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1668128240703,"user":{"displayName":"Cap Vanzan","userId":"05248490625695273722"},"user_tz":180},"id":"xz6m7sHwKpt2","outputId":"8c3cbd3f-3bcb-4272-b033-9be27f74d092"},"outputs":[{"data":{"text/plain":["[2, 3, 4, 5, 6, 1]"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["l = [1, 2, 3, 4, 5, 6]\n","\n","\n","i = 1\n","l = l[i:] + l[:i]\n","l"]}],"metadata":{"colab":{"collapsed_sections":["A1bIc0ZAumSJ","JuIxLRfousPd","ZZdJjTltuR4z","bVjnEhgiB83l","RbEbL0qHKTLe","wAk9iqMClea1","cAEtHDMAj-1Z","n483Ij76Ra17","aHWiFkWTcjS0"],"provenance":[{"file_id":"1z5YmbSqayjX1AVwNGdk4fiusOkBxa_YK","timestamp":1663640920362}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}