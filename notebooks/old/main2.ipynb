{"cells":[{"cell_type":"markdown","metadata":{"id":"A1bIc0ZAumSJ"},"source":["# Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56436,"status":"ok","timestamp":1672089940838,"user":{"displayName":"Matheus Vanzan","userId":"00040097546844763627"},"user_tz":180},"id":"eckl1rAzruSX","outputId":"04679820-0d4d-46c7-e806-98100392003f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["####################################\n","#\n","#  ADD THIS TO EVERY COLAB FILE!\n","#\n","####################################\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import drive.Shareddrives.GPTJ.project.settings as settings\n","\n","PATH_PROJECT = settings.PATH_PROJECT\n","PATH_DATA = settings.PATH_DATA"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50801,"status":"ok","timestamp":1672089991635,"user":{"displayName":"Matheus Vanzan","userId":"00040097546844763627"},"user_tz":180},"id":"L5zLhAxca2u4","outputId":"d2ae2c5e-81aa-4de0-f61e-07f02402c750"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 143 kB 15.7 MB/s \n","\u001b[K     |████████████████████████████████| 55.9 MB 261 kB/s \n","\u001b[K     |████████████████████████████████| 85 kB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 66.6 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 56.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 45.1 MB/s \n","\u001b[K     |████████████████████████████████| 452 kB 68.2 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 69.3 MB/s \n","\u001b[K     |████████████████████████████████| 132 kB 69.1 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 72.3 MB/s \n","\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! cd $PATH_PROJECT && pip install -q -r requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1672089992514,"user":{"displayName":"Matheus Vanzan","userId":"00040097546844763627"},"user_tz":180},"id":"M5QqmMI7iYnu","outputId":"a70eca3a-7fd6-4e87-ac42-c2be17ed02e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec 26 21:26:30 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   66C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi\n","\n","# Standard -> Tesla T4\n","# Premium -> Tesla P100-PCIE-16GB"]},{"cell_type":"markdown","metadata":{"id":"ZZdJjTltuR4z"},"source":["# Cache local do Dataset\n","\n","Como o dataset tem um tamanho grande e está no Google Drive distribuído em vários arquivos, queremos carregar todos em um único arquivo já tokenizado pelo *tokenizer* da GPT.\n","\n","Para evitar problemas de sincronização, vamos copiar os arquivos para /content/tmp/, depois copiar de volta os arquivos resultantes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216511,"status":"ok","timestamp":1668132197236,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"},"user_tz":180},"id":"5sYLF6MicevF","outputId":"af3ae1e2-1c23-4c38-8e22-c0c87b65a678"},"outputs":[{"name":"stdout","output_type":"stream","text":["model 0\n","\n","real\t1m11.157s\n","user\t0m0.016s\n","sys\t0m2.026s\n","model 1\n","\n","real\t1m45.635s\n","user\t0m0.029s\n","sys\t0m1.899s\n","model 2\n","^C\n"]}],"source":["! mkdir -p \"/content/tmp/\"\n","! for i in {0..8}; do echo \"model $i\" && time cp -r /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/$i /content/tmp/; done"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667102237626,"user":{"displayName":"Matheus Vanzan","userId":"15834607519873191987"},"user_tz":180},"id":"QOECcvyLJbg6","outputId":"c97112d9-6fe6-4041-a0d4-215fca1f5a14"},"outputs":[{"name":"stdout","output_type":"stream","text":["model 0\n","1.3G\t/content/tmp/0\n","1541\n","model 1\n","989M\t/content/tmp/1\n","2478\n","model 2\n","76M\t/content/tmp/2\n","2942\n","model 3\n","16M\t/content/tmp/3\n","475\n","model 4\n","1.8M\t/content/tmp/4\n","42\n","model 5\n","67M\t/content/tmp/5\n","751\n","model 6\n","28M\t/content/tmp/6\n","398\n","model 7\n","141M\t/content/tmp/7\n","1228\n","model 8\n","137M\t/content/tmp/8\n","1013\n"]}],"source":["\n","# ! ls \"$PATH_DATA/kaggle/proc-1/$LABEL/\" | wc -l\n","# ! ls \"/content/tmp/$LABEL/\" | wc -l\n","\n","! for i in {0..8}; do echo \"model $i\" && du -sh \"/content/tmp/$i\" && ls \"/content/tmp/$i\" | wc -l; done"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791150,"status":"ok","timestamp":1667103028762,"user":{"displayName":"Matheus Vanzan","userId":"15834607519873191987"},"user_tz":180},"id":"CRqayGhgy5eg","outputId":"6e740d54-5b92-49cd-dec5-3c8618902349"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch=None, cache=True, check=False, complete=False, epochs=None, label=None, limit=None, metrics=False, model=None, multi=False, path='/content/tmp/', process=False, test=False, train=False)\n","pid: 16787\n","Args: limit 1024\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/tmp/\n","Args: model_name gpt2\n","Args: multi False\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: downloading tokenizer...\n","Downloading: 100% 1.04M/1.04M [00:01<00:00, 748kB/s]\n","Downloading: 100% 456k/456k [00:01<00:00, 403kB/s]\n","Downloading: 100% 665/665 [00:00<00:00, 479kB/s]\n","Model: saving tokenizer...\n","Model: tokenizer saved!\n","Dataset: label 0 - eval - in model as torch.tensor(0)\n","Dataset: label 0 - eval - creating from /content/tmp/0 ...\n","Dataset: label 0 - eval - 154 files\n","Token indices sequence length is longer than the specified maximum sequence length for this model (95541 > 1024). Running this sequence through the model will result in indexing errors\n","Dataset: label 0 - eval - 0%\n","Dataset: label 0 - eval - 9%\n","Dataset: label 0 - eval - 19%\n","Dataset: label 0 - eval - 29%\n","Dataset: label 0 - eval - 38%\n","Dataset: label 0 - eval - 48%\n","Dataset: label 0 - eval - 58%\n","Dataset: label 0 - eval - 68%\n","Dataset: label 0 - eval - 77%\n","Dataset: label 0 - eval - 87%\n","Dataset: label 0 - eval - 97%\n","Dataset: label 0 - eval - saved at /content/tmp/0.limit-1024.chunk-32.eval.csv\n","Dataset: label 0 - eval - 4896 chunks - 0.04 Gb\n","Dataset: label 1 - eval - in model as torch.tensor(1)\n","Dataset: label 1 - eval - creating from /content/tmp/1 ...\n","Dataset: label 1 - eval - 247 files\n","Dataset: label 1 - eval - 0%\n","Dataset: label 1 - eval - 9%\n","Dataset: label 1 - eval - 19%\n","Dataset: label 1 - eval - 29%\n","Dataset: label 1 - eval - 38%\n","Dataset: label 1 - eval - 48%\n","Dataset: label 1 - eval - 58%\n","Dataset: label 1 - eval - 68%\n","Dataset: label 1 - eval - 77%\n","Dataset: label 1 - eval - 87%\n","Dataset: label 1 - eval - 97%\n","Dataset: label 1 - eval - saved at /content/tmp/1.limit-1024.chunk-32.eval.csv\n","Dataset: label 1 - eval - 7873 chunks - 0.06 Gb\n","Dataset: label 2 - eval - in model as torch.tensor(1)\n","Dataset: label 2 - eval - creating from /content/tmp/2 ...\n","Dataset: label 2 - eval - 294 files\n","Dataset: label 2 - eval - 0%\n","Dataset: label 2 - eval - 9%\n","Dataset: label 2 - eval - 19%\n","Dataset: label 2 - eval - 29%\n","Dataset: label 2 - eval - 39%\n","Dataset: label 2 - eval - 49%\n","Dataset: label 2 - eval - 59%\n","Dataset: label 2 - eval - 69%\n","Dataset: label 2 - eval - 78%\n","Dataset: label 2 - eval - 88%\n","Dataset: label 2 - eval - 98%\n","Dataset: label 2 - eval - saved at /content/tmp/2.limit-1024.chunk-32.eval.csv\n","Dataset: label 2 - eval - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - eval - in model as torch.tensor(1)\n","Dataset: label 3 - eval - creating from /content/tmp/3 ...\n","Dataset: label 3 - eval - 47 files\n","Dataset: label 3 - eval - 0%\n","Dataset: label 3 - eval - 8%\n","Dataset: label 3 - eval - 17%\n","Dataset: label 3 - eval - 25%\n","Dataset: label 3 - eval - 34%\n","Dataset: label 3 - eval - 42%\n","Dataset: label 3 - eval - 51%\n","Dataset: label 3 - eval - 59%\n","Dataset: label 3 - eval - 68%\n","Dataset: label 3 - eval - 76%\n","Dataset: label 3 - eval - 85%\n","Dataset: label 3 - eval - 93%\n","Dataset: label 3 - eval - saved at /content/tmp/3.limit-1024.chunk-32.eval.csv\n","Dataset: label 3 - eval - 1356 chunks - 0.01 Gb\n","Dataset: label 4 - eval - in model as torch.tensor(1)\n","Dataset: label 4 - eval - creating from /content/tmp/4 ...\n","Dataset: label 4 - eval - 4 files\n","Dataset: label 4 - eval - saved at /content/tmp/4.limit-1024.chunk-32.eval.csv\n","Dataset: label 4 - eval - 128 chunks - 0.0 Gb\n","Dataset: label 5 - eval - in model as torch.tensor(1)\n","Dataset: label 5 - eval - creating from /content/tmp/5 ...\n","Dataset: label 5 - eval - 75 files\n","Dataset: label 5 - eval - 0%\n","Dataset: label 5 - eval - 9%\n","Dataset: label 5 - eval - 18%\n","Dataset: label 5 - eval - 28%\n","Dataset: label 5 - eval - 37%\n","Dataset: label 5 - eval - 46%\n","Dataset: label 5 - eval - 56%\n","Dataset: label 5 - eval - 65%\n","Dataset: label 5 - eval - 74%\n","Dataset: label 5 - eval - 84%\n","Dataset: label 5 - eval - 93%\n","Dataset: label 5 - eval - saved at /content/tmp/5.limit-1024.chunk-32.eval.csv\n","Dataset: label 5 - eval - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - eval - in model as torch.tensor(1)\n","Dataset: label 6 - eval - creating from /content/tmp/6 ...\n","Dataset: label 6 - eval - 39 files\n","Dataset: label 6 - eval - 0%\n","Dataset: label 6 - eval - 7%\n","Dataset: label 6 - eval - 15%\n","Dataset: label 6 - eval - 23%\n","Dataset: label 6 - eval - 30%\n","Dataset: label 6 - eval - 38%\n","Dataset: label 6 - eval - 46%\n","Dataset: label 6 - eval - 53%\n","Dataset: label 6 - eval - 61%\n","Dataset: label 6 - eval - 69%\n","Dataset: label 6 - eval - 76%\n","Dataset: label 6 - eval - 84%\n","Dataset: label 6 - eval - 92%\n","Dataset: label 6 - eval - saved at /content/tmp/6.limit-1024.chunk-32.eval.csv\n","Dataset: label 6 - eval - 1227 chunks - 0.01 Gb\n","Dataset: label 7 - eval - in model as torch.tensor(1)\n","Dataset: label 7 - eval - creating from /content/tmp/7 ...\n","Dataset: label 7 - eval - 122 files\n","Dataset: label 7 - eval - 0%\n","Dataset: label 7 - eval - 9%\n","Dataset: label 7 - eval - 19%\n","Dataset: label 7 - eval - 29%\n","Dataset: label 7 - eval - 39%\n","Dataset: label 7 - eval - 49%\n","Dataset: label 7 - eval - 59%\n","Dataset: label 7 - eval - 68%\n","Dataset: label 7 - eval - 78%\n","Dataset: label 7 - eval - 88%\n","Dataset: label 7 - eval - 98%\n","Dataset: label 7 - eval - saved at /content/tmp/7.limit-1024.chunk-32.eval.csv\n","Dataset: label 7 - eval - 3873 chunks - 0.03 Gb\n","Dataset: label 8 - eval - in model as torch.tensor(1)\n","Dataset: label 8 - eval - creating from /content/tmp/8 ...\n","Dataset: label 8 - eval - 101 files\n","Dataset: label 8 - eval - 0%\n","Dataset: label 8 - eval - 9%\n","Dataset: label 8 - eval - 19%\n","Dataset: label 8 - eval - 29%\n","Dataset: label 8 - eval - 39%\n","Dataset: label 8 - eval - 49%\n","Dataset: label 8 - eval - 59%\n","Dataset: label 8 - eval - 69%\n","Dataset: label 8 - eval - 79%\n","Dataset: label 8 - eval - 89%\n","Dataset: label 8 - eval - 99%\n","Dataset: label 8 - eval - saved at /content/tmp/8.limit-1024.chunk-32.eval.csv\n","Dataset: label 8 - eval - 3232 chunks - 0.03 Gb\n","Dataset: label 0 - test - in model as torch.tensor(0)\n","Dataset: label 0 - test - creating from /content/tmp/0 ...\n","Dataset: label 0 - test - 154 files\n","Dataset: label 0 - test - 0%\n","Dataset: label 0 - test - 9%\n","Dataset: label 0 - test - 19%\n","Dataset: label 0 - test - 29%\n","Dataset: label 0 - test - 38%\n","Dataset: label 0 - test - 48%\n","Dataset: label 0 - test - 58%\n","Dataset: label 0 - test - 68%\n","Dataset: label 0 - test - 77%\n","Dataset: label 0 - test - 87%\n","Dataset: label 0 - test - 97%\n","Dataset: label 0 - test - saved at /content/tmp/0.limit-1024.chunk-32.test.csv\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - creating from /content/tmp/1 ...\n","Dataset: label 1 - test - 247 files\n","Dataset: label 1 - test - 0%\n","Dataset: label 1 - test - 9%\n","Dataset: label 1 - test - 19%\n","Dataset: label 1 - test - 29%\n","Dataset: label 1 - test - 38%\n","Dataset: label 1 - test - 48%\n","Dataset: label 1 - test - 58%\n","Dataset: label 1 - test - 68%\n","Dataset: label 1 - test - 77%\n","Dataset: label 1 - test - 87%\n","Dataset: label 1 - test - 97%\n","Dataset: label 1 - test - saved at /content/tmp/1.limit-1024.chunk-32.test.csv\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - creating from /content/tmp/2 ...\n","Dataset: label 2 - test - 294 files\n","Dataset: label 2 - test - 0%\n","Dataset: label 2 - test - 9%\n","Dataset: label 2 - test - 19%\n","Dataset: label 2 - test - 29%\n","Dataset: label 2 - test - 39%\n","Dataset: label 2 - test - 49%\n","Dataset: label 2 - test - 59%\n","Dataset: label 2 - test - 69%\n","Dataset: label 2 - test - 78%\n","Dataset: label 2 - test - 88%\n","Dataset: label 2 - test - 98%\n","Dataset: label 2 - test - saved at /content/tmp/2.limit-1024.chunk-32.test.csv\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - creating from /content/tmp/3 ...\n","Dataset: label 3 - test - 47 files\n","Dataset: label 3 - test - 0%\n","Dataset: label 3 - test - 8%\n","Dataset: label 3 - test - 17%\n","Dataset: label 3 - test - 25%\n","Dataset: label 3 - test - 34%\n","Dataset: label 3 - test - 42%\n","Dataset: label 3 - test - 51%\n","Dataset: label 3 - test - 59%\n","Dataset: label 3 - test - 68%\n","Dataset: label 3 - test - 76%\n","Dataset: label 3 - test - 85%\n","Dataset: label 3 - test - 93%\n","Dataset: label 3 - test - saved at /content/tmp/3.limit-1024.chunk-32.test.csv\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - creating from /content/tmp/4 ...\n","Dataset: label 4 - test - 4 files\n","Dataset: label 4 - test - saved at /content/tmp/4.limit-1024.chunk-32.test.csv\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - creating from /content/tmp/5 ...\n","Dataset: label 5 - test - 75 files\n","Dataset: label 5 - test - 0%\n","Dataset: label 5 - test - 9%\n","Dataset: label 5 - test - 18%\n","Dataset: label 5 - test - 28%\n","Dataset: label 5 - test - 37%\n","Dataset: label 5 - test - 46%\n","Dataset: label 5 - test - 56%\n","Dataset: label 5 - test - 65%\n","Dataset: label 5 - test - 74%\n","Dataset: label 5 - test - 84%\n","Dataset: label 5 - test - 93%\n","Dataset: label 5 - test - saved at /content/tmp/5.limit-1024.chunk-32.test.csv\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - creating from /content/tmp/6 ...\n","Dataset: label 6 - test - 39 files\n","Dataset: label 6 - test - 0%\n","Dataset: label 6 - test - 7%\n","Dataset: label 6 - test - 15%\n","Dataset: label 6 - test - 23%\n","Dataset: label 6 - test - 30%\n","Dataset: label 6 - test - 38%\n","Dataset: label 6 - test - 46%\n","Dataset: label 6 - test - 53%\n","Dataset: label 6 - test - 61%\n","Dataset: label 6 - test - 69%\n","Dataset: label 6 - test - 76%\n","Dataset: label 6 - test - 84%\n","Dataset: label 6 - test - 92%\n","Dataset: label 6 - test - saved at /content/tmp/6.limit-1024.chunk-32.test.csv\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - creating from /content/tmp/7 ...\n","Dataset: label 7 - test - 122 files\n","Dataset: label 7 - test - 0%\n","Dataset: label 7 - test - 9%\n","Dataset: label 7 - test - 19%\n","Dataset: label 7 - test - 29%\n","Dataset: label 7 - test - 39%\n","Dataset: label 7 - test - 49%\n","Dataset: label 7 - test - 59%\n","Dataset: label 7 - test - 68%\n","Dataset: label 7 - test - 78%\n","Dataset: label 7 - test - 88%\n","Dataset: label 7 - test - 98%\n","Dataset: label 7 - test - saved at /content/tmp/7.limit-1024.chunk-32.test.csv\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - creating from /content/tmp/8 ...\n","Dataset: label 8 - test - 101 files\n","Dataset: label 8 - test - 0%\n","Dataset: label 8 - test - 9%\n","Dataset: label 8 - test - 19%\n","Dataset: label 8 - test - 29%\n","Dataset: label 8 - test - 39%\n","Dataset: label 8 - test - 49%\n","Dataset: label 8 - test - 59%\n","Dataset: label 8 - test - 69%\n","Dataset: label 8 - test - 79%\n","Dataset: label 8 - test - 89%\n","Dataset: label 8 - test - 99%\n","Dataset: label 8 - test - saved at /content/tmp/8.limit-1024.chunk-32.test.csv\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","0:13:02\n"]}],"source":["! cd $PATH_PROJECT && python main.py --cache --path=\"/content/tmp/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19659,"status":"ok","timestamp":1667103048411,"user":{"displayName":"Matheus Vanzan","userId":"15834607519873191987"},"user_tz":180},"id":"2B4hadbyJeiO","outputId":"48f92f98-4b1e-4801-a47a-1686d675b57f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","real\t0m19.622s\n","user\t0m0.001s\n","sys\t0m0.028s\n"]}],"source":["# copy files back\n","! time cp /content/tmp/*.csv \"/content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/\""]},{"cell_type":"markdown","metadata":{"id":"KLYL5KtG59QR"},"source":["# Cache"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6410,"status":"ok","timestamp":1668119403483,"user":{"displayName":"Matheus Vanzan","userId":"02191216176553053689"},"user_tz":180},"id":"a7MNeFoci9Bw","outputId":"09d84120-5e33-44c0-9276-0fd3e5c2021d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch=None, cache=True, check=False, complete=False, epochs=None, fold=None, label=None, limit='256', metrics=False, model='gpt2', multi=False, path=None, process=False, test=False, train=False)\n","pid: 8146\n","Args: limit 256\n","Args: epochs 2\n","Args: batch 160\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi False\n","Args: fold 1\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","-----\n","label 0\n","-----\n","label 1\n","-----\n","label 2\n","-----\n","label 3\n","-----\n","label 4\n","-----\n","label 5\n","-----\n","label 6\n","-----\n","label 7\n","-----\n","label 8\n","0:00:00\n"]}],"source":["# cache dataset\n","! cd $PATH_PROJECT && python main.py --cache --model='gpt2' --limit='256'"]},{"cell_type":"markdown","metadata":{"id":"bVjnEhgiB83l"},"source":["# Treino"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6j94wuJsP2a7","outputId":"914ed3a0-8749-46ad-9de0-4ebea054fb22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch='160', cache=False, check=False, complete=False, epochs='6', fold='1', label=None, limit='102400', metrics=False, model='gpt2', multi=True, path=None, process=False, test=False, train=True)\n","pid: 1041\n","Args: limit 102400\n","Args: epochs 6\n","Args: batch 160\n","Args: labels ['all']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi True\n","Args: fold 1\n","START all\n","Model: name gpt2\n","Model: label 'all'\n","Model: num_labels 9\n","Model: using saved tokenizer...\n","-----\n","label 0\n","-----\n","label 1\n","-----\n","label 2\n","-----\n","label 3\n","-----\n","label 4\n","-----\n","label 5\n","-----\n","label 6\n","-----\n","label 7\n","-----\n","label 8\n","Dataset: label 0 - train - in model as torch.tensor(0)\n","Dataset: label 0 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 0 - train - 3053845 chunks - 25.55 Gb\n","Dataset: label 1 - train - in model as torch.tensor(1)\n","Dataset: label 1 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 1 - train - 3367155 chunks - 28.74 Gb\n","Dataset: label 2 - train - in model as torch.tensor(2)\n","Dataset: label 2 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 2 - train - 696858 chunks - 5.53 Gb\n","Dataset: label 3 - train - in model as torch.tensor(3)\n","Dataset: label 3 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 3 - train - 147095 chunks - 1.19 Gb\n","Dataset: label 4 - train - in model as torch.tensor(4)\n","Dataset: label 4 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 4 - train - 16514 chunks - 0.13 Gb\n","Dataset: label 5 - train - in model as torch.tensor(5)\n","Dataset: label 5 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 5 - train - 602272 chunks - 4.91 Gb\n","Dataset: label 6 - train - in model as torch.tensor(6)\n","Dataset: label 6 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 6 - train - 79083 chunks - 0.66 Gb\n","Dataset: label 7 - train - in model as torch.tensor(7)\n","Dataset: label 7 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 7 - train - 1026322 chunks - 7.87 Gb\n","Dataset: label 8 - train - in model as torch.tensor(8)\n","Dataset: label 8 - train - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-1.chunk-32.train.csv ...\n","Dataset: label 8 - train - 1308376 chunks - 11.2 Gb\n","Dataset: label 0 - eval - in model as torch.tensor(0)\n","Dataset: label 0 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 0 - eval - 377643 chunks - 3.07 Gb\n","Dataset: label 1 - eval - in model as torch.tensor(1)\n","Dataset: label 1 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 1 - eval - 422037 chunks - 3.45 Gb\n","Dataset: label 2 - eval - in model as torch.tensor(2)\n","Dataset: label 2 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 2 - eval - 91220 chunks - 0.75 Gb\n","Dataset: label 3 - eval - in model as torch.tensor(3)\n","Dataset: label 3 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 3 - eval - 18165 chunks - 0.14 Gb\n","Dataset: label 4 - eval - in model as torch.tensor(4)\n","Dataset: label 4 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 4 - eval - 3125 chunks - 0.02 Gb\n","Dataset: label 5 - eval - in model as torch.tensor(5)\n","Dataset: label 5 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 5 - eval - 75007 chunks - 0.59 Gb\n","Dataset: label 6 - eval - in model as torch.tensor(6)\n","Dataset: label 6 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 6 - eval - 10356 chunks - 0.08 Gb\n","Dataset: label 7 - eval - in model as torch.tensor(7)\n","Dataset: label 7 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 7 - eval - 111166 chunks - 0.94 Gb\n","Dataset: label 8 - eval - in model as torch.tensor(8)\n","Dataset: label 8 - eval - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-102400.fold-1.chunk-32.eval.csv ...\n","Dataset: label 8 - eval - 150907 chunks - 1.19 Gb\n","Model: looking for /content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.fold-1.chunk-32.epochs-6.batch-160/model\n","Model: using cached model...\n","Loading model from /content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.fold-1.chunk-32.epochs-6.batch-160/partial/checkpoint-159000.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 10297520\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 160\n","  Total train batch size (w. parallel, distributed & accumulation) = 160\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 386160\n","  Number of trainable parameters = 124446720\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 2\n","  Continuing training from global step 159000\n","  Will skip the first 2 epochs then the first 30280 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n","Skipping the first batches:   0% 0/30280 [00:00<?, ?it/s]\n","Skipping the first batches: 100% 30280/30280 [02:39<00:00, 190.13it/s]\n","\n"," 41% 159001/386160 [02:44<03:54, 969.37it/s]\u001b[A\n"," 41% 159017/386160 [02:59<03:54, 969.37it/s]\u001b[A\n"," 41% 159018/386160 [03:00<04:27, 850.61it/s]\u001b[A\n"," 41% 159019/386160 [03:01<04:29, 841.79it/s]\u001b[A\n"," 41% 159020/386160 [03:01<04:33, 829.50it/s]\u001b[A\n"," 41% 159021/386160 [03:02<04:39, 812.63it/s]\u001b[A\n"," 41% 159022/386160 [03:03<04:47, 789.45it/s]\u001b[A\n"," 41% 159023/386160 [03:04<04:59, 758.79it/s]\u001b[A\n"," 41% 159024/386160 [03:05<05:16, 718.43it/s]\u001b[A\n"," 41% 159025/386160 [03:06<05:40, 667.28it/s]\u001b[A\n"," 41% 159026/386160 [03:07<06:14, 606.02it/s]\u001b[A\n"," 41% 159027/386160 [03:08<07:03, 536.26it/s]\u001b[A\n"," 41% 159028/386160 [03:09<08:12, 460.78it/s]\u001b[A\n"," 41% 159029/386160 [03:10<09:52, 383.57it/s]\u001b[A\n"," 41% 159030/386160 [03:11<12:13, 309.80it/s]\u001b[A\n"," 41% 159031/386160 [03:12<15:34, 243.13it/s]\u001b[A\n"," 41% 159032/386160 [03:13<20:19, 186.29it/s]\u001b[A\n"," 41% 159033/386160 [03:14<27:04, 139.85it/s]\u001b[A\n"," 41% 159034/386160 [03:15<36:39, 103.24it/s]\u001b[A\n"," 41% 159035/386160 [03:16<50:14, 75.35it/s] \u001b[A\n"," 41% 159036/386160 [03:17<1:09:25, 54.53it/s]\u001b[A\n"," 41% 159037/386160 [03:18<1:36:27, 39.24it/s]\u001b[A\n"," 41% 159038/386160 [03:19<2:14:36, 28.12it/s]\u001b[A\n"," 41% 159039/386160 [03:20<3:07:12, 20.22it/s]\u001b[A\n"," 41% 159040/386160 [03:21<4:19:49, 14.57it/s]\u001b[A\n"," 41% 159041/386160 [03:22<5:57:48, 10.58it/s]\u001b[A\n"," 41% 159042/386160 [03:23<8:08:17,  7.75it/s]\u001b[A\n"," 41% 159043/386160 [03:24<10:56:26,  5.77it/s]\u001b[A\n"," 41% 159044/386160 [03:24<14:27:40,  4.36it/s]\u001b[A\n"," 41% 159045/386160 [03:25<18:39:38,  3.38it/s]\u001b[A\n"," 41% 159046/386160 [03:26<23:31:56,  2.68it/s]\u001b[A\n"," 41% 159047/386160 [03:27<28:40:46,  2.20it/s]\u001b[A\n"," 41% 159048/386160 [03:28<33:56:00,  1.86it/s]\u001b[A\n"," 41% 159049/386160 [03:29<38:51:52,  1.62it/s]\u001b[A\n"," 41% 159050/386160 [03:30<43:17:28,  1.46it/s]\u001b[A\n"," 41% 159051/386160 [03:31<47:02:05,  1.34it/s]\u001b[A\n"," 41% 159052/386160 [03:32<50:05:15,  1.26it/s]\u001b[A\n"," 41% 159053/386160 [03:33<55:44:04,  1.13it/s]\u001b[A\n"," 41% 159054/386160 [03:34<56:35:08,  1.11it/s]\u001b[A\n"," 41% 159055/386160 [03:35<57:18:32,  1.10it/s]\u001b[A\n"," 41% 159056/386160 [03:36<57:42:27,  1.09it/s]\u001b[A\n"," 41% 159057/386160 [03:37<58:00:43,  1.09it/s]\u001b[A\n"," 41% 159058/386160 [03:38<58:17:07,  1.08it/s]\u001b[A\n"," 41% 159059/386160 [03:39<58:29:07,  1.08it/s]\u001b[A\n"," 41% 159060/386160 [03:40<58:33:02,  1.08it/s]\u001b[A\n"," 41% 159061/386160 [03:41<58:23:18,  1.08it/s]\u001b[A\n"," 41% 159062/386160 [03:41<58:27:09,  1.08it/s]\u001b[A\n"," 41% 159063/386160 [03:42<58:38:10,  1.08it/s]\u001b[A\n"," 41% 159064/386160 [03:43<58:35:41,  1.08it/s]\u001b[A\n"," 41% 159065/386160 [03:44<58:35:05,  1.08it/s]\u001b[A\n"," 41% 159066/386160 [03:45<58:32:43,  1.08it/s]\u001b[A\n"," 41% 159067/386160 [03:46<58:34:42,  1.08it/s]\u001b[A\n"," 41% 159068/386160 [03:47<58:38:20,  1.08it/s]\u001b[A\n"," 41% 159069/386160 [03:48<58:52:10,  1.07it/s]\u001b[A\n"," 41% 159070/386160 [03:49<58:48:08,  1.07it/s]\u001b[A\n"," 41% 159071/386160 [03:50<58:46:11,  1.07it/s]\u001b[A\n"," 41% 159072/386160 [03:51<58:41:31,  1.07it/s]\u001b[A\n"," 41% 159073/386160 [03:52<58:44:31,  1.07it/s]\u001b[A\n"," 41% 159074/386160 [03:53<58:33:15,  1.08it/s]\u001b[A\n"," 41% 159075/386160 [03:54<58:31:41,  1.08it/s]\u001b[A\n"," 41% 159076/386160 [03:54<58:27:26,  1.08it/s]\u001b[A\n"," 41% 159077/386160 [03:55<58:32:36,  1.08it/s]\u001b[A\n"," 41% 159078/386160 [03:56<58:29:56,  1.08it/s]\u001b[A\n"," 41% 159079/386160 [03:57<58:25:36,  1.08it/s]\u001b[A\n"," 41% 159080/386160 [03:58<58:25:10,  1.08it/s]\u001b[A\n"," 41% 159081/386160 [03:59<58:37:04,  1.08it/s]\u001b[A\n"," 41% 159082/386160 [04:00<58:46:03,  1.07it/s]\u001b[A\n"," 41% 159083/386160 [04:01<58:41:42,  1.07it/s]\u001b[A\n"," 41% 159084/386160 [04:02<58:40:01,  1.08it/s]\u001b[A\n"," 41% 159085/386160 [04:03<58:36:44,  1.08it/s]\u001b[A\n"," 41% 159086/386160 [04:04<58:40:24,  1.08it/s]\u001b[A\n"," 41% 159087/386160 [04:05<58:42:49,  1.07it/s]\u001b[A\n"," 41% 159088/386160 [04:06<58:41:07,  1.07it/s]\u001b[A\n"," 41% 159089/386160 [04:07<58:43:29,  1.07it/s]\u001b[A\n"," 41% 159090/386160 [04:08<58:46:20,  1.07it/s]\u001b[A\n"," 41% 159091/386160 [04:08<58:44:06,  1.07it/s]\u001b[A\n"," 41% 159092/386160 [04:09<58:48:28,  1.07it/s]\u001b[A\n"," 41% 159093/386160 [04:10<58:48:08,  1.07it/s]\u001b[A\n"," 41% 159094/386160 [04:11<58:55:24,  1.07it/s]\u001b[A\n"," 41% 159095/386160 [04:12<58:58:01,  1.07it/s]\u001b[A\n"," 41% 159096/386160 [04:13<58:55:46,  1.07it/s]\u001b[A\n"," 41% 159097/386160 [04:14<58:58:55,  1.07it/s]\u001b[A\n"," 41% 159098/386160 [04:15<58:59:27,  1.07it/s]\u001b[A\n"," 41% 159099/386160 [04:16<58:58:04,  1.07it/s]\u001b[A\n"," 41% 159100/386160 [04:17<58:56:26,  1.07it/s]\u001b[A\n"," 41% 159101/386160 [04:18<58:53:41,  1.07it/s]\u001b[A\n"," 41% 159102/386160 [04:19<58:51:17,  1.07it/s]\u001b[A\n"," 41% 159103/386160 [04:20<58:51:42,  1.07it/s]\u001b[A\n"," 41% 159104/386160 [04:21<58:48:58,  1.07it/s]\u001b[A\n"," 41% 159105/386160 [04:22<58:52:37,  1.07it/s]\u001b[A\n"," 41% 159106/386160 [04:22<58:52:37,  1.07it/s]\u001b[A\n"," 41% 159107/386160 [04:23<58:55:05,  1.07it/s]\u001b[A\n"," 41% 159108/386160 [04:24<58:57:38,  1.07it/s]\u001b[A\n"," 41% 159109/386160 [04:25<59:00:12,  1.07it/s]\u001b[A\n"," 41% 159110/386160 [04:26<58:59:42,  1.07it/s]\u001b[A\n"," 41% 159111/386160 [04:27<58:58:34,  1.07it/s]\u001b[A\n"," 41% 159112/386160 [04:28<58:58:16,  1.07it/s]\u001b[A\n"," 41% 159113/386160 [04:29<59:21:09,  1.06it/s]\u001b[A\n"," 41% 159114/386160 [04:30<60:15:23,  1.05it/s]\u001b[A\n"," 41% 159115/386160 [04:31<60:58:42,  1.03it/s]\u001b[A\n"," 41% 159116/386160 [04:32<61:19:24,  1.03it/s]\u001b[A\n"," 41% 159117/386160 [04:33<61:54:52,  1.02it/s]\u001b[A\n"," 41% 159118/386160 [04:34<62:21:03,  1.01it/s]\u001b[A\n"," 41% 159119/386160 [04:35<61:51:30,  1.02it/s]\u001b[A\n"," 41% 159120/386160 [04:36<61:10:09,  1.03it/s]\u001b[A\n"," 41% 159121/386160 [04:37<60:33:43,  1.04it/s]\u001b[A\n"," 41% 159122/386160 [04:38<60:06:45,  1.05it/s]\u001b[A\n"," 41% 159123/386160 [04:39<59:46:34,  1.06it/s]\u001b[A\n"," 41% 159124/386160 [04:40<59:39:34,  1.06it/s]\u001b[A\n"," 41% 159125/386160 [04:41<59:35:13,  1.06it/s]\u001b[A\n"," 41% 159126/386160 [04:42<59:26:03,  1.06it/s]\u001b[A\n"," 41% 159127/386160 [04:42<59:17:20,  1.06it/s]\u001b[A\n"," 41% 159128/386160 [04:43<59:13:29,  1.06it/s]\u001b[A\n"," 41% 159129/386160 [04:44<59:19:19,  1.06it/s]\u001b[A\n"," 41% 159130/386160 [04:45<59:18:54,  1.06it/s]\u001b[A\n"," 41% 159131/386160 [04:46<59:17:41,  1.06it/s]\u001b[A\n"," 41% 159132/386160 [04:47<59:16:39,  1.06it/s]\u001b[A\n"," 41% 159133/386160 [04:48<59:14:33,  1.06it/s]\u001b[A\n"," 41% 159134/386160 [04:49<59:11:22,  1.07it/s]\u001b[A\n"," 41% 159135/386160 [04:50<59:12:09,  1.07it/s]\u001b[A\n"," 41% 159136/386160 [04:51<59:20:08,  1.06it/s]\u001b[A\n"," 41% 159137/386160 [04:52<59:15:36,  1.06it/s]\u001b[A\n"," 41% 159138/386160 [04:53<59:09:43,  1.07it/s]\u001b[A\n"," 41% 159139/386160 [04:54<59:11:16,  1.07it/s]\u001b[A\n"," 41% 159140/386160 [04:55<59:14:13,  1.06it/s]\u001b[A\n"," 41% 159141/386160 [04:56<59:09:28,  1.07it/s]\u001b[A\n"," 41% 159142/386160 [04:57<59:06:28,  1.07it/s]\u001b[A\n"," 41% 159143/386160 [04:58<59:17:40,  1.06it/s]\u001b[A\n"," 41% 159144/386160 [04:58<59:08:35,  1.07it/s]\u001b[A\n"," 41% 159145/386160 [04:59<59:08:32,  1.07it/s]\u001b[A\n"," 41% 159146/386160 [05:00<59:10:51,  1.07it/s]\u001b[A\n"," 41% 159147/386160 [05:01<59:09:43,  1.07it/s]\u001b[A\n"," 41% 159148/386160 [05:02<59:08:44,  1.07it/s]\u001b[A\n"," 41% 159149/386160 [05:03<59:08:03,  1.07it/s]\u001b[A\n"," 41% 159150/386160 [05:04<59:07:04,  1.07it/s]\u001b[A\n"," 41% 159151/386160 [05:05<59:05:35,  1.07it/s]\u001b[A\n"," 41% 159152/386160 [05:06<59:08:02,  1.07it/s]\u001b[A\n"," 41% 159153/386160 [05:07<59:15:10,  1.06it/s]\u001b[A\n"," 41% 159154/386160 [05:08<59:12:54,  1.06it/s]\u001b[A\n"," 41% 159155/386160 [05:09<59:06:31,  1.07it/s]\u001b[A\n"," 41% 159156/386160 [05:10<59:00:52,  1.07it/s]\u001b[A\n"," 41% 159157/386160 [05:11<59:03:22,  1.07it/s]\u001b[A\n"," 41% 159158/386160 [05:12<59:13:13,  1.06it/s]\u001b[A\n"," 41% 159159/386160 [05:13<59:10:59,  1.07it/s]\u001b[A\n"," 41% 159160/386160 [05:13<59:07:47,  1.07it/s]\u001b[A\n"," 41% 159161/386160 [05:14<59:06:56,  1.07it/s]\u001b[A\n"," 41% 159162/386160 [05:15<59:06:05,  1.07it/s]\u001b[A\n"," 41% 159163/386160 [05:16<58:58:34,  1.07it/s]\u001b[A\n"," 41% 159164/386160 [05:17<58:54:41,  1.07it/s]\u001b[A\n"," 41% 159165/386160 [05:18<58:49:21,  1.07it/s]\u001b[A\n"," 41% 159166/386160 [05:19<58:49:48,  1.07it/s]\u001b[A\n"," 41% 159167/386160 [05:20<58:54:30,  1.07it/s]\u001b[A\n"," 41% 159168/386160 [05:21<58:51:47,  1.07it/s]\u001b[A\n"," 41% 159169/386160 [05:22<58:50:51,  1.07it/s]\u001b[A\n"," 41% 159170/386160 [05:23<59:01:48,  1.07it/s]\u001b[A\n"," 41% 159171/386160 [05:24<58:55:52,  1.07it/s]\u001b[A\n"," 41% 159172/386160 [05:25<58:55:37,  1.07it/s]\u001b[A\n"," 41% 159173/386160 [05:26<58:52:50,  1.07it/s]\u001b[A\n"," 41% 159174/386160 [05:27<58:49:22,  1.07it/s]\u001b[A\n"," 41% 159175/386160 [05:27<58:50:05,  1.07it/s]\u001b[A\n"," 41% 159176/386160 [05:28<58:47:33,  1.07it/s]\u001b[A\n"," 41% 159177/386160 [05:29<58:44:15,  1.07it/s]\u001b[A\n"," 41% 159178/386160 [05:30<58:48:55,  1.07it/s]\u001b[A\n"," 41% 159179/386160 [05:31<58:46:22,  1.07it/s]\u001b[A\n"," 41% 159180/386160 [05:32<58:50:18,  1.07it/s]\u001b[A\n"," 41% 159181/386160 [05:33<58:49:26,  1.07it/s]\u001b[A\n"," 41% 159182/386160 [05:34<58:54:07,  1.07it/s]\u001b[A\n"," 41% 159183/386160 [05:35<58:55:22,  1.07it/s]\u001b[A\n"," 41% 159184/386160 [05:36<58:54:11,  1.07it/s]\u001b[A\n"," 41% 159185/386160 [05:37<58:56:33,  1.07it/s]\u001b[A\n"," 41% 159186/386160 [05:38<58:55:45,  1.07it/s]\u001b[A\n"," 41% 159187/386160 [05:39<58:51:53,  1.07it/s]\u001b[A\n"," 41% 159188/386160 [05:40<58:49:03,  1.07it/s]\u001b[A\n"," 41% 159189/386160 [05:41<58:51:41,  1.07it/s]\u001b[A\n"," 41% 159190/386160 [05:41<58:55:29,  1.07it/s]\u001b[A\n"," 41% 159191/386160 [05:42<58:52:47,  1.07it/s]\u001b[A\n"," 41% 159192/386160 [05:43<58:57:21,  1.07it/s]\u001b[A\n"," 41% 159193/386160 [05:44<58:57:07,  1.07it/s]\u001b[A\n"," 41% 159194/386160 [05:45<59:00:02,  1.07it/s]\u001b[A\n"," 41% 159195/386160 [05:46<58:59:19,  1.07it/s]\u001b[A\n"," 41% 159196/386160 [05:47<58:55:39,  1.07it/s]\u001b[A\n"," 41% 159197/386160 [05:48<58:54:42,  1.07it/s]\u001b[A\n"," 41% 159198/386160 [05:49<58:53:08,  1.07it/s]\u001b[A\n"," 41% 159199/386160 [05:50<58:53:35,  1.07it/s]\u001b[A\n"," 41% 159200/386160 [05:51<58:54:18,  1.07it/s]\u001b[A\n"," 41% 159201/386160 [05:52<58:56:22,  1.07it/s]\u001b[A\n"," 41% 159202/386160 [05:53<58:52:45,  1.07it/s]\u001b[A\n"," 41% 159203/386160 [05:54<58:54:41,  1.07it/s]\u001b[A\n"," 41% 159204/386160 [05:55<58:56:02,  1.07it/s]\u001b[A\n"," 41% 159205/386160 [05:55<58:54:17,  1.07it/s]\u001b[A\n"," 41% 159206/386160 [05:56<58:54:26,  1.07it/s]\u001b[A\n"," 41% 159207/386160 [05:57<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159208/386160 [05:58<58:54:24,  1.07it/s]\u001b[A\n"," 41% 159209/386160 [05:59<58:59:08,  1.07it/s]\u001b[A\n"," 41% 159210/386160 [06:00<58:59:15,  1.07it/s]\u001b[A\n"," 41% 159211/386160 [06:01<58:56:26,  1.07it/s]\u001b[A\n"," 41% 159212/386160 [06:02<58:58:12,  1.07it/s]\u001b[A\n"," 41% 159213/386160 [06:03<59:01:33,  1.07it/s]\u001b[A\n"," 41% 159214/386160 [06:04<58:57:50,  1.07it/s]\u001b[A\n"," 41% 159215/386160 [06:05<58:59:27,  1.07it/s]\u001b[A\n"," 41% 159216/386160 [06:06<59:00:11,  1.07it/s]\u001b[A\n"," 41% 159217/386160 [06:07<58:59:32,  1.07it/s]\u001b[A\n"," 41% 159218/386160 [06:08<59:02:30,  1.07it/s]\u001b[A\n"," 41% 159219/386160 [06:09<59:01:39,  1.07it/s]\u001b[A\n"," 41% 159220/386160 [06:10<59:05:18,  1.07it/s]\u001b[A\n"," 41% 159221/386160 [06:10<59:05:46,  1.07it/s]\u001b[A\n"," 41% 159222/386160 [06:11<59:04:07,  1.07it/s]\u001b[A\n"," 41% 159223/386160 [06:12<59:00:57,  1.07it/s]\u001b[A\n"," 41% 159224/386160 [06:13<59:02:14,  1.07it/s]\u001b[A\n"," 41% 159225/386160 [06:14<59:05:47,  1.07it/s]\u001b[A\n"," 41% 159226/386160 [06:15<59:02:23,  1.07it/s]\u001b[A\n"," 41% 159227/386160 [06:16<59:04:02,  1.07it/s]\u001b[A\n"," 41% 159228/386160 [06:17<59:07:35,  1.07it/s]\u001b[A\n"," 41% 159229/386160 [06:18<59:02:29,  1.07it/s]\u001b[A\n"," 41% 159230/386160 [06:19<59:03:02,  1.07it/s]\u001b[A\n"," 41% 159231/386160 [06:20<59:04:57,  1.07it/s]\u001b[A\n"," 41% 159232/386160 [06:21<59:04:41,  1.07it/s]\u001b[A\n"," 41% 159233/386160 [06:22<59:01:50,  1.07it/s]\u001b[A\n"," 41% 159234/386160 [06:23<59:01:03,  1.07it/s]\u001b[A\n"," 41% 159235/386160 [06:24<58:59:52,  1.07it/s]\u001b[A\n"," 41% 159236/386160 [06:24<59:00:59,  1.07it/s]\u001b[A\n"," 41% 159237/386160 [06:25<59:14:17,  1.06it/s]\u001b[A\n"," 41% 159238/386160 [06:26<59:13:49,  1.06it/s]\u001b[A\n"," 41% 159239/386160 [06:27<59:41:11,  1.06it/s]\u001b[A\n"," 41% 159240/386160 [06:28<60:36:28,  1.04it/s]\u001b[A\n"," 41% 159241/386160 [06:29<60:35:33,  1.04it/s]\u001b[A\n"," 41% 159242/386160 [06:30<61:04:28,  1.03it/s]\u001b[A\n"," 41% 159243/386160 [06:31<61:36:59,  1.02it/s]\u001b[A\n"," 41% 159244/386160 [06:32<61:17:44,  1.03it/s]\u001b[A\n"," 41% 159245/386160 [06:33<60:36:05,  1.04it/s]\u001b[A\n"," 41% 159246/386160 [06:34<60:05:56,  1.05it/s]\u001b[A\n"," 41% 159247/386160 [06:35<59:46:42,  1.05it/s]\u001b[A\n"," 41% 159248/386160 [06:36<59:35:25,  1.06it/s]\u001b[A\n"," 41% 159249/386160 [06:37<59:27:34,  1.06it/s]\u001b[A\n"," 41% 159250/386160 [06:38<59:22:27,  1.06it/s]\u001b[A\n"," 41% 159251/386160 [06:39<59:14:23,  1.06it/s]\u001b[A\n"," 41% 159252/386160 [06:40<59:14:45,  1.06it/s]\u001b[A\n"," 41% 159253/386160 [06:41<59:11:12,  1.06it/s]\u001b[A\n"," 41% 159254/386160 [06:42<59:05:38,  1.07it/s]\u001b[A\n"," 41% 159255/386160 [06:43<59:00:32,  1.07it/s]\u001b[A\n"," 41% 159256/386160 [06:43<59:00:24,  1.07it/s]\u001b[A\n"," 41% 159257/386160 [06:44<59:04:31,  1.07it/s]\u001b[A\n"," 41% 159258/386160 [06:45<59:02:49,  1.07it/s]\u001b[A\n"," 41% 159259/386160 [06:46<59:04:27,  1.07it/s]\u001b[A\n"," 41% 159260/386160 [06:47<59:04:27,  1.07it/s]\u001b[A\n"," 41% 159261/386160 [06:48<59:06:07,  1.07it/s]\u001b[A\n"," 41% 159262/386160 [06:49<59:10:02,  1.07it/s]\u001b[A\n"," 41% 159263/386160 [06:50<59:06:07,  1.07it/s]\u001b[A\n"," 41% 159264/386160 [06:51<59:06:15,  1.07it/s]\u001b[A\n"," 41% 159265/386160 [06:52<59:16:24,  1.06it/s]\u001b[A\n"," 41% 159266/386160 [06:53<59:16:16,  1.06it/s]\u001b[A\n"," 41% 159267/386160 [06:54<59:09:11,  1.07it/s]\u001b[A\n"," 41% 159268/386160 [06:55<59:07:41,  1.07it/s]\u001b[A\n"," 41% 159269/386160 [06:56<59:05:10,  1.07it/s]\u001b[A\n"," 41% 159270/386160 [06:57<59:01:41,  1.07it/s]\u001b[A\n"," 41% 159271/386160 [06:58<59:10:00,  1.07it/s]\u001b[A\n"," 41% 159272/386160 [06:59<59:03:02,  1.07it/s]\u001b[A\n"," 41% 159273/386160 [06:59<59:00:07,  1.07it/s]\u001b[A\n"," 41% 159274/386160 [07:00<59:04:32,  1.07it/s]\u001b[A\n"," 41% 159275/386160 [07:01<58:57:47,  1.07it/s]\u001b[A\n"," 41% 159276/386160 [07:02<58:59:41,  1.07it/s]\u001b[A\n"," 41% 159277/386160 [07:03<59:01:56,  1.07it/s]\u001b[A\n"," 41% 159278/386160 [07:04<58:58:11,  1.07it/s]\u001b[A\n"," 41% 159279/386160 [07:05<58:54:01,  1.07it/s]\u001b[A\n"," 41% 159280/386160 [07:06<58:58:53,  1.07it/s]\u001b[A\n"," 41% 159281/386160 [07:07<58:55:36,  1.07it/s]\u001b[A\n"," 41% 159282/386160 [07:08<58:52:50,  1.07it/s]\u001b[A\n"," 41% 159283/386160 [07:09<59:00:40,  1.07it/s]\u001b[A\n"," 41% 159284/386160 [07:10<59:04:30,  1.07it/s]\u001b[A\n"," 41% 159285/386160 [07:11<59:01:49,  1.07it/s]\u001b[A\n"," 41% 159286/386160 [07:12<59:00:31,  1.07it/s]\u001b[A\n"," 41% 159287/386160 [07:13<58:55:51,  1.07it/s]\u001b[A\n"," 41% 159288/386160 [07:13<58:58:05,  1.07it/s]\u001b[A\n"," 41% 159289/386160 [07:14<59:03:14,  1.07it/s]\u001b[A\n"," 41% 159290/386160 [07:15<59:07:33,  1.07it/s]\u001b[A\n"," 41% 159291/386160 [07:16<59:09:47,  1.07it/s]\u001b[A\n"," 41% 159292/386160 [07:17<59:10:30,  1.06it/s]\u001b[A\n"," 41% 159293/386160 [07:18<59:08:00,  1.07it/s]\u001b[A\n"," 41% 159294/386160 [07:19<59:16:02,  1.06it/s]\u001b[A\n"," 41% 159295/386160 [07:20<59:12:50,  1.06it/s]\u001b[A\n"," 41% 159296/386160 [07:21<59:07:45,  1.07it/s]\u001b[A\n"," 41% 159297/386160 [07:22<59:08:30,  1.07it/s]\u001b[A\n"," 41% 159298/386160 [07:23<59:17:33,  1.06it/s]\u001b[A\n"," 41% 159299/386160 [07:24<59:07:02,  1.07it/s]\u001b[A\n"," 41% 159300/386160 [07:25<59:02:10,  1.07it/s]\u001b[A\n"," 41% 159301/386160 [07:26<59:03:59,  1.07it/s]\u001b[A\n"," 41% 159302/386160 [07:27<59:10:16,  1.06it/s]\u001b[A\n"," 41% 159303/386160 [07:28<59:11:44,  1.06it/s]\u001b[A\n"," 41% 159304/386160 [07:28<59:11:24,  1.06it/s]\u001b[A\n"," 41% 159305/386160 [07:29<59:07:56,  1.07it/s]\u001b[A\n"," 41% 159306/386160 [07:30<59:04:53,  1.07it/s]\u001b[A\n"," 41% 159307/386160 [07:31<58:59:18,  1.07it/s]\u001b[A\n"," 41% 159308/386160 [07:32<58:59:40,  1.07it/s]\u001b[A\n"," 41% 159309/386160 [07:33<59:01:23,  1.07it/s]\u001b[A\n"," 41% 159310/386160 [07:34<59:10:05,  1.06it/s]\u001b[A\n"," 41% 159311/386160 [07:35<59:06:41,  1.07it/s]\u001b[A\n"," 41% 159312/386160 [07:36<59:08:54,  1.07it/s]\u001b[A\n"," 41% 159313/386160 [07:37<59:07:07,  1.07it/s]\u001b[A\n"," 41% 159314/386160 [07:38<59:04:37,  1.07it/s]\u001b[A\n"," 41% 159315/386160 [07:39<59:06:40,  1.07it/s]\u001b[A\n"," 41% 159316/386160 [07:40<59:09:21,  1.07it/s]\u001b[A\n"," 41% 159317/386160 [07:41<59:04:43,  1.07it/s]\u001b[A\n"," 41% 159318/386160 [07:42<59:02:45,  1.07it/s]\u001b[A\n"," 41% 159319/386160 [07:43<59:08:50,  1.07it/s]\u001b[A\n"," 41% 159320/386160 [07:44<59:05:12,  1.07it/s]\u001b[A\n"," 41% 159321/386160 [07:44<58:59:26,  1.07it/s]\u001b[A\n"," 41% 159322/386160 [07:45<59:03:57,  1.07it/s]\u001b[A\n"," 41% 159323/386160 [07:46<58:59:36,  1.07it/s]\u001b[A\n"," 41% 159324/386160 [07:47<59:02:43,  1.07it/s]\u001b[A\n"," 41% 159325/386160 [07:48<59:04:31,  1.07it/s]\u001b[A\n"," 41% 159326/386160 [07:49<59:05:34,  1.07it/s]\u001b[A\n"," 41% 159327/386160 [07:50<59:10:53,  1.06it/s]\u001b[A\n"," 41% 159328/386160 [07:51<59:03:32,  1.07it/s]\u001b[A\n"," 41% 159329/386160 [07:52<58:58:49,  1.07it/s]\u001b[A\n"," 41% 159330/386160 [07:53<58:57:09,  1.07it/s]\u001b[A\n"," 41% 159331/386160 [07:54<58:54:10,  1.07it/s]\u001b[A\n"," 41% 159332/386160 [07:55<58:54:21,  1.07it/s]\u001b[A\n"," 41% 159333/386160 [07:56<59:02:34,  1.07it/s]\u001b[A\n"," 41% 159334/386160 [07:57<59:01:11,  1.07it/s]\u001b[A\n"," 41% 159335/386160 [07:58<58:59:02,  1.07it/s]\u001b[A\n"," 41% 159336/386160 [07:58<58:55:09,  1.07it/s]\u001b[A\n"," 41% 159337/386160 [07:59<58:58:32,  1.07it/s]\u001b[A\n"," 41% 159338/386160 [08:00<59:08:22,  1.07it/s]\u001b[A\n"," 41% 159339/386160 [08:01<59:03:32,  1.07it/s]\u001b[A\n"," 41% 159340/386160 [08:02<58:59:50,  1.07it/s]\u001b[A\n"," 41% 159341/386160 [08:03<58:56:31,  1.07it/s]\u001b[A\n"," 41% 159342/386160 [08:04<58:57:46,  1.07it/s]\u001b[A\n"," 41% 159343/386160 [08:05<59:02:17,  1.07it/s]\u001b[A\n"," 41% 159344/386160 [08:06<59:01:37,  1.07it/s]\u001b[A\n"," 41% 159345/386160 [08:07<59:00:48,  1.07it/s]\u001b[A\n"," 41% 159346/386160 [08:08<59:02:03,  1.07it/s]\u001b[A\n"," 41% 159347/386160 [08:09<58:53:45,  1.07it/s]\u001b[A\n"," 41% 159348/386160 [08:10<58:51:54,  1.07it/s]\u001b[A\n"," 41% 159349/386160 [08:11<58:58:25,  1.07it/s]\u001b[A\n"," 41% 159350/386160 [08:12<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159351/386160 [08:13<58:57:39,  1.07it/s]\u001b[A\n"," 41% 159352/386160 [08:13<58:55:04,  1.07it/s]\u001b[A\n"," 41% 159353/386160 [08:14<58:51:10,  1.07it/s]\u001b[A\n"," 41% 159354/386160 [08:15<58:50:48,  1.07it/s]\u001b[A\n"," 41% 159355/386160 [08:16<58:53:54,  1.07it/s]\u001b[A\n"," 41% 159356/386160 [08:17<58:48:31,  1.07it/s]\u001b[A\n"," 41% 159357/386160 [08:18<58:50:42,  1.07it/s]\u001b[A\n"," 41% 159358/386160 [08:19<58:58:18,  1.07it/s]\u001b[A\n"," 41% 159359/386160 [08:20<58:57:23,  1.07it/s]\u001b[A\n"," 41% 159360/386160 [08:21<59:13:43,  1.06it/s]\u001b[A\n"," 41% 159361/386160 [08:22<59:11:13,  1.06it/s]\u001b[A\n"," 41% 159362/386160 [08:23<59:10:14,  1.06it/s]\u001b[A\n"," 41% 159363/386160 [08:24<59:07:33,  1.07it/s]\u001b[A\n"," 41% 159364/386160 [08:25<59:24:42,  1.06it/s]\u001b[A\n"," 41% 159365/386160 [08:26<60:10:34,  1.05it/s]\u001b[A\n"," 41% 159366/386160 [08:27<60:31:23,  1.04it/s]\u001b[A\n"," 41% 159367/386160 [08:28<60:41:28,  1.04it/s]\u001b[A\n"," 41% 159368/386160 [08:29<61:03:49,  1.03it/s]\u001b[A\n"," 41% 159369/386160 [08:30<61:44:08,  1.02it/s]\u001b[A\n"," 41% 159370/386160 [08:31<61:06:18,  1.03it/s]\u001b[A\n"," 41% 159371/386160 [08:32<60:34:28,  1.04it/s]\u001b[A\n"," 41% 159372/386160 [08:32<60:00:34,  1.05it/s]\u001b[A\n"," 41% 159373/386160 [08:33<59:40:16,  1.06it/s]\u001b[A\n"," 41% 159374/386160 [08:34<59:23:17,  1.06it/s]\u001b[A\n"," 41% 159375/386160 [08:35<59:11:14,  1.06it/s]\u001b[A\n"," 41% 159376/386160 [08:36<59:02:26,  1.07it/s]\u001b[A\n"," 41% 159377/386160 [08:37<59:04:38,  1.07it/s]\u001b[A\n"," 41% 159378/386160 [08:38<59:07:26,  1.07it/s]\u001b[A\n"," 41% 159379/386160 [08:39<59:02:09,  1.07it/s]\u001b[A\n"," 41% 159380/386160 [08:40<58:59:44,  1.07it/s]\u001b[A\n"," 41% 159381/386160 [08:41<59:05:58,  1.07it/s]\u001b[A\n"," 41% 159382/386160 [08:42<59:18:12,  1.06it/s]\u001b[A\n"," 41% 159383/386160 [08:43<59:12:50,  1.06it/s]\u001b[A\n"," 41% 159384/386160 [08:44<59:05:30,  1.07it/s]\u001b[A\n"," 41% 159385/386160 [08:45<59:02:59,  1.07it/s]\u001b[A\n"," 41% 159386/386160 [08:46<58:59:29,  1.07it/s]\u001b[A\n"," 41% 159387/386160 [08:47<59:00:20,  1.07it/s]\u001b[A\n"," 41% 159388/386160 [08:47<58:59:12,  1.07it/s]\u001b[A\n"," 41% 159389/386160 [08:48<59:01:21,  1.07it/s]\u001b[A\n"," 41% 159390/386160 [08:49<58:58:02,  1.07it/s]\u001b[A\n"," 41% 159391/386160 [08:50<58:54:22,  1.07it/s]\u001b[A\n"," 41% 159392/386160 [08:51<58:52:52,  1.07it/s]\u001b[A\n"," 41% 159393/386160 [08:52<58:56:26,  1.07it/s]\u001b[A\n"," 41% 159394/386160 [08:53<58:58:37,  1.07it/s]\u001b[A\n"," 41% 159395/386160 [08:54<59:04:50,  1.07it/s]\u001b[A\n"," 41% 159396/386160 [08:55<58:57:40,  1.07it/s]\u001b[A\n"," 41% 159397/386160 [08:56<58:59:37,  1.07it/s]\u001b[A\n"," 41% 159398/386160 [08:57<59:01:44,  1.07it/s]\u001b[A\n"," 41% 159399/386160 [08:58<58:55:09,  1.07it/s]\u001b[A\n"," 41% 159400/386160 [08:59<58:50:55,  1.07it/s]\u001b[A\n"," 41% 159401/386160 [09:00<58:51:13,  1.07it/s]\u001b[A\n"," 41% 159402/386160 [09:01<58:47:15,  1.07it/s]\u001b[A\n"," 41% 159403/386160 [09:01<58:47:54,  1.07it/s]\u001b[A\n"," 41% 159404/386160 [09:02<58:46:58,  1.07it/s]\u001b[A\n"," 41% 159405/386160 [09:03<58:45:22,  1.07it/s]\u001b[A\n"," 41% 159406/386160 [09:04<58:47:55,  1.07it/s]\u001b[A\n"," 41% 159407/386160 [09:05<58:49:47,  1.07it/s]\u001b[A\n"," 41% 159408/386160 [09:06<58:48:05,  1.07it/s]\u001b[A\n"," 41% 159409/386160 [09:07<58:48:18,  1.07it/s]\u001b[A\n"," 41% 159410/386160 [09:08<58:44:47,  1.07it/s]\u001b[A\n"," 41% 159411/386160 [09:09<58:45:34,  1.07it/s]\u001b[A\n"," 41% 159412/386160 [09:10<58:48:15,  1.07it/s]\u001b[A\n"," 41% 159413/386160 [09:11<58:48:06,  1.07it/s]\u001b[A\n"," 41% 159414/386160 [09:12<58:48:31,  1.07it/s]\u001b[A\n"," 41% 159415/386160 [09:13<58:48:28,  1.07it/s]\u001b[A\n"," 41% 159416/386160 [09:14<58:52:19,  1.07it/s]\u001b[A\n"," 41% 159417/386160 [09:15<58:53:17,  1.07it/s]\u001b[A\n"," 41% 159418/386160 [09:15<59:00:26,  1.07it/s]\u001b[A\n"," 41% 159419/386160 [09:16<58:57:20,  1.07it/s]\u001b[A\n"," 41% 159420/386160 [09:17<59:00:49,  1.07it/s]\u001b[A\n"," 41% 159421/386160 [09:18<59:04:15,  1.07it/s]\u001b[A\n"," 41% 159422/386160 [09:19<58:58:32,  1.07it/s]\u001b[A\n"," 41% 159423/386160 [09:20<58:55:09,  1.07it/s]\u001b[A\n"," 41% 159424/386160 [09:21<58:59:57,  1.07it/s]\u001b[A\n"," 41% 159425/386160 [09:22<59:05:52,  1.07it/s]\u001b[A\n"," 41% 159426/386160 [09:23<59:01:42,  1.07it/s]\u001b[A\n"," 41% 159427/386160 [09:24<59:12:56,  1.06it/s]\u001b[A\n"," 41% 159428/386160 [09:25<59:15:40,  1.06it/s]\u001b[A\n"," 41% 159429/386160 [09:26<59:06:23,  1.07it/s]\u001b[A\n"," 41% 159430/386160 [09:27<59:04:37,  1.07it/s]\u001b[A\n"," 41% 159431/386160 [09:28<59:12:38,  1.06it/s]\u001b[A\n"," 41% 159432/386160 [09:29<59:08:38,  1.06it/s]\u001b[A\n"," 41% 159433/386160 [09:30<59:15:22,  1.06it/s]\u001b[A\n"," 41% 159434/386160 [09:31<59:13:18,  1.06it/s]\u001b[A\n"," 41% 159435/386160 [09:31<59:09:43,  1.06it/s]\u001b[A\n"," 41% 159436/386160 [09:32<59:13:59,  1.06it/s]\u001b[A\n"," 41% 159437/386160 [09:33<59:11:04,  1.06it/s]\u001b[A\n"," 41% 159438/386160 [09:34<59:24:45,  1.06it/s]\u001b[A\n"," 41% 159439/386160 [09:35<59:19:27,  1.06it/s]\u001b[A\n"," 41% 159440/386160 [09:36<59:16:53,  1.06it/s]\u001b[A\n"," 41% 159441/386160 [09:37<59:18:21,  1.06it/s]\u001b[A\n"," 41% 159442/386160 [09:38<59:12:56,  1.06it/s]\u001b[A\n"," 41% 159443/386160 [09:39<59:12:47,  1.06it/s]\u001b[A\n"," 41% 159444/386160 [09:40<59:13:01,  1.06it/s]\u001b[A\n"," 41% 159445/386160 [09:41<59:08:30,  1.06it/s]\u001b[A\n"," 41% 159446/386160 [09:42<59:04:15,  1.07it/s]\u001b[A\n"," 41% 159447/386160 [09:43<59:10:10,  1.06it/s]\u001b[A\n"," 41% 159448/386160 [09:44<59:07:47,  1.07it/s]\u001b[A\n"," 41% 159449/386160 [09:45<59:03:58,  1.07it/s]\u001b[A\n"," 41% 159450/386160 [09:46<59:07:21,  1.07it/s]\u001b[A\n"," 41% 159451/386160 [09:46<59:03:11,  1.07it/s]\u001b[A\n"," 41% 159452/386160 [09:47<59:04:00,  1.07it/s]\u001b[A\n"," 41% 159453/386160 [09:48<59:05:59,  1.07it/s]\u001b[A\n"," 41% 159454/386160 [09:49<59:09:43,  1.06it/s]\u001b[A\n"," 41% 159455/386160 [09:50<59:10:34,  1.06it/s]\u001b[A\n"," 41% 159456/386160 [09:51<59:12:51,  1.06it/s]\u001b[A\n"," 41% 159457/386160 [09:52<59:12:34,  1.06it/s]\u001b[A\n"," 41% 159458/386160 [09:53<59:11:27,  1.06it/s]\u001b[A\n"," 41% 159459/386160 [09:54<59:09:19,  1.06it/s]\u001b[A\n"," 41% 159460/386160 [09:55<59:05:10,  1.07it/s]\u001b[A\n"," 41% 159461/386160 [09:56<59:10:32,  1.06it/s]\u001b[A\n"," 41% 159462/386160 [09:57<59:09:39,  1.06it/s]\u001b[A\n"," 41% 159463/386160 [09:58<59:03:45,  1.07it/s]\u001b[A\n"," 41% 159464/386160 [09:59<58:59:03,  1.07it/s]\u001b[A\n"," 41% 159465/386160 [10:00<58:53:10,  1.07it/s]\u001b[A\n"," 41% 159466/386160 [10:01<58:49:07,  1.07it/s]\u001b[A\n"," 41% 159467/386160 [10:01<58:52:05,  1.07it/s]\u001b[A\n"," 41% 159468/386160 [10:02<58:52:19,  1.07it/s]\u001b[A\n"," 41% 159469/386160 [10:03<58:57:45,  1.07it/s]\u001b[A\n"," 41% 159470/386160 [10:04<58:54:56,  1.07it/s]\u001b[A\n"," 41% 159471/386160 [10:05<58:54:12,  1.07it/s]\u001b[A\n"," 41% 159472/386160 [10:06<59:00:02,  1.07it/s]\u001b[A\n"," 41% 159473/386160 [10:07<58:56:04,  1.07it/s]\u001b[A\n"," 41% 159474/386160 [10:08<58:54:56,  1.07it/s]\u001b[A\n"," 41% 159475/386160 [10:09<58:52:21,  1.07it/s]\u001b[A\n"," 41% 159476/386160 [10:10<58:52:26,  1.07it/s]\u001b[A\n"," 41% 159477/386160 [10:11<58:49:37,  1.07it/s]\u001b[A\n"," 41% 159478/386160 [10:12<58:50:51,  1.07it/s]\u001b[A\n"," 41% 159479/386160 [10:13<58:51:02,  1.07it/s]\u001b[A\n"," 41% 159480/386160 [10:14<58:50:19,  1.07it/s]\u001b[A\n"," 41% 159481/386160 [10:15<58:51:10,  1.07it/s]\u001b[A\n"," 41% 159482/386160 [10:16<58:57:06,  1.07it/s]\u001b[A\n"," 41% 159483/386160 [10:16<58:53:54,  1.07it/s]\u001b[A\n"," 41% 159484/386160 [10:17<58:53:56,  1.07it/s]\u001b[A\n"," 41% 159485/386160 [10:18<58:53:56,  1.07it/s]\u001b[A\n"," 41% 159486/386160 [10:19<58:53:17,  1.07it/s]\u001b[A\n"," 41% 159487/386160 [10:20<58:52:44,  1.07it/s]\u001b[A\n"," 41% 159488/386160 [10:21<58:48:46,  1.07it/s]\u001b[A\n"," 41% 159489/386160 [10:22<58:50:35,  1.07it/s]\u001b[A\n"," 41% 159490/386160 [10:23<59:25:27,  1.06it/s]\u001b[A\n"," 41% 159491/386160 [10:24<59:49:43,  1.05it/s]\u001b[A\n"," 41% 159492/386160 [10:25<60:08:35,  1.05it/s]\u001b[A\n"," 41% 159493/386160 [10:26<60:45:09,  1.04it/s]\u001b[A\n"," 41% 159494/386160 [10:27<61:12:26,  1.03it/s]\u001b[A\n"," 41% 159495/386160 [10:28<61:03:13,  1.03it/s]\u001b[A\n"," 41% 159496/386160 [10:29<60:22:47,  1.04it/s]\u001b[A\n"," 41% 159497/386160 [10:30<59:52:29,  1.05it/s]\u001b[A\n"," 41% 159498/386160 [10:31<59:37:04,  1.06it/s]\u001b[A\n"," 41% 159499/386160 [10:32<59:19:45,  1.06it/s]\u001b[A\n"," 41% 159500/386160 [10:33<59:05:10,  1.07it/s]\u001b[A\n"," 41% 159501/386160 [10:33<59:00:01,  1.07it/s]\u001b[A\n"," 41% 159502/386160 [10:34<59:01:19,  1.07it/s]\u001b[A\n"," 41% 159503/386160 [10:35<58:58:20,  1.07it/s]\u001b[A\n"," 41% 159504/386160 [10:36<58:56:34,  1.07it/s]\u001b[A\n"," 41% 159505/386160 [10:37<59:01:35,  1.07it/s]\u001b[A\n"," 41% 159506/386160 [10:38<58:57:47,  1.07it/s]\u001b[A\n"," 41% 159507/386160 [10:39<58:56:12,  1.07it/s]\u001b[A\n"," 41% 159508/386160 [10:40<58:52:37,  1.07it/s]\u001b[A\n"," 41% 159509/386160 [10:41<58:48:33,  1.07it/s]\u001b[A\n"," 41% 159510/386160 [10:42<58:46:47,  1.07it/s]\u001b[A\n"," 41% 159511/386160 [10:43<58:45:49,  1.07it/s]\u001b[A\n"," 41% 159512/386160 [10:44<58:47:48,  1.07it/s]\u001b[A\n"," 41% 159513/386160 [10:45<58:46:02,  1.07it/s]\u001b[A\n"," 41% 159514/386160 [10:46<58:48:33,  1.07it/s]\u001b[A\n"," 41% 159515/386160 [10:47<58:46:46,  1.07it/s]\u001b[A\n"," 41% 159516/386160 [10:48<58:53:54,  1.07it/s]\u001b[A\n"," 41% 159517/386160 [10:48<58:51:34,  1.07it/s]\u001b[A\n"," 41% 159518/386160 [10:49<58:53:45,  1.07it/s]\u001b[A\n"," 41% 159519/386160 [10:50<59:03:08,  1.07it/s]\u001b[A\n"," 41% 159520/386160 [10:51<59:00:36,  1.07it/s]\u001b[A\n"," 41% 159521/386160 [10:52<58:57:27,  1.07it/s]\u001b[A\n"," 41% 159522/386160 [10:53<59:08:03,  1.06it/s]\u001b[A\n"," 41% 159523/386160 [10:54<59:05:21,  1.07it/s]\u001b[A\n"," 41% 159524/386160 [10:55<59:05:24,  1.07it/s]\u001b[A\n"," 41% 159525/386160 [10:56<58:56:59,  1.07it/s]\u001b[A\n"," 41% 159526/386160 [10:57<58:58:29,  1.07it/s]\u001b[A\n"," 41% 159527/386160 [10:58<59:01:33,  1.07it/s]\u001b[A\n"," 41% 159528/386160 [10:59<58:57:32,  1.07it/s]\u001b[A\n"," 41% 159529/386160 [11:00<58:55:36,  1.07it/s]\u001b[A\n"," 41% 159530/386160 [11:01<58:52:34,  1.07it/s]\u001b[A\n"," 41% 159531/386160 [11:02<58:49:03,  1.07it/s]\u001b[A\n"," 41% 159532/386160 [11:02<58:47:08,  1.07it/s]\u001b[A\n"," 41% 159533/386160 [11:03<58:44:44,  1.07it/s]\u001b[A\n"," 41% 159534/386160 [11:04<58:45:36,  1.07it/s]\u001b[A\n"," 41% 159535/386160 [11:05<58:45:41,  1.07it/s]\u001b[A\n"," 41% 159536/386160 [11:06<58:47:42,  1.07it/s]\u001b[A\n"," 41% 159537/386160 [11:07<58:52:55,  1.07it/s]\u001b[A\n"," 41% 159538/386160 [11:08<58:56:00,  1.07it/s]\u001b[A\n"," 41% 159539/386160 [11:09<59:02:03,  1.07it/s]\u001b[A\n"," 41% 159540/386160 [11:10<59:00:23,  1.07it/s]\u001b[A\n"," 41% 159541/386160 [11:11<59:02:06,  1.07it/s]\u001b[A\n"," 41% 159542/386160 [11:12<58:57:48,  1.07it/s]\u001b[A\n"," 41% 159543/386160 [11:13<58:58:38,  1.07it/s]\u001b[A\n"," 41% 159544/386160 [11:14<59:02:52,  1.07it/s]\u001b[A\n"," 41% 159545/386160 [11:15<59:00:30,  1.07it/s]\u001b[A\n"," 41% 159546/386160 [11:16<58:58:49,  1.07it/s]\u001b[A\n"," 41% 159547/386160 [11:17<58:59:35,  1.07it/s]\u001b[A\n"," 41% 159548/386160 [11:17<59:00:56,  1.07it/s]\u001b[A\n"," 41% 159549/386160 [11:18<58:55:56,  1.07it/s]\u001b[A\n"," 41% 159550/386160 [11:19<59:04:31,  1.07it/s]\u001b[A\n"," 41% 159551/386160 [11:20<58:59:23,  1.07it/s]\u001b[A\n"," 41% 159552/386160 [11:21<58:57:51,  1.07it/s]\u001b[A\n"," 41% 159553/386160 [11:22<58:58:33,  1.07it/s]\u001b[A\n"," 41% 159554/386160 [11:23<59:00:09,  1.07it/s]\u001b[A\n"," 41% 159555/386160 [11:24<58:57:40,  1.07it/s]\u001b[A\n"," 41% 159556/386160 [11:25<58:58:11,  1.07it/s]\u001b[A\n"," 41% 159557/386160 [11:26<58:59:57,  1.07it/s]\u001b[A\n"," 41% 159558/386160 [11:27<58:57:08,  1.07it/s]\u001b[A\n"," 41% 159559/386160 [11:28<58:55:38,  1.07it/s]\u001b[A\n"," 41% 159560/386160 [11:29<58:58:07,  1.07it/s]\u001b[A\n"," 41% 159561/386160 [11:30<58:58:19,  1.07it/s]\u001b[A\n"," 41% 159562/386160 [11:31<59:04:03,  1.07it/s]\u001b[A\n"," 41% 159563/386160 [11:32<59:07:09,  1.06it/s]\u001b[A\n"," 41% 159564/386160 [11:32<59:02:45,  1.07it/s]\u001b[A\n"," 41% 159565/386160 [11:33<58:59:46,  1.07it/s]\u001b[A\n"," 41% 159566/386160 [11:34<59:01:13,  1.07it/s]\u001b[A\n"," 41% 159567/386160 [11:35<59:03:43,  1.07it/s]\u001b[A\n"," 41% 159568/386160 [11:36<59:00:47,  1.07it/s]\u001b[A\n"," 41% 159569/386160 [11:37<59:02:37,  1.07it/s]\u001b[A\n"," 41% 159570/386160 [11:38<58:56:44,  1.07it/s]\u001b[A\n"," 41% 159571/386160 [11:39<58:54:39,  1.07it/s]\u001b[A\n"," 41% 159572/386160 [11:40<59:08:16,  1.06it/s]\u001b[A\n"," 41% 159573/386160 [11:41<59:02:06,  1.07it/s]\u001b[A\n"," 41% 159574/386160 [11:42<59:00:12,  1.07it/s]\u001b[A\n"," 41% 159575/386160 [11:43<59:00:39,  1.07it/s]\u001b[A\n"," 41% 159576/386160 [11:44<59:02:45,  1.07it/s]\u001b[A\n"," 41% 159577/386160 [11:45<58:58:18,  1.07it/s]\u001b[A\n"," 41% 159578/386160 [11:46<59:07:20,  1.06it/s]\u001b[A\n"," 41% 159579/386160 [11:47<59:03:10,  1.07it/s]\u001b[A\n"," 41% 159580/386160 [11:47<58:57:46,  1.07it/s]\u001b[A\n"," 41% 159581/386160 [11:48<58:58:12,  1.07it/s]\u001b[A\n"," 41% 159582/386160 [11:49<58:58:08,  1.07it/s]\u001b[A\n"," 41% 159583/386160 [11:50<59:05:02,  1.07it/s]\u001b[A\n"," 41% 159584/386160 [11:51<58:59:57,  1.07it/s]\u001b[A\n"," 41% 159585/386160 [11:52<58:56:00,  1.07it/s]\u001b[A\n"," 41% 159586/386160 [11:53<58:59:08,  1.07it/s]\u001b[A\n"," 41% 159587/386160 [11:54<59:03:57,  1.07it/s]\u001b[A\n"," 41% 159588/386160 [11:55<59:00:04,  1.07it/s]\u001b[A\n"," 41% 159589/386160 [11:56<58:54:58,  1.07it/s]\u001b[A\n"," 41% 159590/386160 [11:57<59:02:48,  1.07it/s]\u001b[A\n"," 41% 159591/386160 [11:58<59:06:07,  1.06it/s]\u001b[A\n"," 41% 159592/386160 [11:59<59:02:44,  1.07it/s]\u001b[A\n"," 41% 159593/386160 [12:00<59:05:46,  1.06it/s]\u001b[A\n"," 41% 159594/386160 [12:01<59:07:45,  1.06it/s]\u001b[A\n"," 41% 159595/386160 [12:02<59:02:58,  1.07it/s]\u001b[A\n"," 41% 159596/386160 [12:02<59:03:38,  1.07it/s]\u001b[A\n"," 41% 159597/386160 [12:03<59:00:02,  1.07it/s]\u001b[A\n"," 41% 159598/386160 [12:04<59:01:13,  1.07it/s]\u001b[A\n"," 41% 159599/386160 [12:05<58:55:38,  1.07it/s]\u001b[A\n"," 41% 159600/386160 [12:06<58:49:53,  1.07it/s]\u001b[A\n"," 41% 159601/386160 [12:07<58:49:46,  1.07it/s]\u001b[A\n"," 41% 159602/386160 [12:08<58:47:27,  1.07it/s]\u001b[A\n"," 41% 159603/386160 [12:09<58:46:45,  1.07it/s]\u001b[A\n"," 41% 159604/386160 [12:10<58:50:08,  1.07it/s]\u001b[A\n"," 41% 159605/386160 [12:11<59:00:18,  1.07it/s]\u001b[A\n"," 41% 159606/386160 [12:12<58:54:42,  1.07it/s]\u001b[A\n"," 41% 159607/386160 [12:13<58:54:20,  1.07it/s]\u001b[A\n"," 41% 159608/386160 [12:14<58:55:29,  1.07it/s]\u001b[A\n"," 41% 159609/386160 [12:15<58:55:07,  1.07it/s]\u001b[A\n"," 41% 159610/386160 [12:16<58:57:02,  1.07it/s]\u001b[A\n"," 41% 159611/386160 [12:17<58:57:22,  1.07it/s]\u001b[A\n"," 41% 159612/386160 [12:17<58:58:40,  1.07it/s]\u001b[A\n"," 41% 159613/386160 [12:18<59:00:37,  1.07it/s]\u001b[A\n"," 41% 159614/386160 [12:19<59:02:23,  1.07it/s]\u001b[A\n"," 41% 159615/386160 [12:20<59:30:25,  1.06it/s]\u001b[A\n"," 41% 159616/386160 [12:21<60:05:22,  1.05it/s]\u001b[A\n"," 41% 159617/386160 [12:22<60:21:51,  1.04it/s]\u001b[A\n"," 41% 159618/386160 [12:23<60:50:17,  1.03it/s]\u001b[A\n"," 41% 159619/386160 [12:24<61:19:12,  1.03it/s]\u001b[A\n"," 41% 159620/386160 [12:25<61:18:19,  1.03it/s]\u001b[A\n"," 41% 159621/386160 [12:26<60:36:04,  1.04it/s]\u001b[A\n"," 41% 159622/386160 [12:27<60:05:06,  1.05it/s]\u001b[A\n"," 41% 159623/386160 [12:28<59:49:03,  1.05it/s]\u001b[A\n"," 41% 159624/386160 [12:29<59:34:10,  1.06it/s]\u001b[A\n"," 41% 159625/386160 [12:30<59:18:11,  1.06it/s]\u001b[A\n"," 41% 159626/386160 [12:31<59:10:28,  1.06it/s]\u001b[A\n"," 41% 159627/386160 [12:32<59:05:44,  1.06it/s]\u001b[A\n"," 41% 159628/386160 [12:33<59:00:18,  1.07it/s]\u001b[A\n"," 41% 159629/386160 [12:34<58:57:34,  1.07it/s]\u001b[A\n"," 41% 159630/386160 [12:35<58:52:45,  1.07it/s]\u001b[A\n"," 41% 159631/386160 [12:35<58:51:16,  1.07it/s]\u001b[A\n"," 41% 159632/386160 [12:36<58:46:37,  1.07it/s]\u001b[A\n"," 41% 159633/386160 [12:37<58:48:43,  1.07it/s]\u001b[A\n"," 41% 159634/386160 [12:38<58:51:51,  1.07it/s]\u001b[A\n"," 41% 159635/386160 [12:39<58:48:28,  1.07it/s]\u001b[A\n"," 41% 159636/386160 [12:40<58:59:41,  1.07it/s]\u001b[A\n"," 41% 159637/386160 [12:41<58:54:02,  1.07it/s]\u001b[A\n"," 41% 159638/386160 [12:42<58:54:24,  1.07it/s]\u001b[A\n"," 41% 159639/386160 [12:43<58:51:19,  1.07it/s]\u001b[A\n"," 41% 159640/386160 [12:44<58:51:28,  1.07it/s]\u001b[A\n"," 41% 159641/386160 [12:45<58:51:41,  1.07it/s]\u001b[A\n"," 41% 159642/386160 [12:46<58:52:04,  1.07it/s]\u001b[A\n"," 41% 159643/386160 [12:47<58:48:06,  1.07it/s]\u001b[A\n"," 41% 159644/386160 [12:48<58:46:03,  1.07it/s]\u001b[A\n"," 41% 159645/386160 [12:49<58:52:19,  1.07it/s]\u001b[A\n"," 41% 159646/386160 [12:50<58:57:57,  1.07it/s]\u001b[A\n"," 41% 159647/386160 [12:50<58:58:25,  1.07it/s]\u001b[A\n"," 41% 159648/386160 [12:51<58:56:13,  1.07it/s]\u001b[A\n"," 41% 159649/386160 [12:52<59:11:05,  1.06it/s]\u001b[A\n"," 41% 159650/386160 [12:53<59:11:16,  1.06it/s]\u001b[A\n"," 41% 159651/386160 [12:54<59:05:43,  1.06it/s]\u001b[A\n"," 41% 159652/386160 [12:55<59:05:47,  1.06it/s]\u001b[A\n"," 41% 159653/386160 [12:56<59:03:56,  1.07it/s]\u001b[A\n"," 41% 159654/386160 [12:57<59:03:44,  1.07it/s]\u001b[A\n"," 41% 159655/386160 [12:58<59:01:47,  1.07it/s]\u001b[A\n"," 41% 159656/386160 [12:59<58:54:57,  1.07it/s]\u001b[A\n"," 41% 159657/386160 [13:00<58:55:26,  1.07it/s]\u001b[A\n"," 41% 159658/386160 [13:01<59:00:15,  1.07it/s]\u001b[A\n"," 41% 159659/386160 [13:02<58:56:55,  1.07it/s]\u001b[A\n"," 41% 159660/386160 [13:03<58:56:53,  1.07it/s]\u001b[A\n"," 41% 159661/386160 [13:04<58:58:07,  1.07it/s]\u001b[A\n"," 41% 159662/386160 [13:05<59:01:34,  1.07it/s]\u001b[A\n"," 41% 159663/386160 [13:05<58:58:47,  1.07it/s]\u001b[A\n"," 41% 159664/386160 [13:06<58:53:50,  1.07it/s]\u001b[A\n"," 41% 159665/386160 [13:07<58:53:23,  1.07it/s]\u001b[A\n"," 41% 159666/386160 [13:08<58:52:50,  1.07it/s]\u001b[A\n"," 41% 159667/386160 [13:09<58:58:51,  1.07it/s]\u001b[A\n"," 41% 159668/386160 [13:10<58:58:10,  1.07it/s]\u001b[A\n"," 41% 159669/386160 [13:11<58:51:41,  1.07it/s]\u001b[A\n"," 41% 159670/386160 [13:12<58:51:49,  1.07it/s]\u001b[A\n"," 41% 159671/386160 [13:13<59:06:04,  1.06it/s]\u001b[A\n"," 41% 159672/386160 [13:14<59:07:06,  1.06it/s]\u001b[A\n"," 41% 159673/386160 [13:15<59:04:40,  1.06it/s]\u001b[A\n"," 41% 159674/386160 [13:16<59:00:08,  1.07it/s]\u001b[A\n"," 41% 159675/386160 [13:17<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159676/386160 [13:18<58:54:12,  1.07it/s]\u001b[A\n"," 41% 159677/386160 [13:19<58:55:25,  1.07it/s]\u001b[A\n"," 41% 159678/386160 [13:20<58:57:24,  1.07it/s]\u001b[A\n"," 41% 159679/386160 [13:20<58:59:04,  1.07it/s]\u001b[A\n"," 41% 159680/386160 [13:21<58:56:31,  1.07it/s]\u001b[A\n"," 41% 159681/386160 [13:22<58:57:38,  1.07it/s]\u001b[A\n"," 41% 159682/386160 [13:23<59:10:52,  1.06it/s]\u001b[A\n"," 41% 159683/386160 [13:24<59:12:51,  1.06it/s]\u001b[A\n"," 41% 159684/386160 [13:25<59:05:29,  1.06it/s]\u001b[A\n"," 41% 159685/386160 [13:26<59:01:03,  1.07it/s]\u001b[A\n"," 41% 159686/386160 [13:27<58:55:55,  1.07it/s]\u001b[A\n"," 41% 159687/386160 [13:28<58:52:19,  1.07it/s]\u001b[A\n"," 41% 159688/386160 [13:29<58:48:30,  1.07it/s]\u001b[A\n"," 41% 159689/386160 [13:30<58:47:30,  1.07it/s]\u001b[A\n"," 41% 159690/386160 [13:31<58:42:55,  1.07it/s]\u001b[A\n"," 41% 159691/386160 [13:32<58:43:31,  1.07it/s]\u001b[A\n"," 41% 159692/386160 [13:33<58:47:35,  1.07it/s]\u001b[A\n"," 41% 159693/386160 [13:34<58:51:01,  1.07it/s]\u001b[A\n"," 41% 159694/386160 [13:35<58:59:56,  1.07it/s]\u001b[A\n"," 41% 159695/386160 [13:35<59:11:23,  1.06it/s]\u001b[A\n"," 41% 159696/386160 [13:36<59:06:55,  1.06it/s]\u001b[A\n"," 41% 159697/386160 [13:37<59:08:52,  1.06it/s]\u001b[A\n"," 41% 159698/386160 [13:38<59:05:14,  1.06it/s]\u001b[A\n"," 41% 159699/386160 [13:39<59:02:26,  1.07it/s]\u001b[A\n"," 41% 159700/386160 [13:40<58:56:46,  1.07it/s]\u001b[A\n"," 41% 159701/386160 [13:41<58:52:41,  1.07it/s]\u001b[A\n"," 41% 159702/386160 [13:42<58:50:59,  1.07it/s]\u001b[A\n"," 41% 159703/386160 [13:43<58:49:34,  1.07it/s]\u001b[A\n"," 41% 159704/386160 [13:44<58:47:48,  1.07it/s]\u001b[A\n"," 41% 159705/386160 [13:45<58:50:56,  1.07it/s]\u001b[A\n"," 41% 159706/386160 [13:46<59:03:01,  1.07it/s]\u001b[A\n"," 41% 159707/386160 [13:47<59:03:28,  1.07it/s]\u001b[A\n"," 41% 159708/386160 [13:48<59:03:26,  1.07it/s]\u001b[A\n"," 41% 159709/386160 [13:49<59:04:40,  1.06it/s]\u001b[A\n"," 41% 159710/386160 [13:50<59:01:53,  1.07it/s]\u001b[A\n"," 41% 159711/386160 [13:50<59:00:43,  1.07it/s]\u001b[A\n"," 41% 159712/386160 [13:51<58:57:32,  1.07it/s]\u001b[A\n"," 41% 159713/386160 [13:52<58:54:55,  1.07it/s]\u001b[A\n"," 41% 159714/386160 [13:53<58:49:28,  1.07it/s]\u001b[A\n"," 41% 159715/386160 [13:54<58:47:25,  1.07it/s]\u001b[A\n"," 41% 159716/386160 [13:55<58:49:08,  1.07it/s]\u001b[A\n"," 41% 159717/386160 [13:56<58:51:57,  1.07it/s]\u001b[A\n"," 41% 159718/386160 [13:57<58:58:23,  1.07it/s]\u001b[A\n"," 41% 159719/386160 [13:58<58:52:27,  1.07it/s]\u001b[A\n"," 41% 159720/386160 [13:59<58:48:59,  1.07it/s]\u001b[A\n"," 41% 159721/386160 [14:00<58:53:06,  1.07it/s]\u001b[A\n"," 41% 159722/386160 [14:01<58:55:38,  1.07it/s]\u001b[A\n"," 41% 159723/386160 [14:02<58:56:14,  1.07it/s]\u001b[A\n"," 41% 159724/386160 [14:03<58:55:00,  1.07it/s]\u001b[A\n"," 41% 159725/386160 [14:04<58:54:08,  1.07it/s]\u001b[A\n"," 41% 159726/386160 [14:05<58:57:56,  1.07it/s]\u001b[A\n"," 41% 159727/386160 [14:05<59:04:58,  1.06it/s]\u001b[A\n"," 41% 159728/386160 [14:06<59:05:56,  1.06it/s]\u001b[A\n"," 41% 159729/386160 [14:07<59:02:47,  1.07it/s]\u001b[A\n"," 41% 159730/386160 [14:08<59:02:27,  1.07it/s]\u001b[A\n"," 41% 159731/386160 [14:09<59:01:29,  1.07it/s]\u001b[A\n"," 41% 159732/386160 [14:10<59:04:26,  1.06it/s]\u001b[A\n"," 41% 159733/386160 [14:11<58:57:36,  1.07it/s]\u001b[A\n"," 41% 159734/386160 [14:12<58:54:13,  1.07it/s]\u001b[A\n"," 41% 159735/386160 [14:13<58:54:19,  1.07it/s]\u001b[A\n"," 41% 159736/386160 [14:14<58:52:49,  1.07it/s]\u001b[A\n"," 41% 159737/386160 [14:15<58:55:21,  1.07it/s]\u001b[A\n"," 41% 159738/386160 [14:16<58:57:48,  1.07it/s]\u001b[A\n"," 41% 159739/386160 [14:17<59:00:18,  1.07it/s]\u001b[A\n"," 41% 159740/386160 [14:18<59:43:03,  1.05it/s]\u001b[A\n"," 41% 159741/386160 [14:19<60:19:00,  1.04it/s]\u001b[A\n"," 41% 159742/386160 [14:20<60:41:17,  1.04it/s]\u001b[A\n"," 41% 159743/386160 [14:21<60:48:20,  1.03it/s]\u001b[A\n"," 41% 159744/386160 [14:22<61:34:34,  1.02it/s]\u001b[A\n"," 41% 159745/386160 [14:23<61:32:08,  1.02it/s]\u001b[A\n"," 41% 159746/386160 [14:24<60:41:17,  1.04it/s]\u001b[A\n"," 41% 159747/386160 [14:24<60:16:07,  1.04it/s]\u001b[A\n"," 41% 159748/386160 [14:25<59:53:51,  1.05it/s]\u001b[A\n"," 41% 159749/386160 [14:26<59:39:18,  1.05it/s]\u001b[A\n"," 41% 159750/386160 [14:27<59:29:22,  1.06it/s]\u001b[A\n"," 41% 159751/386160 [14:28<59:17:23,  1.06it/s]\u001b[A\n"," 41% 159752/386160 [14:29<59:11:22,  1.06it/s]\u001b[A\n"," 41% 159753/386160 [14:30<59:10:42,  1.06it/s]\u001b[A\n"," 41% 159754/386160 [14:31<59:06:25,  1.06it/s]\u001b[A\n"," 41% 159755/386160 [14:32<59:10:04,  1.06it/s]\u001b[A\n"," 41% 159756/386160 [14:33<59:08:09,  1.06it/s]\u001b[A\n"," 41% 159757/386160 [14:34<59:03:15,  1.06it/s]\u001b[A\n"," 41% 159758/386160 [14:35<58:55:41,  1.07it/s]\u001b[A\n"," 41% 159759/386160 [14:36<58:52:11,  1.07it/s]\u001b[A\n"," 41% 159760/386160 [14:37<58:54:28,  1.07it/s]\u001b[A\n"," 41% 159761/386160 [14:38<58:59:51,  1.07it/s]\u001b[A\n"," 41% 159762/386160 [14:39<58:55:40,  1.07it/s]\u001b[A\n"," 41% 159763/386160 [14:39<58:57:26,  1.07it/s]\u001b[A\n"," 41% 159764/386160 [14:40<58:58:08,  1.07it/s]\u001b[A\n"," 41% 159765/386160 [14:41<58:55:40,  1.07it/s]\u001b[A\n"," 41% 159766/386160 [14:42<58:54:56,  1.07it/s]\u001b[A\n"," 41% 159767/386160 [14:43<58:58:26,  1.07it/s]\u001b[A\n"," 41% 159768/386160 [14:44<59:04:15,  1.06it/s]\u001b[A\n"," 41% 159769/386160 [14:45<59:03:12,  1.06it/s]\u001b[A\n"," 41% 159770/386160 [14:46<59:03:41,  1.06it/s]\u001b[A\n"," 41% 159771/386160 [14:47<59:02:58,  1.06it/s]\u001b[A\n"," 41% 159772/386160 [14:48<59:00:57,  1.07it/s]\u001b[A\n"," 41% 159773/386160 [14:49<58:57:50,  1.07it/s]\u001b[A\n"," 41% 159774/386160 [14:50<58:54:49,  1.07it/s]\u001b[A\n"," 41% 159775/386160 [14:51<59:01:44,  1.07it/s]\u001b[A\n"," 41% 159776/386160 [14:52<59:06:01,  1.06it/s]\u001b[A\n"," 41% 159777/386160 [14:53<59:04:51,  1.06it/s]\u001b[A\n"," 41% 159778/386160 [14:54<58:59:57,  1.07it/s]\u001b[A\n"," 41% 159779/386160 [14:54<58:59:43,  1.07it/s]\u001b[A\n"," 41% 159780/386160 [14:55<58:59:47,  1.07it/s]\u001b[A\n"," 41% 159781/386160 [14:56<58:58:57,  1.07it/s]\u001b[A\n"," 41% 159782/386160 [14:57<58:58:17,  1.07it/s]\u001b[A\n"," 41% 159783/386160 [14:58<59:08:19,  1.06it/s]\u001b[A\n"," 41% 159784/386160 [14:59<59:06:53,  1.06it/s]\u001b[A\n"," 41% 159785/386160 [15:00<59:06:36,  1.06it/s]\u001b[A\n"," 41% 159786/386160 [15:01<59:03:06,  1.06it/s]\u001b[A\n"," 41% 159787/386160 [15:02<58:56:42,  1.07it/s]\u001b[A\n"," 41% 159788/386160 [15:03<58:55:06,  1.07it/s]\u001b[A\n"," 41% 159789/386160 [15:04<59:01:51,  1.07it/s]\u001b[A\n"," 41% 159790/386160 [15:05<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159791/386160 [15:06<58:57:31,  1.07it/s]\u001b[A\n"," 41% 159792/386160 [15:07<59:00:41,  1.07it/s]\u001b[A\n"," 41% 159793/386160 [15:08<59:14:52,  1.06it/s]\u001b[A\n"," 41% 159794/386160 [15:09<59:14:07,  1.06it/s]\u001b[A\n"," 41% 159795/386160 [15:10<59:11:45,  1.06it/s]\u001b[A\n"," 41% 159796/386160 [15:10<59:09:40,  1.06it/s]\u001b[A\n"," 41% 159797/386160 [15:11<59:07:25,  1.06it/s]\u001b[A\n"," 41% 159798/386160 [15:12<59:06:20,  1.06it/s]\u001b[A\n"," 41% 159799/386160 [15:13<59:05:31,  1.06it/s]\u001b[A\n"," 41% 159800/386160 [15:14<59:01:02,  1.07it/s]\u001b[A\n"," 41% 159801/386160 [15:15<59:00:18,  1.07it/s]\u001b[A\n"," 41% 159802/386160 [15:16<59:05:25,  1.06it/s]\u001b[A\n"," 41% 159803/386160 [15:17<59:02:07,  1.07it/s]\u001b[A\n"," 41% 159804/386160 [15:18<59:13:09,  1.06it/s]\u001b[A\n"," 41% 159805/386160 [15:19<59:06:53,  1.06it/s]\u001b[A\n"," 41% 159806/386160 [15:20<59:05:13,  1.06it/s]\u001b[A\n"," 41% 159807/386160 [15:21<59:07:10,  1.06it/s]\u001b[A\n"," 41% 159808/386160 [15:22<59:02:23,  1.06it/s]\u001b[A\n"," 41% 159809/386160 [15:23<58:58:15,  1.07it/s]\u001b[A\n"," 41% 159810/386160 [15:24<58:56:30,  1.07it/s]\u001b[A\n"," 41% 159811/386160 [15:25<58:56:30,  1.07it/s]\u001b[A\n"," 41% 159812/386160 [15:25<58:55:11,  1.07it/s]\u001b[A\n"," 41% 159813/386160 [15:26<58:50:08,  1.07it/s]\u001b[A\n"," 41% 159814/386160 [15:27<58:48:56,  1.07it/s]\u001b[A\n"," 41% 159815/386160 [15:28<58:53:20,  1.07it/s]\u001b[A\n"," 41% 159816/386160 [15:29<59:04:40,  1.06it/s]\u001b[A\n"," 41% 159817/386160 [15:30<59:03:42,  1.06it/s]\u001b[A\n"," 41% 159818/386160 [15:31<59:01:25,  1.07it/s]\u001b[A\n"," 41% 159819/386160 [15:32<59:00:03,  1.07it/s]\u001b[A\n"," 41% 159820/386160 [15:33<58:54:36,  1.07it/s]\u001b[A\n"," 41% 159821/386160 [15:34<58:57:57,  1.07it/s]\u001b[A\n"," 41% 159822/386160 [15:35<58:59:34,  1.07it/s]\u001b[A\n"," 41% 159823/386160 [15:36<59:00:19,  1.07it/s]\u001b[A\n"," 41% 159824/386160 [15:37<58:58:24,  1.07it/s]\u001b[A\n"," 41% 159825/386160 [15:38<59:05:34,  1.06it/s]\u001b[A\n"," 41% 159826/386160 [15:39<59:02:33,  1.06it/s]\u001b[A\n"," 41% 159827/386160 [15:40<59:12:07,  1.06it/s]\u001b[A\n"," 41% 159828/386160 [15:41<59:08:50,  1.06it/s]\u001b[A\n"," 41% 159829/386160 [15:41<59:11:59,  1.06it/s]\u001b[A\n"," 41% 159830/386160 [15:42<59:09:50,  1.06it/s]\u001b[A\n"," 41% 159831/386160 [15:43<59:05:20,  1.06it/s]\u001b[A\n"," 41% 159832/386160 [15:44<59:00:04,  1.07it/s]\u001b[A\n"," 41% 159833/386160 [15:45<58:59:35,  1.07it/s]\u001b[A\n"," 41% 159834/386160 [15:46<58:57:49,  1.07it/s]\u001b[A\n"," 41% 159835/386160 [15:47<58:53:46,  1.07it/s]\u001b[A\n"," 41% 159836/386160 [15:48<59:01:21,  1.07it/s]\u001b[A\n"," 41% 159837/386160 [15:49<58:59:59,  1.07it/s]\u001b[A\n"," 41% 159838/386160 [15:50<58:57:29,  1.07it/s]\u001b[A\n"," 41% 159839/386160 [15:51<59:01:53,  1.06it/s]\u001b[A\n"," 41% 159840/386160 [15:52<59:00:40,  1.07it/s]\u001b[A\n"," 41% 159841/386160 [15:53<58:56:23,  1.07it/s]\u001b[A\n"," 41% 159842/386160 [15:54<58:55:28,  1.07it/s]\u001b[A\n"," 41% 159843/386160 [15:55<58:51:26,  1.07it/s]\u001b[A\n"," 41% 159844/386160 [15:56<58:57:37,  1.07it/s]\u001b[A\n"," 41% 159845/386160 [15:56<59:02:16,  1.06it/s]\u001b[A\n"," 41% 159846/386160 [15:57<59:00:55,  1.07it/s]\u001b[A\n"," 41% 159847/386160 [15:58<58:58:13,  1.07it/s]\u001b[A\n"," 41% 159848/386160 [15:59<58:56:25,  1.07it/s]\u001b[A\n"," 41% 159849/386160 [16:00<59:09:09,  1.06it/s]\u001b[A\n"," 41% 159850/386160 [16:01<59:02:16,  1.06it/s]\u001b[A\n"," 41% 159851/386160 [16:02<58:59:36,  1.07it/s]\u001b[A\n"," 41% 159852/386160 [16:03<58:58:57,  1.07it/s]\u001b[A\n"," 41% 159853/386160 [16:04<58:57:06,  1.07it/s]\u001b[A\n"," 41% 159854/386160 [16:05<58:57:42,  1.07it/s]\u001b[A\n"," 41% 159855/386160 [16:06<58:58:13,  1.07it/s]\u001b[A\n"," 41% 159856/386160 [16:07<58:54:35,  1.07it/s]\u001b[A\n"," 41% 159857/386160 [16:08<59:01:41,  1.06it/s]\u001b[A\n"," 41% 159858/386160 [16:09<59:01:58,  1.06it/s]\u001b[A\n"," 41% 159859/386160 [16:10<58:56:15,  1.07it/s]\u001b[A\n"," 41% 159860/386160 [16:11<58:59:40,  1.07it/s]\u001b[A\n"," 41% 159861/386160 [16:11<59:06:36,  1.06it/s]\u001b[A\n"," 41% 159862/386160 [16:12<59:00:57,  1.07it/s]\u001b[A\n"," 41% 159863/386160 [16:13<58:58:19,  1.07it/s]\u001b[A\n"," 41% 159864/386160 [16:14<59:47:39,  1.05it/s]\u001b[A\n"," 41% 159865/386160 [16:15<60:15:05,  1.04it/s]\u001b[A\n"," 41% 159866/386160 [16:16<60:39:37,  1.04it/s]\u001b[A\n"," 41% 159867/386160 [16:17<60:55:01,  1.03it/s]\u001b[A\n"," 41% 159868/386160 [16:18<61:18:57,  1.03it/s]\u001b[A\n"," 41% 159869/386160 [16:19<61:43:12,  1.02it/s]\u001b[A\n"," 41% 159870/386160 [16:20<61:18:26,  1.03it/s]\u001b[A\n"," 41% 159871/386160 [16:21<60:42:14,  1.04it/s]\u001b[A\n"," 41% 159872/386160 [16:22<60:08:02,  1.05it/s]\u001b[A\n"," 41% 159873/386160 [16:23<59:47:29,  1.05it/s]\u001b[A\n"," 41% 159874/386160 [16:24<59:26:13,  1.06it/s]\u001b[A\n"," 41% 159875/386160 [16:25<59:17:31,  1.06it/s]\u001b[A\n"," 41% 159876/386160 [16:26<59:17:56,  1.06it/s]\u001b[A\n"," 41% 159877/386160 [16:27<59:10:47,  1.06it/s]\u001b[A\n"," 41% 159878/386160 [16:28<59:09:30,  1.06it/s]\u001b[A\n"," 41% 159879/386160 [16:29<59:01:41,  1.06it/s]\u001b[A\n"," 41% 159880/386160 [16:30<58:57:20,  1.07it/s]\u001b[A\n"," 41% 159881/386160 [16:31<58:55:22,  1.07it/s]\u001b[A\n"," 41% 159882/386160 [16:31<59:02:35,  1.06it/s]\u001b[A\n"," 41% 159883/386160 [16:32<59:01:51,  1.06it/s]\u001b[A\n"," 41% 159884/386160 [16:33<59:01:20,  1.06it/s]\u001b[A\n"," 41% 159885/386160 [16:34<58:58:42,  1.07it/s]\u001b[A\n"," 41% 159886/386160 [16:35<59:02:06,  1.06it/s]\u001b[A\n"," 41% 159887/386160 [16:36<59:00:04,  1.07it/s]\u001b[A\n"," 41% 159888/386160 [16:37<58:59:47,  1.07it/s]\u001b[A\n"," 41% 159889/386160 [16:38<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159890/386160 [16:39<59:04:01,  1.06it/s]\u001b[A\n"," 41% 159891/386160 [16:40<58:52:31,  1.07it/s]\u001b[A\n"," 41% 159892/386160 [16:41<58:46:15,  1.07it/s]\u001b[A\n"," 41% 159893/386160 [16:42<58:46:44,  1.07it/s]\u001b[A\n"," 41% 159894/386160 [16:43<58:56:21,  1.07it/s]\u001b[A\n"," 41% 159895/386160 [16:44<58:54:10,  1.07it/s]\u001b[A\n"," 41% 159896/386160 [16:45<58:56:12,  1.07it/s]\u001b[A\n"," 41% 159897/386160 [16:46<58:53:04,  1.07it/s]\u001b[A\n"," 41% 159898/386160 [16:46<58:50:49,  1.07it/s]\u001b[A\n"," 41% 159899/386160 [16:47<58:47:27,  1.07it/s]\u001b[A\n"," 41% 159900/386160 [16:48<58:49:20,  1.07it/s]\u001b[A\n"," 41% 159901/386160 [16:49<58:49:00,  1.07it/s]\u001b[A\n"," 41% 159902/386160 [16:50<58:56:02,  1.07it/s]\u001b[A\n"," 41% 159903/386160 [16:51<58:57:28,  1.07it/s]\u001b[A\n"," 41% 159904/386160 [16:52<58:52:09,  1.07it/s]\u001b[A\n"," 41% 159905/386160 [16:53<58:56:53,  1.07it/s]\u001b[A\n"," 41% 159906/386160 [16:54<58:55:33,  1.07it/s]\u001b[A\n"," 41% 159907/386160 [16:55<58:53:02,  1.07it/s]\u001b[A\n"," 41% 159908/386160 [16:56<58:59:01,  1.07it/s]\u001b[A\n"," 41% 159909/386160 [16:57<58:55:14,  1.07it/s]\u001b[A\n"," 41% 159910/386160 [16:58<58:51:27,  1.07it/s]\u001b[A\n"," 41% 159911/386160 [16:59<58:50:15,  1.07it/s]\u001b[A\n"," 41% 159912/386160 [17:00<58:49:02,  1.07it/s]\u001b[A\n"," 41% 159913/386160 [17:01<58:56:00,  1.07it/s]\u001b[A\n"," 41% 159914/386160 [17:01<58:56:50,  1.07it/s]\u001b[A\n"," 41% 159915/386160 [17:02<58:59:06,  1.07it/s]\u001b[A\n"," 41% 159916/386160 [17:03<58:56:29,  1.07it/s]\u001b[A\n"," 41% 159917/386160 [17:04<58:51:57,  1.07it/s]\u001b[A\n"," 41% 159918/386160 [17:05<58:50:48,  1.07it/s]\u001b[A\n"," 41% 159919/386160 [17:06<58:48:24,  1.07it/s]\u001b[A\n"," 41% 159920/386160 [17:07<58:46:40,  1.07it/s]\u001b[A\n"," 41% 159921/386160 [17:08<58:48:37,  1.07it/s]\u001b[A\n"," 41% 159922/386160 [17:09<58:44:49,  1.07it/s]\u001b[A\n"," 41% 159923/386160 [17:10<58:45:30,  1.07it/s]\u001b[A\n"," 41% 159924/386160 [17:11<58:56:11,  1.07it/s]\u001b[A\n"," 41% 159925/386160 [17:12<58:55:29,  1.07it/s]\u001b[A\n"," 41% 159926/386160 [17:13<58:54:46,  1.07it/s]\u001b[A\n"," 41% 159927/386160 [17:14<59:01:17,  1.06it/s]\u001b[A\n"," 41% 159928/386160 [17:15<59:02:06,  1.06it/s]\u001b[A\n"," 41% 159929/386160 [17:16<59:00:36,  1.06it/s]\u001b[A\n"," 41% 159930/386160 [17:16<59:09:00,  1.06it/s]\u001b[A\n"," 41% 159931/386160 [17:17<59:08:10,  1.06it/s]\u001b[A\n"," 41% 159932/386160 [17:18<59:02:01,  1.06it/s]\u001b[A\n"," 41% 159933/386160 [17:19<59:03:15,  1.06it/s]\u001b[A\n"," 41% 159934/386160 [17:20<59:05:02,  1.06it/s]\u001b[A\n"," 41% 159935/386160 [17:21<59:09:18,  1.06it/s]\u001b[A\n"," 41% 159936/386160 [17:22<59:07:08,  1.06it/s]\u001b[A\n"," 41% 159937/386160 [17:23<59:07:04,  1.06it/s]\u001b[A\n"," 41% 159938/386160 [17:24<59:14:32,  1.06it/s]\u001b[A\n"," 41% 159939/386160 [17:25<59:20:51,  1.06it/s]\u001b[A\n"," 41% 159940/386160 [17:26<59:23:35,  1.06it/s]\u001b[A\n"," 41% 159941/386160 [17:27<59:20:16,  1.06it/s]\u001b[A\n"," 41% 159942/386160 [17:28<59:19:58,  1.06it/s]\u001b[A\n"," 41% 159943/386160 [17:29<59:13:51,  1.06it/s]\u001b[A\n"," 41% 159944/386160 [17:30<59:07:31,  1.06it/s]\u001b[A\n"," 41% 159945/386160 [17:31<59:16:44,  1.06it/s]\u001b[A\n"," 41% 159946/386160 [17:32<59:11:33,  1.06it/s]\u001b[A\n"," 41% 159947/386160 [17:32<59:13:00,  1.06it/s]\u001b[A\n"," 41% 159948/386160 [17:33<59:02:55,  1.06it/s]\u001b[A\n"," 41% 159949/386160 [17:34<59:14:03,  1.06it/s]\u001b[A\n"," 41% 159950/386160 [17:35<59:14:01,  1.06it/s]\u001b[A\n"," 41% 159951/386160 [17:36<59:11:40,  1.06it/s]\u001b[A\n"," 41% 159952/386160 [17:37<59:20:17,  1.06it/s]\u001b[A\n"," 41% 159953/386160 [17:38<59:13:08,  1.06it/s]\u001b[A\n"," 41% 159954/386160 [17:39<59:09:20,  1.06it/s]\u001b[A\n"," 41% 159955/386160 [17:40<59:09:57,  1.06it/s]\u001b[A\n"," 41% 159956/386160 [17:41<59:12:04,  1.06it/s]\u001b[A\n"," 41% 159957/386160 [17:42<59:09:43,  1.06it/s]\u001b[A\n"," 41% 159958/386160 [17:43<59:03:30,  1.06it/s]\u001b[A\n"," 41% 159959/386160 [17:44<59:02:27,  1.06it/s]\u001b[A\n"," 41% 159960/386160 [17:45<59:03:42,  1.06it/s]\u001b[A\n"," 41% 159961/386160 [17:46<59:00:33,  1.06it/s]\u001b[A\n"," 41% 159962/386160 [17:47<59:05:24,  1.06it/s]\u001b[A\n"," 41% 159963/386160 [17:48<59:05:02,  1.06it/s]\u001b[A\n"," 41% 159964/386160 [17:48<59:03:56,  1.06it/s]\u001b[A\n"," 41% 159965/386160 [17:49<59:03:31,  1.06it/s]\u001b[A\n"," 41% 159966/386160 [17:50<58:59:34,  1.07it/s]\u001b[A\n"," 41% 159967/386160 [17:51<58:58:56,  1.07it/s]\u001b[A\n"," 41% 159968/386160 [17:52<59:02:03,  1.06it/s]\u001b[A\n"," 41% 159969/386160 [17:53<58:59:11,  1.07it/s]\u001b[A\n"," 41% 159970/386160 [17:54<59:02:17,  1.06it/s]\u001b[A\n"," 41% 159971/386160 [17:55<59:04:29,  1.06it/s]\u001b[A\n"," 41% 159972/386160 [17:56<59:03:20,  1.06it/s]\u001b[A\n"," 41% 159973/386160 [17:57<59:02:47,  1.06it/s]\u001b[A\n"," 41% 159974/386160 [17:58<58:56:54,  1.07it/s]\u001b[A\n"," 41% 159975/386160 [17:59<58:56:31,  1.07it/s]\u001b[A\n"," 41% 159976/386160 [18:00<58:57:10,  1.07it/s]\u001b[A\n"," 41% 159977/386160 [18:01<59:01:17,  1.06it/s]\u001b[A\n"," 41% 159978/386160 [18:02<58:56:49,  1.07it/s]\u001b[A\n"," 41% 159979/386160 [18:03<58:52:30,  1.07it/s]\u001b[A\n"," 41% 159980/386160 [18:04<58:51:39,  1.07it/s]\u001b[A\n"," 41% 159981/386160 [18:04<58:51:43,  1.07it/s]\u001b[A\n"," 41% 159982/386160 [18:05<59:00:40,  1.06it/s]\u001b[A\n"," 41% 159983/386160 [18:06<59:04:13,  1.06it/s]\u001b[A\n"," 41% 159984/386160 [18:07<58:59:35,  1.06it/s]\u001b[A\n"," 41% 159985/386160 [18:08<58:58:12,  1.07it/s]\u001b[A\n"," 41% 159986/386160 [18:09<58:51:40,  1.07it/s]\u001b[A\n"," 41% 159987/386160 [18:10<58:48:49,  1.07it/s]\u001b[A\n"," 41% 159988/386160 [18:11<58:53:23,  1.07it/s]\u001b[A\n"," 41% 159989/386160 [18:12<59:26:31,  1.06it/s]\u001b[A\n"," 41% 159990/386160 [18:13<59:58:43,  1.05it/s]\u001b[A\n"," 41% 159991/386160 [18:14<60:14:41,  1.04it/s]\u001b[A\n"," 41% 159992/386160 [18:15<60:29:11,  1.04it/s]\u001b[A\n"," 41% 159993/386160 [18:16<61:35:58,  1.02it/s]\u001b[A\n"," 41% 159994/386160 [18:17<61:30:30,  1.02it/s]\u001b[A\n"," 41% 159995/386160 [18:18<60:42:56,  1.03it/s]\u001b[A\n"," 41% 159996/386160 [18:19<60:14:12,  1.04it/s]\u001b[A\n"," 41% 159997/386160 [18:20<59:46:17,  1.05it/s]\u001b[A\n"," 41% 159998/386160 [18:21<59:25:12,  1.06it/s]\u001b[A\n"," 41% 159999/386160 [18:22<59:14:41,  1.06it/s]\u001b[A\n"," 41% 160000/386160 [18:23<59:06:39,  1.06it/s]\u001b[ACalling StepCallback.on_log()\n","\n","\u001b[A{'loss': 0.0889, 'learning_rate': 2.928319867412472e-05, 'epoch': 2.49}\n","\n"," 41% 160000/386160 [18:23<59:06:39,  1.06it/s]\u001b[ASaving model checkpoint to /content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.fold-1.chunk-32.epochs-6.batch-160/partial/checkpoint-160000\n","Configuration saved in /content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.fold-1.chunk-32.epochs-6.batch-160/partial/checkpoint-160000/config.json\n","Model weights saved in /content/drive/Shareddrives/GPTJ/data/gpt2/all.limit-102400.fold-1.chunk-32.epochs-6.batch-160/partial/checkpoint-160000/pytorch_model.bin\n","\n"," 41% 160001/386160 [18:30<180:24:02,  2.87s/it]\u001b[A\n"," 41% 160002/386160 [18:31<143:52:50,  2.29s/it]\u001b[A\n"," 41% 160003/386160 [18:32<118:37:48,  1.89s/it]\u001b[A\n"," 41% 160004/386160 [18:33<101:46:01,  1.62s/it]\u001b[A\n"," 41% 160005/386160 [18:34<89:56:30,  1.43s/it] \u001b[A\n"," 41% 160006/386160 [18:35<81:26:29,  1.30s/it]\u001b[A\n"," 41% 160007/386160 [18:36<76:03:17,  1.21s/it]\u001b[A\n"," 41% 160008/386160 [18:37<73:36:28,  1.17s/it]\u001b[A\n"," 41% 160009/386160 [18:38<71:51:03,  1.14s/it]\u001b[A\n"," 41% 160010/386160 [18:39<70:28:10,  1.12s/it]\u001b[A\n"," 41% 160011/386160 [18:40<68:46:32,  1.09s/it]\u001b[A\n"," 41% 160012/386160 [18:41<66:35:44,  1.06s/it]\u001b[A\n"," 41% 160013/386160 [18:42<64:52:29,  1.03s/it]\u001b[A\n"," 41% 160014/386160 [18:43<63:40:54,  1.01s/it]\u001b[A\n"," 41% 160015/386160 [18:44<62:54:48,  1.00s/it]\u001b[A\n"," 41% 160016/386160 [18:45<62:27:17,  1.01it/s]\u001b[A\n"," 41% 160017/386160 [18:46<62:13:47,  1.01it/s]\u001b[A\n"," 41% 160018/386160 [18:47<61:43:40,  1.02it/s]\u001b[A\n"," 41% 160019/386160 [18:48<61:58:58,  1.01it/s]\u001b[A\n"," 41% 160020/386160 [18:49<62:27:47,  1.01it/s]\u001b[A\n"," 41% 160021/386160 [18:50<62:27:54,  1.01it/s]\u001b[A\n"," 41% 160022/386160 [18:51<62:17:47,  1.01it/s]\u001b[A\n"," 41% 160023/386160 [18:52<62:38:19,  1.00it/s]\u001b[A\n"," 41% 160024/386160 [18:53<62:06:24,  1.01it/s]\u001b[A\n"," 41% 160025/386160 [18:54<61:29:56,  1.02it/s]\u001b[A\n"," 41% 160026/386160 [18:55<61:03:17,  1.03it/s]\u001b[A\n"," 41% 160027/386160 [18:56<60:39:18,  1.04it/s]\u001b[A\n"," 41% 160028/386160 [18:57<60:23:31,  1.04it/s]\u001b[A\n"," 41% 160029/386160 [18:58<60:17:43,  1.04it/s]\u001b[A\n"," 41% 160030/386160 [18:59<60:12:59,  1.04it/s]\u001b[A\n"," 41% 160031/386160 [18:59<60:02:05,  1.05it/s]\u001b[A\n"," 41% 160032/386160 [19:00<59:53:55,  1.05it/s]\u001b[A\n"," 41% 160033/386160 [19:01<59:49:40,  1.05it/s]\u001b[A\n"," 41% 160034/386160 [19:02<59:42:55,  1.05it/s]\u001b[A\n"," 41% 160035/386160 [19:03<59:29:39,  1.06it/s]\u001b[A\n"," 41% 160036/386160 [19:04<59:33:46,  1.05it/s]\u001b[A\n"," 41% 160037/386160 [19:05<59:28:16,  1.06it/s]\u001b[A\n"," 41% 160038/386160 [19:06<59:24:51,  1.06it/s]\u001b[A\n"," 41% 160039/386160 [19:07<59:30:59,  1.06it/s]\u001b[A\n"," 41% 160040/386160 [19:08<59:43:25,  1.05it/s]\u001b[A\n"," 41% 160041/386160 [19:09<59:33:09,  1.05it/s]\u001b[A\n"," 41% 160042/386160 [19:10<59:18:39,  1.06it/s]\u001b[A\n"," 41% 160043/386160 [19:11<59:19:31,  1.06it/s]\u001b[A\n"," 41% 160044/386160 [19:12<59:15:54,  1.06it/s]\u001b[A\n"," 41% 160045/386160 [19:13<59:18:23,  1.06it/s]\u001b[A\n"," 41% 160046/386160 [19:14<59:09:48,  1.06it/s]\u001b[A\n"," 41% 160047/386160 [19:15<59:08:50,  1.06it/s]\u001b[A\n"," 41% 160048/386160 [19:16<59:05:19,  1.06it/s]\u001b[A\n"," 41% 160049/386160 [19:16<58:59:22,  1.06it/s]\u001b[A\n"," 41% 160050/386160 [19:17<58:55:18,  1.07it/s]\u001b[A\n"," 41% 160051/386160 [19:18<58:51:49,  1.07it/s]\u001b[A\n"," 41% 160052/386160 [19:19<59:01:58,  1.06it/s]\u001b[A\n"," 41% 160053/386160 [19:20<58:58:18,  1.07it/s]\u001b[A\n"," 41% 160054/386160 [19:21<58:57:56,  1.07it/s]\u001b[A\n"," 41% 160055/386160 [19:22<58:48:24,  1.07it/s]\u001b[A\n"," 41% 160056/386160 [19:23<58:49:58,  1.07it/s]\u001b[A\n"," 41% 160057/386160 [19:24<58:51:32,  1.07it/s]\u001b[A\n"," 41% 160058/386160 [19:25<58:53:38,  1.07it/s]\u001b[A\n"," 41% 160059/386160 [19:26<58:53:40,  1.07it/s]\u001b[A\n"," 41% 160060/386160 [19:27<58:50:55,  1.07it/s]\u001b[A\n"," 41% 160061/386160 [19:28<58:48:58,  1.07it/s]\u001b[A\n"," 41% 160062/386160 [19:29<58:47:20,  1.07it/s]\u001b[A\n"," 41% 160063/386160 [19:30<58:48:32,  1.07it/s]\u001b[A\n"," 41% 160064/386160 [19:31<58:46:53,  1.07it/s]\u001b[A\n"," 41% 160065/386160 [19:31<58:41:56,  1.07it/s]\u001b[A\n"," 41% 160066/386160 [19:32<58:41:22,  1.07it/s]\u001b[A\n"," 41% 160067/386160 [19:33<58:38:53,  1.07it/s]\u001b[A\n"," 41% 160068/386160 [19:34<58:37:49,  1.07it/s]\u001b[A\n"," 41% 160069/386160 [19:35<58:41:50,  1.07it/s]\u001b[A\n"," 41% 160070/386160 [19:36<58:48:15,  1.07it/s]\u001b[A\n"," 41% 160071/386160 [19:37<58:49:03,  1.07it/s]\u001b[A\n"," 41% 160072/386160 [19:38<58:50:37,  1.07it/s]\u001b[A\n"," 41% 160073/386160 [19:39<58:52:52,  1.07it/s]\u001b[A\n"," 41% 160074/386160 [19:40<58:53:12,  1.07it/s]\u001b[A\n"," 41% 160075/386160 [19:41<58:49:38,  1.07it/s]\u001b[A\n"," 41% 160076/386160 [19:42<58:48:15,  1.07it/s]\u001b[A\n"," 41% 160077/386160 [19:43<58:49:07,  1.07it/s]\u001b[A\n"," 41% 160078/386160 [19:44<58:50:26,  1.07it/s]\u001b[A\n"," 41% 160079/386160 [19:45<58:47:27,  1.07it/s]\u001b[A\n"," 41% 160080/386160 [19:45<58:49:07,  1.07it/s]\u001b[A\n"," 41% 160081/386160 [19:46<58:48:48,  1.07it/s]\u001b[A\n"," 41% 160082/386160 [19:47<58:50:25,  1.07it/s]\u001b[A\n"," 41% 160083/386160 [19:48<58:51:58,  1.07it/s]\u001b[A\n"," 41% 160084/386160 [19:49<58:50:54,  1.07it/s]\u001b[A\n"," 41% 160085/386160 [19:50<59:00:38,  1.06it/s]\u001b[A\n"," 41% 160086/386160 [19:51<58:53:27,  1.07it/s]\u001b[A\n"," 41% 160087/386160 [19:52<58:53:55,  1.07it/s]\u001b[A\n"," 41% 160088/386160 [19:53<58:46:45,  1.07it/s]\u001b[A\n"," 41% 160089/386160 [19:54<58:48:16,  1.07it/s]\u001b[A\n"," 41% 160090/386160 [19:55<58:49:01,  1.07it/s]\u001b[A\n"," 41% 160091/386160 [19:56<58:50:27,  1.07it/s]\u001b[A\n"," 41% 160092/386160 [19:57<59:06:19,  1.06it/s]\u001b[A\n"," 41% 160093/386160 [19:58<59:11:31,  1.06it/s]\u001b[A\n"," 41% 160094/386160 [19:59<59:01:44,  1.06it/s]\u001b[A\n"," 41% 160095/386160 [20:00<59:03:30,  1.06it/s]\u001b[A\n"," 41% 160096/386160 [20:01<59:06:19,  1.06it/s]\u001b[A\n"," 41% 160097/386160 [20:01<59:02:31,  1.06it/s]\u001b[A\n"," 41% 160098/386160 [20:02<59:02:19,  1.06it/s]\u001b[A\n"," 41% 160099/386160 [20:03<58:58:29,  1.06it/s]\u001b[A\n"," 41% 160100/386160 [20:04<58:58:02,  1.06it/s]\u001b[A\n"," 41% 160101/386160 [20:05<59:03:08,  1.06it/s]\u001b[A\n"," 41% 160102/386160 [20:06<59:01:13,  1.06it/s]\u001b[A\n"," 41% 160103/386160 [20:07<59:01:11,  1.06it/s]\u001b[A\n"," 41% 160104/386160 [20:08<59:45:35,  1.05it/s]\u001b[A\n"," 41% 160105/386160 [20:09<60:30:34,  1.04it/s]\u001b[A\n"," 41% 160106/386160 [20:10<60:47:48,  1.03it/s]\u001b[A\n"," 41% 160107/386160 [20:11<61:08:24,  1.03it/s]\u001b[A\n"," 41% 160108/386160 [20:12<61:37:47,  1.02it/s]\u001b[A\n"," 41% 160109/386160 [20:13<61:41:06,  1.02it/s]\u001b[A\n"," 41% 160110/386160 [20:14<60:55:22,  1.03it/s]\u001b[A\n"," 41% 160111/386160 [20:15<60:24:49,  1.04it/s]\u001b[A\n"," 41% 160112/386160 [20:16<59:59:31,  1.05it/s]\u001b[A\n"," 41% 160113/386160 [20:17<59:37:34,  1.05it/s]\u001b[A\n"," 41% 160114/386160 [20:18<59:17:22,  1.06it/s]\u001b[A\n"," 41% 160115/386160 [20:19<59:14:37,  1.06it/s]\u001b[A\n"," 41% 160116/386160 [20:20<59:10:33,  1.06it/s]\u001b[A\n"," 41% 160117/386160 [20:21<58:59:35,  1.06it/s]\u001b[A\n"," 41% 160118/386160 [20:21<59:00:12,  1.06it/s]\u001b[A\n"," 41% 160119/386160 [20:22<59:01:46,  1.06it/s]\u001b[A\n"," 41% 160120/386160 [20:23<59:02:16,  1.06it/s]\u001b[A\n"," 41% 160121/386160 [20:24<59:02:16,  1.06it/s]\u001b[A\n"," 41% 160122/386160 [20:25<59:00:59,  1.06it/s]\u001b[A\n"," 41% 160123/386160 [20:26<59:03:24,  1.06it/s]\u001b[A\n"," 41% 160124/386160 [20:27<59:05:49,  1.06it/s]\u001b[A\n"," 41% 160125/386160 [20:28<59:04:13,  1.06it/s]\u001b[A\n"," 41% 160126/386160 [20:29<58:59:42,  1.06it/s]\u001b[A\n"," 41% 160127/386160 [20:30<59:01:06,  1.06it/s]\u001b[A\n"," 41% 160128/386160 [20:31<59:05:05,  1.06it/s]\u001b[A\n"," 41% 160129/386160 [20:32<59:00:27,  1.06it/s]\u001b[A\n"," 41% 160130/386160 [20:33<58:59:41,  1.06it/s]\u001b[A\n"," 41% 160131/386160 [20:34<59:08:25,  1.06it/s]\u001b[A\n"," 41% 160132/386160 [20:35<59:04:12,  1.06it/s]\u001b[A\n"," 41% 160133/386160 [20:36<59:09:08,  1.06it/s]\u001b[A\n"," 41% 160134/386160 [20:37<59:02:47,  1.06it/s]\u001b[A\n"," 41% 160135/386160 [20:37<59:05:07,  1.06it/s]\u001b[A\n"," 41% 160136/386160 [20:38<59:09:23,  1.06it/s]\u001b[A\n"," 41% 160137/386160 [20:39<59:02:41,  1.06it/s]\u001b[A\n"," 41% 160138/386160 [20:40<59:04:50,  1.06it/s]\u001b[A\n"," 41% 160139/386160 [20:41<59:04:30,  1.06it/s]\u001b[A\n"," 41% 160140/386160 [20:42<58:59:55,  1.06it/s]\u001b[A\n"," 41% 160141/386160 [20:43<58:59:39,  1.06it/s]\u001b[A\n"," 41% 160142/386160 [20:44<58:57:10,  1.06it/s]\u001b[A\n"," 41% 160143/386160 [20:45<58:56:50,  1.07it/s]\u001b[A\n"," 41% 160144/386160 [20:46<58:59:40,  1.06it/s]\u001b[A\n"," 41% 160145/386160 [20:47<59:00:10,  1.06it/s]\u001b[A\n"," 41% 160146/386160 [20:48<58:56:46,  1.07it/s]\u001b[A\n"," 41% 160147/386160 [20:49<58:53:10,  1.07it/s]\u001b[A\n"," 41% 160148/386160 [20:50<59:01:02,  1.06it/s]\u001b[A\n"," 41% 160149/386160 [20:51<58:59:14,  1.06it/s]\u001b[A\n"," 41% 160150/386160 [20:52<58:55:56,  1.07it/s]\u001b[A\n"," 41% 160151/386160 [20:52<59:03:02,  1.06it/s]\u001b[A\n"," 41% 160152/386160 [20:53<58:56:53,  1.07it/s]\u001b[A\n"," 41% 160153/386160 [20:54<58:52:38,  1.07it/s]\u001b[A\n"," 41% 160154/386160 [20:55<58:53:14,  1.07it/s]\u001b[A\n"," 41% 160155/386160 [20:56<58:59:54,  1.06it/s]\u001b[A\n"," 41% 160156/386160 [20:57<58:59:35,  1.06it/s]\u001b[A\n"," 41% 160157/386160 [20:58<58:59:31,  1.06it/s]\u001b[A\n"," 41% 160158/386160 [20:59<58:55:48,  1.07it/s]\u001b[A\n"," 41% 160159/386160 [21:00<58:54:32,  1.07it/s]\u001b[A\n"," 41% 160160/386160 [21:01<59:01:26,  1.06it/s]\u001b[A\n"," 41% 160161/386160 [21:02<58:53:57,  1.07it/s]\u001b[A\n"," 41% 160162/386160 [21:03<58:56:11,  1.07it/s]\u001b[A\n"," 41% 160163/386160 [21:04<58:57:22,  1.06it/s]\u001b[A\n"," 41% 160164/386160 [21:05<58:54:37,  1.07it/s]\u001b[A\n"," 41% 160165/386160 [21:06<58:48:43,  1.07it/s]\u001b[A\n"," 41% 160166/386160 [21:07<58:46:18,  1.07it/s]\u001b[A\n"," 41% 160167/386160 [21:07<58:47:28,  1.07it/s]\u001b[A\n"," 41% 160168/386160 [21:08<58:52:14,  1.07it/s]\u001b[A\n"," 41% 160169/386160 [21:09<58:47:51,  1.07it/s]\u001b[A\n"," 41% 160170/386160 [21:10<58:48:30,  1.07it/s]\u001b[A\n"," 41% 160171/386160 [21:11<58:54:20,  1.07it/s]\u001b[A\n"," 41% 160172/386160 [21:12<58:53:38,  1.07it/s]\u001b[A\n"," 41% 160173/386160 [21:13<58:48:03,  1.07it/s]\u001b[A\n"," 41% 160174/386160 [21:14<58:51:53,  1.07it/s]\u001b[A\n"," 41% 160175/386160 [21:15<58:53:00,  1.07it/s]\u001b[A\n"," 41% 160176/386160 [21:16<58:52:32,  1.07it/s]\u001b[A\n"," 41% 160177/386160 [21:17<58:52:39,  1.07it/s]\u001b[A\n"," 41% 160178/386160 [21:18<58:57:18,  1.06it/s]\u001b[A\n"," 41% 160179/386160 [21:19<58:59:07,  1.06it/s]\u001b[A\n"," 41% 160180/386160 [21:20<59:07:03,  1.06it/s]\u001b[A\n"," 41% 160181/386160 [21:21<59:08:31,  1.06it/s]\u001b[A\n"," 41% 160182/386160 [21:22<59:03:45,  1.06it/s]\u001b[A\n"," 41% 160183/386160 [21:23<58:57:25,  1.06it/s]\u001b[A\n"," 41% 160184/386160 [21:23<58:54:49,  1.07it/s]\u001b[A\n"," 41% 160185/386160 [21:24<59:04:57,  1.06it/s]\u001b[A\n"," 41% 160186/386160 [21:25<58:59:08,  1.06it/s]\u001b[A\n"," 41% 160187/386160 [21:26<59:03:28,  1.06it/s]\u001b[A\n"," 41% 160188/386160 [21:27<58:59:29,  1.06it/s]\u001b[A\n"," 41% 160189/386160 [21:28<58:52:43,  1.07it/s]\u001b[A\n"," 41% 160190/386160 [21:29<58:50:58,  1.07it/s]\u001b[A\n"," 41% 160191/386160 [21:30<58:55:36,  1.07it/s]\u001b[A\n"," 41% 160192/386160 [21:31<59:01:23,  1.06it/s]\u001b[A\n"," 41% 160193/386160 [21:32<58:57:44,  1.06it/s]\u001b[A\n"," 41% 160194/386160 [21:33<58:56:57,  1.06it/s]\u001b[A\n"," 41% 160195/386160 [21:34<58:57:28,  1.06it/s]\u001b[A\n"," 41% 160196/386160 [21:35<58:57:37,  1.06it/s]\u001b[A\n"," 41% 160197/386160 [21:36<58:55:40,  1.07it/s]\u001b[A\n"," 41% 160198/386160 [21:37<58:56:21,  1.06it/s]\u001b[A\n"," 41% 160199/386160 [21:38<58:55:06,  1.07it/s]\u001b[A\n"," 41% 160200/386160 [21:38<58:51:55,  1.07it/s]\u001b[A\n"," 41% 160201/386160 [21:39<58:53:08,  1.07it/s]\u001b[A\n"," 41% 160202/386160 [21:40<59:00:06,  1.06it/s]\u001b[A\n"," 41% 160203/386160 [21:41<58:57:02,  1.06it/s]\u001b[A\n"," 41% 160204/386160 [21:42<58:55:35,  1.07it/s]\u001b[A\n"," 41% 160205/386160 [21:43<58:57:56,  1.06it/s]\u001b[A\n"," 41% 160206/386160 [21:44<58:56:39,  1.06it/s]\u001b[A\n"," 41% 160207/386160 [21:45<58:54:39,  1.07it/s]\u001b[A\n"," 41% 160208/386160 [21:46<58:51:35,  1.07it/s]\u001b[A\n"," 41% 160209/386160 [21:47<58:46:49,  1.07it/s]\u001b[A\n"," 41% 160210/386160 [21:48<58:51:50,  1.07it/s]\u001b[A\n"," 41% 160211/386160 [21:49<58:55:08,  1.07it/s]\u001b[A\n"," 41% 160212/386160 [21:50<58:55:16,  1.07it/s]\u001b[A\n"," 41% 160213/386160 [21:51<58:57:33,  1.06it/s]\u001b[A\n"," 41% 160214/386160 [21:52<58:54:19,  1.07it/s]\u001b[A\n"," 41% 160215/386160 [21:53<58:50:32,  1.07it/s]\u001b[A\n"," 41% 160216/386160 [21:53<58:49:21,  1.07it/s]\u001b[A\n"," 41% 160217/386160 [21:54<58:49:24,  1.07it/s]\u001b[A\n"," 41% 160218/386160 [21:55<58:55:03,  1.07it/s]\u001b[A\n"," 41% 160219/386160 [21:56<58:57:14,  1.06it/s]\u001b[A\n"," 41% 160220/386160 [21:57<59:00:52,  1.06it/s]\u001b[A\n"," 41% 160221/386160 [21:58<58:52:46,  1.07it/s]\u001b[A\n"," 41% 160222/386160 [21:59<58:49:33,  1.07it/s]\u001b[A\n"," 41% 160223/386160 [22:00<58:53:52,  1.07it/s]\u001b[A\n"," 41% 160224/386160 [22:01<58:53:59,  1.07it/s]\u001b[A\n"," 41% 160225/386160 [22:02<58:55:18,  1.07it/s]\u001b[A\n"," 41% 160226/386160 [22:03<59:02:53,  1.06it/s]\u001b[A\n"," 41% 160227/386160 [22:04<59:28:49,  1.06it/s]\u001b[A\n"," 41% 160228/386160 [22:05<60:12:50,  1.04it/s]\u001b[A\n"," 41% 160229/386160 [22:06<61:12:14,  1.03it/s]\u001b[A\n"," 41% 160230/386160 [22:07<61:04:06,  1.03it/s]\u001b[A\n"," 41% 160231/386160 [22:08<61:50:24,  1.01it/s]\u001b[A\n"," 41% 160232/386160 [22:09<61:44:10,  1.02it/s]\u001b[A\n"," 41% 160233/386160 [22:10<61:00:41,  1.03it/s]\u001b[A\n"," 41% 160234/386160 [22:11<60:25:05,  1.04it/s]\u001b[A\n"," 41% 160235/386160 [22:12<60:01:49,  1.05it/s]\u001b[A\n"," 41% 160236/386160 [22:13<59:40:07,  1.05it/s]\u001b[A\n"," 41% 160237/386160 [22:14<59:26:52,  1.06it/s]\u001b[A\n"," 41% 160238/386160 [22:14<59:17:03,  1.06it/s]\u001b[A\n"," 41% 160239/386160 [22:15<59:10:04,  1.06it/s]\u001b[A\n"," 41% 160240/386160 [22:16<59:12:50,  1.06it/s]\u001b[A\n"," 41% 160241/386160 [22:17<59:05:20,  1.06it/s]\u001b[A\n"," 41% 160242/386160 [22:18<59:09:01,  1.06it/s]\u001b[A\n"," 41% 160243/386160 [22:19<59:08:16,  1.06it/s]\u001b[A\n"," 41% 160244/386160 [22:20<59:08:02,  1.06it/s]\u001b[A\n"," 41% 160245/386160 [22:21<59:05:28,  1.06it/s]\u001b[A\n"," 41% 160246/386160 [22:22<59:02:20,  1.06it/s]\u001b[A\n"," 41% 160247/386160 [22:23<59:04:58,  1.06it/s]\u001b[A\n"," 41% 160248/386160 [22:24<59:00:52,  1.06it/s]\u001b[A\n"," 41% 160249/386160 [22:25<58:59:12,  1.06it/s]\u001b[A\n"," 41% 160250/386160 [22:26<58:55:17,  1.07it/s]\u001b[A\n"," 41% 160251/386160 [22:27<59:05:52,  1.06it/s]\u001b[A\n"," 41% 160252/386160 [22:28<59:05:38,  1.06it/s]\u001b[A\n"," 41% 160253/386160 [22:29<59:01:52,  1.06it/s]\u001b[A\n"," 41% 160254/386160 [22:30<59:03:09,  1.06it/s]\u001b[A\n"," 41% 160255/386160 [22:30<59:10:17,  1.06it/s]\u001b[A\n"," 41% 160256/386160 [22:31<59:08:36,  1.06it/s]\u001b[A\n"," 42% 160257/386160 [22:32<59:09:43,  1.06it/s]\u001b[A\n"," 42% 160258/386160 [22:33<59:05:24,  1.06it/s]\u001b[A\n"," 42% 160259/386160 [22:34<59:00:10,  1.06it/s]\u001b[A\n"," 42% 160260/386160 [22:35<59:02:23,  1.06it/s]\u001b[A\n"," 42% 160261/386160 [22:36<59:03:32,  1.06it/s]\u001b[A\n"," 42% 160262/386160 [22:37<58:57:07,  1.06it/s]\u001b[A\n"," 42% 160263/386160 [22:38<59:00:50,  1.06it/s]\u001b[A\n"," 42% 160264/386160 [22:39<58:56:02,  1.06it/s]\u001b[A\n"," 42% 160265/386160 [22:40<58:58:55,  1.06it/s]\u001b[A\n"," 42% 160266/386160 [22:41<58:54:59,  1.07it/s]\u001b[A\n"," 42% 160267/386160 [22:42<59:02:22,  1.06it/s]\u001b[A\n"," 42% 160268/386160 [22:43<58:56:47,  1.06it/s]\u001b[A\n"," 42% 160269/386160 [22:44<58:50:13,  1.07it/s]\u001b[A\n"," 42% 160270/386160 [22:45<58:47:13,  1.07it/s]\u001b[A\n"," 42% 160271/386160 [22:45<58:52:41,  1.07it/s]\u001b[A\n"," 42% 160272/386160 [22:46<58:54:08,  1.07it/s]\u001b[A\n"," 42% 160273/386160 [22:47<58:52:45,  1.07it/s]\u001b[A\n"," 42% 160274/386160 [22:48<58:56:19,  1.06it/s]\u001b[A\n"," 42% 160275/386160 [22:49<59:01:20,  1.06it/s]\u001b[A\n"," 42% 160276/386160 [22:50<58:56:24,  1.06it/s]\u001b[A\n"," 42% 160277/386160 [22:51<58:57:29,  1.06it/s]\u001b[A\n"," 42% 160278/386160 [22:52<58:58:43,  1.06it/s]\u001b[A\n"," 42% 160279/386160 [22:53<59:01:19,  1.06it/s]\u001b[A\n"," 42% 160280/386160 [22:54<59:02:34,  1.06it/s]\u001b[A\n"," 42% 160281/386160 [22:55<59:03:45,  1.06it/s]\u001b[A\n"," 42% 160282/386160 [22:56<59:02:58,  1.06it/s]\u001b[A\n"," 42% 160283/386160 [22:57<58:58:40,  1.06it/s]\u001b[A\n"," 42% 160284/386160 [22:58<59:02:37,  1.06it/s]\u001b[A\n"," 42% 160285/386160 [22:59<59:04:04,  1.06it/s]\u001b[A\n"," 42% 160286/386160 [23:00<58:56:17,  1.06it/s]\u001b[A\n"," 42% 160287/386160 [23:01<58:53:12,  1.07it/s]\u001b[A\n"," 42% 160288/386160 [23:01<58:56:47,  1.06it/s]\u001b[A\n"," 42% 160289/386160 [23:02<58:56:48,  1.06it/s]\u001b[A\n"," 42% 160290/386160 [23:03<59:02:31,  1.06it/s]\u001b[A\n"," 42% 160291/386160 [23:04<58:58:23,  1.06it/s]\u001b[A\n"," 42% 160292/386160 [23:05<58:59:08,  1.06it/s]\u001b[A\n"," 42% 160293/386160 [23:06<58:58:12,  1.06it/s]\u001b[A\n"," 42% 160294/386160 [23:07<58:50:54,  1.07it/s]\u001b[A\n"," 42% 160295/386160 [23:08<58:59:09,  1.06it/s]\u001b[A\n"," 42% 160296/386160 [23:09<59:00:18,  1.06it/s]\u001b[A\n"," 42% 160297/386160 [23:10<58:55:41,  1.06it/s]\u001b[A\n"," 42% 160298/386160 [23:11<59:02:48,  1.06it/s]\u001b[A\n"," 42% 160299/386160 [23:12<59:00:25,  1.06it/s]\u001b[A\n"," 42% 160300/386160 [23:13<59:01:17,  1.06it/s]\u001b[A\n"," 42% 160301/386160 [23:14<59:02:30,  1.06it/s]\u001b[A\n"," 42% 160302/386160 [23:15<58:54:43,  1.06it/s]\u001b[A\n"," 42% 160303/386160 [23:16<58:58:22,  1.06it/s]\u001b[A\n"," 42% 160304/386160 [23:17<59:05:05,  1.06it/s]\u001b[A\n"," 42% 160305/386160 [23:17<58:59:45,  1.06it/s]\u001b[A\n"," 42% 160306/386160 [23:18<59:12:38,  1.06it/s]\u001b[A\n"," 42% 160307/386160 [23:19<59:09:07,  1.06it/s]\u001b[A\n"," 42% 160308/386160 [23:20<59:05:54,  1.06it/s]\u001b[A\n"," 42% 160309/386160 [23:21<59:08:48,  1.06it/s]\u001b[A\n"," 42% 160310/386160 [23:22<59:01:53,  1.06it/s]\u001b[A\n"," 42% 160311/386160 [23:23<58:59:16,  1.06it/s]\u001b[A\n"," 42% 160312/386160 [23:24<59:02:26,  1.06it/s]\u001b[A\n"," 42% 160313/386160 [23:25<58:57:27,  1.06it/s]\u001b[A\n"," 42% 160314/386160 [23:26<58:56:56,  1.06it/s]\u001b[A\n"," 42% 160315/386160 [23:27<58:54:50,  1.06it/s]\u001b[A\n"," 42% 160316/386160 [23:28<58:59:41,  1.06it/s]\u001b[A\n"," 42% 160317/386160 [23:29<59:28:36,  1.05it/s]\u001b[A\n"," 42% 160318/386160 [23:30<59:15:49,  1.06it/s]\u001b[A\n"," 42% 160319/386160 [23:31<59:12:59,  1.06it/s]\u001b[A\n"," 42% 160320/386160 [23:32<59:06:09,  1.06it/s]\u001b[A\n"," 42% 160321/386160 [23:33<58:57:52,  1.06it/s]\u001b[A\n"," 42% 160322/386160 [23:33<58:51:57,  1.07it/s]\u001b[A\n"," 42% 160323/386160 [23:34<58:59:01,  1.06it/s]\u001b[A\n"," 42% 160324/386160 [23:35<58:55:01,  1.06it/s]\u001b[A\n"," 42% 160325/386160 [23:36<58:55:38,  1.06it/s]\u001b[A\n"," 42% 160326/386160 [23:37<58:53:36,  1.07it/s]\u001b[A\n"," 42% 160327/386160 [23:38<58:53:35,  1.07it/s]\u001b[A\n"," 42% 160328/386160 [23:39<58:56:20,  1.06it/s]\u001b[A\n"," 42% 160329/386160 [23:40<59:08:22,  1.06it/s]\u001b[A\n"," 42% 160330/386160 [23:41<59:01:38,  1.06it/s]\u001b[A\n"," 42% 160331/386160 [23:42<59:04:15,  1.06it/s]\u001b[A\n"," 42% 160332/386160 [23:43<59:03:19,  1.06it/s]\u001b[A\n"," 42% 160333/386160 [23:44<59:03:53,  1.06it/s]\u001b[A\n"," 42% 160334/386160 [23:45<58:59:24,  1.06it/s]\u001b[A\n"," 42% 160335/386160 [23:46<59:00:22,  1.06it/s]\u001b[A\n"," 42% 160336/386160 [23:47<58:57:53,  1.06it/s]\u001b[A\n"," 42% 160337/386160 [23:48<58:55:43,  1.06it/s]\u001b[A\n"," 42% 160338/386160 [23:49<58:55:01,  1.06it/s]\u001b[A\n"," 42% 160339/386160 [23:49<58:57:58,  1.06it/s]\u001b[A\n"," 42% 160340/386160 [23:50<58:56:11,  1.06it/s]\u001b[A\n"," 42% 160341/386160 [23:51<58:58:34,  1.06it/s]\u001b[A\n"," 42% 160342/386160 [23:52<59:01:57,  1.06it/s]\u001b[A\n"," 42% 160343/386160 [23:53<58:59:27,  1.06it/s]\u001b[A\n"," 42% 160344/386160 [23:54<58:57:23,  1.06it/s]\u001b[A\n"," 42% 160345/386160 [23:55<58:56:34,  1.06it/s]\u001b[A\n"," 42% 160346/386160 [23:56<58:57:39,  1.06it/s]\u001b[A\n"," 42% 160347/386160 [23:57<58:59:36,  1.06it/s]\u001b[A\n"," 42% 160348/386160 [23:58<59:03:42,  1.06it/s]\u001b[A\n"," 42% 160349/386160 [23:59<58:57:27,  1.06it/s]\u001b[A\n"," 42% 160350/386160 [24:00<58:56:46,  1.06it/s]\u001b[A\n"," 42% 160351/386160 [24:01<59:33:11,  1.05it/s]\u001b[A\n"," 42% 160352/386160 [24:02<60:16:18,  1.04it/s]\u001b[A\n"," 42% 160353/386160 [24:03<60:53:26,  1.03it/s]\u001b[A\n"," 42% 160354/386160 [24:04<61:33:56,  1.02it/s]\u001b[A\n"," 42% 160355/386160 [24:05<61:54:46,  1.01it/s]\u001b[A\n"," 42% 160356/386160 [24:06<61:55:09,  1.01it/s]\u001b[A\n"," 42% 160357/386160 [24:07<61:06:18,  1.03it/s]\u001b[A\n"," 42% 160358/386160 [24:08<60:27:07,  1.04it/s]\u001b[A\n"," 42% 160359/386160 [24:09<59:57:12,  1.05it/s]\u001b[A\n"," 42% 160360/386160 [24:10<59:40:51,  1.05it/s]\u001b[A\n"," 42% 160361/386160 [24:10<59:23:50,  1.06it/s]\u001b[A\n"," 42% 160362/386160 [24:11<59:14:27,  1.06it/s]\u001b[A\n"," 42% 160363/386160 [24:12<59:09:18,  1.06it/s]\u001b[A\n"," 42% 160364/386160 [24:13<58:59:50,  1.06it/s]\u001b[A\n"," 42% 160365/386160 [24:14<59:01:40,  1.06it/s]\u001b[A\n"," 42% 160366/386160 [24:15<59:05:34,  1.06it/s]\u001b[A\n"," 42% 160367/386160 [24:16<59:07:39,  1.06it/s]\u001b[A\n"," 42% 160368/386160 [24:17<59:05:30,  1.06it/s]\u001b[A\n"," 42% 160369/386160 [24:18<59:05:14,  1.06it/s]\u001b[A\n"," 42% 160370/386160 [24:19<58:58:49,  1.06it/s]\u001b[A\n"," 42% 160371/386160 [24:20<58:57:33,  1.06it/s]\u001b[A\n"," 42% 160372/386160 [24:21<59:03:45,  1.06it/s]\u001b[A\n"," 42% 160373/386160 [24:22<59:03:11,  1.06it/s]\u001b[A\n"," 42% 160374/386160 [24:23<59:01:58,  1.06it/s]\u001b[A\n"," 42% 160375/386160 [24:24<58:56:10,  1.06it/s]\u001b[A\n"," 42% 160376/386160 [24:25<58:52:39,  1.07it/s]\u001b[A\n"," 42% 160377/386160 [24:25<59:04:37,  1.06it/s]\u001b[A\n"," 42% 160378/386160 [24:26<59:04:56,  1.06it/s]\u001b[A\n"," 42% 160379/386160 [24:27<59:06:24,  1.06it/s]\u001b[A\n"," 42% 160380/386160 [24:28<59:09:16,  1.06it/s]\u001b[A\n"," 42% 160381/386160 [24:29<59:01:24,  1.06it/s]\u001b[A\n"," 42% 160382/386160 [24:30<58:56:39,  1.06it/s]\u001b[A\n"," 42% 160383/386160 [24:31<59:03:58,  1.06it/s]\u001b[A\n"," 42% 160384/386160 [24:32<58:57:44,  1.06it/s]\u001b[A\n"," 42% 160385/386160 [24:33<59:05:22,  1.06it/s]\u001b[A\n"," 42% 160386/386160 [24:34<58:56:22,  1.06it/s]\u001b[A\n"," 42% 160387/386160 [24:35<58:50:58,  1.07it/s]\u001b[A\n"," 42% 160388/386160 [24:36<59:02:48,  1.06it/s]\u001b[A\n"," 42% 160389/386160 [24:37<58:56:07,  1.06it/s]\u001b[A\n"," 42% 160390/386160 [24:38<58:57:50,  1.06it/s]\u001b[A\n"," 42% 160391/386160 [24:39<58:58:03,  1.06it/s]\u001b[A\n"," 42% 160392/386160 [24:40<58:59:53,  1.06it/s]\u001b[A\n"," 42% 160393/386160 [24:41<59:07:26,  1.06it/s]\u001b[A\n"," 42% 160394/386160 [24:41<59:05:52,  1.06it/s]\u001b[A\n"," 42% 160395/386160 [24:42<59:02:34,  1.06it/s]\u001b[A\n"," 42% 160396/386160 [24:43<59:04:30,  1.06it/s]\u001b[A\n"," 42% 160397/386160 [24:44<59:03:44,  1.06it/s]\u001b[A\n"," 42% 160398/386160 [24:45<59:00:15,  1.06it/s]\u001b[A\n"," 42% 160399/386160 [24:46<59:02:09,  1.06it/s]\u001b[A\n"," 42% 160400/386160 [24:47<58:56:55,  1.06it/s]\u001b[A\n"," 42% 160401/386160 [24:48<58:55:23,  1.06it/s]\u001b[A\n"," 42% 160402/386160 [24:49<58:58:49,  1.06it/s]\u001b[A\n"," 42% 160403/386160 [24:50<58:54:58,  1.06it/s]\u001b[A\n"," 42% 160404/386160 [24:51<58:57:28,  1.06it/s]\u001b[A\n"," 42% 160405/386160 [24:52<59:02:58,  1.06it/s]\u001b[A\n"," 42% 160406/386160 [24:53<59:12:53,  1.06it/s]\u001b[A\n"," 42% 160407/386160 [24:54<59:05:18,  1.06it/s]\u001b[A\n"," 42% 160408/386160 [24:55<58:54:00,  1.06it/s]\u001b[A\n"," 42% 160409/386160 [24:56<59:00:04,  1.06it/s]\u001b[A\n"," 42% 160410/386160 [24:57<58:57:54,  1.06it/s]\u001b[A\n"," 42% 160411/386160 [24:57<59:01:08,  1.06it/s]\u001b[A\n"," 42% 160412/386160 [24:58<59:07:47,  1.06it/s]\u001b[A\n"," 42% 160413/386160 [24:59<59:00:28,  1.06it/s]\u001b[A\n"," 42% 160414/386160 [25:00<59:02:21,  1.06it/s]\u001b[A\n"," 42% 160415/386160 [25:01<59:00:09,  1.06it/s]\u001b[A\n"," 42% 160416/386160 [25:02<58:57:08,  1.06it/s]\u001b[A\n"," 42% 160417/386160 [25:03<58:59:07,  1.06it/s]\u001b[A\n"," 42% 160418/386160 [25:04<59:02:37,  1.06it/s]\u001b[A\n"," 42% 160419/386160 [25:05<58:55:21,  1.06it/s]\u001b[A\n"," 42% 160420/386160 [25:06<58:58:13,  1.06it/s]\u001b[A\n"," 42% 160421/386160 [25:07<58:57:09,  1.06it/s]\u001b[A\n"," 42% 160422/386160 [25:08<58:56:45,  1.06it/s]\u001b[A\n"," 42% 160423/386160 [25:09<59:06:21,  1.06it/s]\u001b[A\n"," 42% 160424/386160 [25:10<59:03:51,  1.06it/s]\u001b[A\n"," 42% 160425/386160 [25:11<59:00:14,  1.06it/s]\u001b[A\n"," 42% 160426/386160 [25:12<58:54:34,  1.06it/s]\u001b[A\n"," 42% 160427/386160 [25:13<58:57:38,  1.06it/s]\u001b[A\n"," 42% 160428/386160 [25:13<59:00:00,  1.06it/s]\u001b[A\n"," 42% 160429/386160 [25:14<58:59:15,  1.06it/s]\u001b[A\n"," 42% 160430/386160 [25:15<59:10:18,  1.06it/s]\u001b[A\n"," 42% 160431/386160 [25:16<59:05:23,  1.06it/s]\u001b[A\n"," 42% 160432/386160 [25:17<58:59:20,  1.06it/s]\u001b[A\n"," 42% 160433/386160 [25:18<58:59:03,  1.06it/s]\u001b[A\n"," 42% 160434/386160 [25:19<59:00:52,  1.06it/s]\u001b[A\n"," 42% 160435/386160 [25:20<58:56:28,  1.06it/s]\u001b[A\n"," 42% 160436/386160 [25:21<59:03:02,  1.06it/s]\u001b[A\n"," 42% 160437/386160 [25:22<58:57:39,  1.06it/s]\u001b[A\n"," 42% 160438/386160 [25:23<58:58:15,  1.06it/s]\u001b[A\n"," 42% 160439/386160 [25:24<58:56:38,  1.06it/s]\u001b[A\n"," 42% 160440/386160 [25:25<58:53:21,  1.06it/s]\u001b[A\n"," 42% 160441/386160 [25:26<59:04:06,  1.06it/s]\u001b[A\n"," 42% 160442/386160 [25:27<58:58:19,  1.06it/s]\u001b[A\n"," 42% 160443/386160 [25:28<59:07:55,  1.06it/s]\u001b[A\n"," 42% 160444/386160 [25:29<59:08:37,  1.06it/s]\u001b[A\n"," 42% 160445/386160 [25:29<59:06:40,  1.06it/s]\u001b[A\n"," 42% 160446/386160 [25:30<59:00:34,  1.06it/s]\u001b[A\n"," 42% 160447/386160 [25:31<59:07:39,  1.06it/s]\u001b[A\n"," 42% 160448/386160 [25:32<59:02:11,  1.06it/s]\u001b[A\n"," 42% 160449/386160 [25:33<59:01:41,  1.06it/s]\u001b[A\n"," 42% 160450/386160 [25:34<58:55:27,  1.06it/s]\u001b[A\n"," 42% 160451/386160 [25:35<58:52:52,  1.06it/s]\u001b[A\n"," 42% 160452/386160 [25:36<59:01:16,  1.06it/s]\u001b[A\n"," 42% 160453/386160 [25:37<58:59:25,  1.06it/s]\u001b[A\n"," 42% 160454/386160 [25:38<59:08:29,  1.06it/s]\u001b[A\n"," 42% 160455/386160 [25:39<59:06:39,  1.06it/s]\u001b[A\n"," 42% 160456/386160 [25:40<59:00:41,  1.06it/s]\u001b[A\n"," 42% 160457/386160 [25:41<58:56:58,  1.06it/s]\u001b[A\n"," 42% 160458/386160 [25:42<58:55:19,  1.06it/s]\u001b[A\n"," 42% 160459/386160 [25:43<58:53:14,  1.06it/s]\u001b[A\n"," 42% 160460/386160 [25:44<58:52:40,  1.06it/s]\u001b[A\n"," 42% 160461/386160 [25:45<58:54:25,  1.06it/s]\u001b[A\n"," 42% 160462/386160 [25:45<58:56:06,  1.06it/s]\u001b[A\n"," 42% 160463/386160 [25:46<58:56:57,  1.06it/s]\u001b[A\n"," 42% 160464/386160 [25:47<59:00:07,  1.06it/s]\u001b[A\n"," 42% 160465/386160 [25:48<58:52:35,  1.06it/s]\u001b[A\n"," 42% 160466/386160 [25:49<58:55:53,  1.06it/s]\u001b[A\n"," 42% 160467/386160 [25:50<59:03:07,  1.06it/s]\u001b[A\n"," 42% 160468/386160 [25:51<59:08:19,  1.06it/s]\u001b[A\n"," 42% 160469/386160 [25:52<59:13:02,  1.06it/s]\u001b[A\n"," 42% 160470/386160 [25:53<59:04:23,  1.06it/s]\u001b[A\n"," 42% 160471/386160 [25:54<58:59:03,  1.06it/s]\u001b[A\n"," 42% 160472/386160 [25:55<58:58:38,  1.06it/s]\u001b[A\n"," 42% 160473/386160 [25:56<58:56:18,  1.06it/s]\u001b[A\n"," 42% 160474/386160 [25:57<59:07:22,  1.06it/s]\u001b[A\n"," 42% 160475/386160 [25:58<59:47:24,  1.05it/s]\u001b[A\n"," 42% 160476/386160 [25:59<60:38:21,  1.03it/s]\u001b[A\n"," 42% 160477/386160 [26:00<60:55:24,  1.03it/s]\u001b[A\n"," 42% 160478/386160 [26:01<61:14:46,  1.02it/s]\u001b[A\n"," 42% 160479/386160 [26:02<61:45:48,  1.01it/s]\u001b[A\n"," 42% 160480/386160 [26:03<61:23:32,  1.02it/s]\u001b[A\n"," 42% 160481/386160 [26:04<60:40:24,  1.03it/s]\u001b[A\n"," 42% 160482/386160 [26:05<60:09:29,  1.04it/s]\u001b[A\n"," 42% 160483/386160 [26:06<59:49:49,  1.05it/s]\u001b[A\n"," 42% 160484/386160 [26:06<59:37:26,  1.05it/s]\u001b[A\n"," 42% 160485/386160 [26:07<59:27:05,  1.05it/s]\u001b[A\n"," 42% 160486/386160 [26:08<59:20:39,  1.06it/s]\u001b[A\n"," 42% 160487/386160 [26:09<59:11:34,  1.06it/s]\u001b[A\n"," 42% 160488/386160 [26:10<59:04:00,  1.06it/s]\u001b[A\n"," 42% 160489/386160 [26:11<58:59:57,  1.06it/s]\u001b[A\n"," 42% 160490/386160 [26:12<58:56:43,  1.06it/s]\u001b[A\n"," 42% 160491/386160 [26:13<58:50:39,  1.07it/s]\u001b[A\n"," 42% 160492/386160 [26:14<58:46:00,  1.07it/s]\u001b[A\n"," 42% 160493/386160 [26:15<58:42:57,  1.07it/s]\u001b[A\n"," 42% 160494/386160 [26:16<58:45:10,  1.07it/s]\u001b[A\n"," 42% 160495/386160 [26:17<58:47:16,  1.07it/s]\u001b[A\n"," 42% 160496/386160 [26:18<58:52:41,  1.06it/s]\u001b[A\n"," 42% 160497/386160 [26:19<58:58:16,  1.06it/s]\u001b[A\n"," 42% 160498/386160 [26:20<59:01:43,  1.06it/s]\u001b[A\n"," 42% 160499/386160 [26:21<59:01:29,  1.06it/s]\u001b[A\n"," 42% 160500/386160 [26:21<58:55:53,  1.06it/s]\u001b[A\n"," 42% 160501/386160 [26:22<58:56:30,  1.06it/s]\u001b[A\n"," 42% 160502/386160 [26:23<58:59:24,  1.06it/s]\u001b[A\n"," 42% 160503/386160 [26:24<59:00:49,  1.06it/s]\u001b[A\n"," 42% 160504/386160 [26:25<58:58:37,  1.06it/s]\u001b[A\n"," 42% 160505/386160 [26:26<58:54:53,  1.06it/s]\u001b[A\n"," 42% 160506/386160 [26:27<59:07:37,  1.06it/s]\u001b[A\n"," 42% 160507/386160 [26:28<59:03:59,  1.06it/s]\u001b[A\n"," 42% 160508/386160 [26:29<59:01:31,  1.06it/s]\u001b[A\n"," 42% 160509/386160 [26:30<58:53:17,  1.06it/s]\u001b[A\n"," 42% 160510/386160 [26:31<58:55:18,  1.06it/s]\u001b[A\n"," 42% 160511/386160 [26:32<58:58:36,  1.06it/s]\u001b[A\n"," 42% 160512/386160 [26:33<58:53:55,  1.06it/s]\u001b[A\n"," 42% 160513/386160 [26:34<58:59:46,  1.06it/s]\u001b[A\n"," 42% 160514/386160 [26:35<58:53:54,  1.06it/s]\u001b[A\n"," 42% 160515/386160 [26:36<58:58:26,  1.06it/s]\u001b[A\n"," 42% 160516/386160 [26:37<58:55:14,  1.06it/s]\u001b[A\n"," 42% 160517/386160 [26:37<58:51:21,  1.06it/s]\u001b[A\n"," 42% 160518/386160 [26:38<59:00:09,  1.06it/s]\u001b[A\n"," 42% 160519/386160 [26:39<58:56:01,  1.06it/s]\u001b[A\n"," 42% 160520/386160 [26:40<58:56:57,  1.06it/s]\u001b[A\n"," 42% 160521/386160 [26:41<58:52:04,  1.06it/s]\u001b[A\n"," 42% 160522/386160 [26:42<58:52:09,  1.06it/s]\u001b[A\n"," 42% 160523/386160 [26:43<58:57:17,  1.06it/s]\u001b[A\n"," 42% 160524/386160 [26:44<58:50:33,  1.07it/s]\u001b[A\n"," 42% 160525/386160 [26:45<58:46:24,  1.07it/s]\u001b[A\n"," 42% 160526/386160 [26:46<58:54:49,  1.06it/s]\u001b[A\n"," 42% 160527/386160 [26:47<58:48:01,  1.07it/s]\u001b[A\n"," 42% 160528/386160 [26:48<58:45:19,  1.07it/s]\u001b[A\n"," 42% 160529/386160 [26:49<58:54:11,  1.06it/s]\u001b[A\n"," 42% 160530/386160 [26:50<58:47:07,  1.07it/s]\u001b[A\n"," 42% 160531/386160 [26:51<58:48:00,  1.07it/s]\u001b[A\n"," 42% 160532/386160 [26:52<58:45:49,  1.07it/s]\u001b[A\n"," 42% 160533/386160 [26:53<58:46:36,  1.07it/s]\u001b[A\n"," 42% 160534/386160 [26:53<58:52:06,  1.06it/s]\u001b[A\n"," 42% 160535/386160 [26:54<58:48:46,  1.07it/s]\u001b[A\n"," 42% 160536/386160 [26:55<58:43:32,  1.07it/s]\u001b[A\n"," 42% 160537/386160 [26:56<58:43:30,  1.07it/s]\u001b[A\n"," 42% 160538/386160 [26:57<58:39:39,  1.07it/s]\u001b[A\n"," 42% 160539/386160 [26:58<58:46:08,  1.07it/s]\u001b[A\n"," 42% 160540/386160 [26:59<58:47:47,  1.07it/s]\u001b[A\n"," 42% 160541/386160 [27:00<58:43:53,  1.07it/s]\u001b[A\n"," 42% 160542/386160 [27:01<58:45:22,  1.07it/s]\u001b[A\n"," 42% 160543/386160 [27:02<58:41:05,  1.07it/s]\u001b[A\n"," 42% 160544/386160 [27:03<58:48:19,  1.07it/s]\u001b[A\n"," 42% 160545/386160 [27:04<58:46:53,  1.07it/s]\u001b[A\n"," 42% 160546/386160 [27:05<58:45:25,  1.07it/s]\u001b[A\n"," 42% 160547/386160 [27:06<58:48:39,  1.07it/s]\u001b[A\n"," 42% 160548/386160 [27:07<58:47:28,  1.07it/s]\u001b[A\n"," 42% 160549/386160 [27:08<58:48:46,  1.07it/s]\u001b[A\n"," 42% 160550/386160 [27:08<58:43:59,  1.07it/s]\u001b[A\n"," 42% 160551/386160 [27:09<58:42:38,  1.07it/s]\u001b[A\n"," 42% 160552/386160 [27:10<58:41:36,  1.07it/s]\u001b[A\n"," 42% 160553/386160 [27:11<58:44:33,  1.07it/s]\u001b[A\n"," 42% 160554/386160 [27:12<58:47:23,  1.07it/s]\u001b[A\n"," 42% 160555/386160 [27:13<58:47:25,  1.07it/s]\u001b[A\n"," 42% 160556/386160 [27:14<58:54:07,  1.06it/s]\u001b[A\n"," 42% 160557/386160 [27:15<58:54:53,  1.06it/s]\u001b[A\n"," 42% 160558/386160 [27:16<58:54:53,  1.06it/s]\u001b[A\n"," 42% 160559/386160 [27:17<59:00:55,  1.06it/s]\u001b[A\n"," 42% 160560/386160 [27:18<58:54:48,  1.06it/s]\u001b[A\n"," 42% 160561/386160 [27:19<58:59:37,  1.06it/s]\u001b[A\n"," 42% 160562/386160 [27:20<59:01:05,  1.06it/s]\u001b[A\n"," 42% 160563/386160 [27:21<58:57:22,  1.06it/s]\u001b[A\n"," 42% 160564/386160 [27:22<58:56:43,  1.06it/s]\u001b[A\n"," 42% 160565/386160 [27:23<58:58:00,  1.06it/s]\u001b[A\n"," 42% 160566/386160 [27:23<58:53:58,  1.06it/s]\u001b[A\n"," 42% 160567/386160 [27:24<59:01:01,  1.06it/s]\u001b[A\n"," 42% 160568/386160 [27:25<58:56:27,  1.06it/s]\u001b[A\n"," 42% 160569/386160 [27:26<58:57:24,  1.06it/s]\u001b[A\n"," 42% 160570/386160 [27:27<58:57:46,  1.06it/s]\u001b[A\n"," 42% 160571/386160 [27:28<58:59:46,  1.06it/s]\u001b[A\n"," 42% 160572/386160 [27:29<59:08:52,  1.06it/s]\u001b[A\n"," 42% 160573/386160 [27:30<59:21:11,  1.06it/s]\u001b[A\n"," 42% 160574/386160 [27:31<59:17:12,  1.06it/s]\u001b[A\n"," 42% 160575/386160 [27:32<59:16:01,  1.06it/s]\u001b[A\n"," 42% 160576/386160 [27:33<59:07:57,  1.06it/s]\u001b[A\n"," 42% 160577/386160 [27:34<59:03:59,  1.06it/s]\u001b[A\n"," 42% 160578/386160 [27:35<59:02:09,  1.06it/s]\u001b[A\n"," 42% 160579/386160 [27:36<58:57:23,  1.06it/s]\u001b[A\n"," 42% 160580/386160 [27:37<59:09:26,  1.06it/s]\u001b[A\n"," 42% 160581/386160 [27:38<59:06:30,  1.06it/s]\u001b[A\n"," 42% 160582/386160 [27:39<59:07:06,  1.06it/s]\u001b[A\n"," 42% 160583/386160 [27:40<59:05:19,  1.06it/s]\u001b[A\n"," 42% 160584/386160 [27:40<59:13:45,  1.06it/s]\u001b[A\n"," 42% 160585/386160 [27:41<59:10:42,  1.06it/s]\u001b[A\n"," 42% 160586/386160 [27:42<59:05:01,  1.06it/s]\u001b[A\n"," 42% 160587/386160 [27:43<59:09:06,  1.06it/s]\u001b[A\n"," 42% 160588/386160 [27:44<59:10:01,  1.06it/s]\u001b[A\n"," 42% 160589/386160 [27:45<59:07:26,  1.06it/s]\u001b[A\n"," 42% 160590/386160 [27:46<59:07:46,  1.06it/s]\u001b[A\n"," 42% 160591/386160 [27:47<59:03:58,  1.06it/s]\u001b[A\n"," 42% 160592/386160 [27:48<59:03:22,  1.06it/s]\u001b[A\n"," 42% 160593/386160 [27:49<59:08:29,  1.06it/s]\u001b[A\n"," 42% 160594/386160 [27:50<59:08:03,  1.06it/s]\u001b[A\n"," 42% 160595/386160 [27:51<59:19:40,  1.06it/s]\u001b[A\n"," 42% 160596/386160 [27:52<59:16:47,  1.06it/s]\u001b[A\n"," 42% 160597/386160 [27:53<59:38:14,  1.05it/s]\u001b[A\n"," 42% 160598/386160 [27:54<60:12:50,  1.04it/s]\u001b[A\n"," 42% 160599/386160 [27:55<60:50:11,  1.03it/s]\u001b[A\n"," 42% 160600/386160 [27:56<61:09:02,  1.02it/s]\u001b[A\n"," 42% 160601/386160 [27:57<61:43:31,  1.02it/s]\u001b[A\n"," 42% 160602/386160 [27:58<61:34:50,  1.02it/s]\u001b[A\n"," 42% 160603/386160 [27:59<60:53:46,  1.03it/s]\u001b[A\n"," 42% 160604/386160 [28:00<60:22:02,  1.04it/s]\u001b[A\n"," 42% 160605/386160 [28:01<59:53:37,  1.05it/s]\u001b[A\n"," 42% 160606/386160 [28:01<59:31:55,  1.05it/s]\u001b[A\n"," 42% 160607/386160 [28:02<59:25:55,  1.05it/s]\u001b[A\n"," 42% 160608/386160 [28:03<59:17:44,  1.06it/s]\u001b[A\n"," 42% 160609/386160 [28:04<59:17:54,  1.06it/s]\u001b[A\n"," 42% 160610/386160 [28:05<59:15:37,  1.06it/s]\u001b[A\n"," 42% 160611/386160 [28:06<59:08:57,  1.06it/s]\u001b[A\n"," 42% 160612/386160 [28:07<59:08:10,  1.06it/s]\u001b[A\n"," 42% 160613/386160 [28:08<59:04:46,  1.06it/s]\u001b[A\n"," 42% 160614/386160 [28:09<58:58:45,  1.06it/s]\u001b[A\n"," 42% 160615/386160 [28:10<59:00:19,  1.06it/s]\u001b[A\n"," 42% 160616/386160 [28:11<58:55:27,  1.06it/s]\u001b[A\n"," 42% 160617/386160 [28:12<59:00:33,  1.06it/s]\u001b[A\n"," 42% 160618/386160 [28:13<58:53:25,  1.06it/s]\u001b[A\n"," 42% 160619/386160 [28:14<58:55:24,  1.06it/s]\u001b[A\n"," 42% 160620/386160 [28:15<59:03:58,  1.06it/s]\u001b[A\n"," 42% 160621/386160 [28:16<59:02:23,  1.06it/s]\u001b[A\n"," 42% 160622/386160 [28:17<58:58:57,  1.06it/s]\u001b[A\n"," 42% 160623/386160 [28:17<58:52:43,  1.06it/s]\u001b[A\n"," 42% 160624/386160 [28:18<58:57:19,  1.06it/s]\u001b[A\n"," 42% 160625/386160 [28:19<58:55:14,  1.06it/s]\u001b[A\n"," 42% 160626/386160 [28:20<58:51:25,  1.06it/s]\u001b[A\n"," 42% 160627/386160 [28:21<58:49:02,  1.07it/s]\u001b[A\n"," 42% 160628/386160 [28:22<59:00:41,  1.06it/s]\u001b[A\n"," 42% 160629/386160 [28:23<58:56:58,  1.06it/s]\u001b[A\n"," 42% 160630/386160 [28:24<59:00:36,  1.06it/s]\u001b[A\n"," 42% 160631/386160 [28:25<58:56:00,  1.06it/s]\u001b[A\n"," 42% 160632/386160 [28:26<58:59:33,  1.06it/s]\u001b[A\n"," 42% 160633/386160 [28:27<59:00:37,  1.06it/s]\u001b[A\n"," 42% 160634/386160 [28:28<58:58:30,  1.06it/s]\u001b[A\n"," 42% 160635/386160 [28:29<58:55:28,  1.06it/s]\u001b[A\n"," 42% 160636/386160 [28:30<58:50:18,  1.06it/s]\u001b[A\n"," 42% 160637/386160 [28:31<58:58:13,  1.06it/s]\u001b[A\n"," 42% 160638/386160 [28:32<58:55:18,  1.06it/s]\u001b[A\n"," 42% 160639/386160 [28:33<58:55:34,  1.06it/s]\u001b[A\n"," 42% 160640/386160 [28:33<58:57:15,  1.06it/s]\u001b[A\n"," 42% 160641/386160 [28:34<58:53:46,  1.06it/s]\u001b[A\n"," 42% 160642/386160 [28:35<58:55:36,  1.06it/s]\u001b[A\n"," 42% 160643/386160 [28:36<58:49:52,  1.06it/s]\u001b[A\n"," 42% 160644/386160 [28:37<58:52:32,  1.06it/s]\u001b[A\n"," 42% 160645/386160 [28:38<58:59:58,  1.06it/s]\u001b[A\n"," 42% 160646/386160 [28:39<59:02:05,  1.06it/s]\u001b[A\n"," 42% 160647/386160 [28:40<58:55:31,  1.06it/s]\u001b[A\n"," 42% 160648/386160 [28:41<58:49:44,  1.06it/s]\u001b[A\n"," 42% 160649/386160 [28:42<58:52:29,  1.06it/s]\u001b[A\n"," 42% 160650/386160 [28:43<58:49:45,  1.06it/s]\u001b[A\n"," 42% 160651/386160 [28:44<58:47:55,  1.07it/s]\u001b[A\n"," 42% 160652/386160 [28:45<58:48:21,  1.07it/s]\u001b[A\n"," 42% 160653/386160 [28:46<58:51:20,  1.06it/s]\u001b[A\n"," 42% 160654/386160 [28:47<58:50:58,  1.06it/s]\u001b[A\n"," 42% 160655/386160 [28:48<58:52:48,  1.06it/s]\u001b[A\n"," 42% 160656/386160 [28:49<58:52:09,  1.06it/s]\u001b[A\n"," 42% 160657/386160 [28:49<59:00:42,  1.06it/s]\u001b[A\n"," 42% 160658/386160 [28:50<58:55:17,  1.06it/s]\u001b[A\n"," 42% 160659/386160 [28:51<58:58:41,  1.06it/s]\u001b[A\n"," 42% 160660/386160 [28:52<58:54:52,  1.06it/s]\u001b[A\n"," 42% 160661/386160 [28:53<58:52:05,  1.06it/s]\u001b[A\n"," 42% 160662/386160 [28:54<58:58:55,  1.06it/s]\u001b[A\n"," 42% 160663/386160 [28:55<58:59:45,  1.06it/s]\u001b[A\n"," 42% 160664/386160 [28:56<58:58:14,  1.06it/s]\u001b[A\n"," 42% 160665/386160 [28:57<58:50:36,  1.06it/s]\u001b[A\n"," 42% 160666/386160 [28:58<58:51:58,  1.06it/s]\u001b[A"]}],"source":["! cd $PATH_PROJECT && python main.py --train --multi --model='gpt2' --limit='102400' --epochs='6' --batch='160' --fold='1'"]},{"cell_type":"markdown","metadata":{"id":"RbEbL0qHKTLe"},"source":["# Test Binary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mx-sB9ZHlUfn","outputId":"e7882b7d-c763-4db4-ebd0-0bd616b8731f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(batch='16', cache=False, check=False, complete=False, epochs=None, label=None, limit='1024', metrics=False, model='gpt2', multi=False, path=None, process=False, test=True, train=False)\n","pid: 17025\n","Args: limit 1024\n","Args: epochs 2\n","Args: batch 16\n","Args: labels ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n","Args: path /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1\n","Args: model_name gpt2\n","Args: multi False\n","Model: name gpt2\n","Model: label '0'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(0)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/0.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [01:59<00:00, 36.15it/s]\n","[[144  10]\n"," [  2 926]]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 3.78MB/s]\n","Downloading builder script: 100% 6.77k/6.77k [00:00<00:00, 3.44MB/s]\n","[[144  10]\n"," [  2 926]]\n","Model: name gpt2\n","Model: label '1'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(0)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/1.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:01<00:00, 35.40it/s]\n","[[243   3]\n"," [  0 836]]\n","[[243   3]\n"," [  0 836]]\n","Model: name gpt2\n","Model: label '2'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(0)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/2.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.17it/s]\n","[[294   0]\n"," [  0 788]]\n","[[294   0]\n"," [  0 788]]\n","Model: name gpt2\n","Model: label '3'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(0)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/3.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.26it/s]\n","[[  46    1]\n"," [   0 1035]]\n","[[  46    1]\n"," [   0 1035]]\n","Model: name gpt2\n","Model: label '4'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(0)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/4.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.28it/s]\n","[[   2    2]\n"," [   0 1078]]\n","[[   2    2]\n"," [   0 1078]]\n","Model: name gpt2\n","Model: label '5'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(0)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(1)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/5.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.14it/s]\n","[[  71    4]\n"," [   0 1007]]\n","[[  71    4]\n"," [   0 1007]]\n","Model: name gpt2\n","Model: label '6'\n","Model: num_labels 2\n","Model: using saved tokenizer...\n","Dataset: label 0 - test - in model as torch.tensor(1)\n","Dataset: label 0 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/0.limit-1024.chunk-32.test.csv ...\n","Dataset: label 0 - test - 4922 chunks - 0.04 Gb\n","Dataset: label 1 - test - in model as torch.tensor(1)\n","Dataset: label 1 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/1.limit-1024.chunk-32.test.csv ...\n","Dataset: label 1 - test - 7872 chunks - 0.06 Gb\n","Dataset: label 2 - test - in model as torch.tensor(1)\n","Dataset: label 2 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/2.limit-1024.chunk-32.test.csv ...\n","Dataset: label 2 - test - 9408 chunks - 0.08 Gb\n","Dataset: label 3 - test - in model as torch.tensor(1)\n","Dataset: label 3 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/3.limit-1024.chunk-32.test.csv ...\n","Dataset: label 3 - test - 1384 chunks - 0.01 Gb\n","Dataset: label 4 - test - in model as torch.tensor(1)\n","Dataset: label 4 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/4.limit-1024.chunk-32.test.csv ...\n","Dataset: label 4 - test - 128 chunks - 0.0 Gb\n","Dataset: label 5 - test - in model as torch.tensor(1)\n","Dataset: label 5 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5.limit-1024.chunk-32.test.csv ...\n","Dataset: label 5 - test - 2400 chunks - 0.02 Gb\n","Dataset: label 6 - test - in model as torch.tensor(0)\n","Dataset: label 6 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/6.limit-1024.chunk-32.test.csv ...\n","Dataset: label 6 - test - 1217 chunks - 0.01 Gb\n","Dataset: label 7 - test - in model as torch.tensor(1)\n","Dataset: label 7 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/7.limit-1024.chunk-32.test.csv ...\n","Dataset: label 7 - test - 3904 chunks - 0.03 Gb\n","Dataset: label 8 - test - in model as torch.tensor(1)\n","Dataset: label 8 - test - loading from /content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/8.limit-1024.chunk-32.test.csv ...\n","Dataset: label 8 - test - 3232 chunks - 0.03 Gb\n","Model: using trained at /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained ...\n","loading configuration file /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2ForSequenceClassification\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 50256,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n","\n","All the weights of GPT2ForSequenceClassification were initialized from the model checkpoint at /content/drive/Shareddrives/GPTJ/data/gpt2/6.limit-1024.chunk-32.epochs-2.batch-16/model-trained.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2ForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 34467\n","  Batch size = 8\n","100% 4309/4309 [02:02<00:00, 35.22it/s]\n","[[  38    1]\n"," [   0 1043]]\n","[[  38    1]\n"," [   0 1043]]\n"]}],"source":["! cd $PATH_PROJECT && python main.py --test --model='gpt2' --limit='1024' --batch='16'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDsk5vqClUmG"},"outputs":[],"source":["! cd $PATH_PROJECT && python main.py --metrics --model='gpt2' --limit='512' --batch='16'"]},{"cell_type":"markdown","metadata":{"id":"wAk9iqMClea1"},"source":["# Test Multi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1672062948067,"user":{"displayName":"Matheus Vanzan","userId":"00040097546844763627"},"user_tz":180},"id":"LUFIB0p9t0bG","outputId":"de926b89-3a15-43d2-9364-1e7cc1fd9ee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file 'main.py': [Errno 2] No such file or directory\n"]}],"source":["! cd $PATH_PROJECT && python main.py --test --multi --model='gpt2' --limit='102400' --epochs='6' --batch='160' --fold='1'"]},{"cell_type":"markdown","metadata":{"id":"n483Ij76Ra17"},"source":["# Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KInTwB233ev"},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir /content/drive/Shareddrives/GPTJ/data/gpt2/7.limit-256.chunk-32.epochs-5.batch-16/logs"]},{"cell_type":"markdown","metadata":{"id":"aHWiFkWTcjS0"},"source":["# Temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfgonH76CGVG"},"outputs":[],"source":["from statistics import mean\n","\n","l1 = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n","print(mean(l1), round(mean(l1)))\n","\n","l2 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n","print(mean(l2), round(mean(l2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxm69BpeWsIS"},"outputs":[],"source":["from collections import Counter\n","\n","L = [1,   1, 3, 5, 6, 6, 6, 7]\n","W = [2.5, 2, 1, 1, 1, 1, 1, 1]\n","\n","def WeightedCounter(L, W):\n","    c = {}\n","    for l, w in zip(L, W):\n","        if not l in c:\n","            c.update({l:0})\n","        c[l] += w\n","    return Counter(c)\n","\n","c1 = Counter(L).most_common()[0][0]\n","c2 = WeightedCounter(L, W).most_common()[0][0]\n","\n","print(c1)\n","print(c2)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["A1bIc0ZAumSJ","ZZdJjTltuR4z","KLYL5KtG59QR","RbEbL0qHKTLe","n483Ij76Ra17","aHWiFkWTcjS0"],"provenance":[{"file_id":"1z5YmbSqayjX1AVwNGdk4fiusOkBxa_YK","timestamp":1663640920362}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}