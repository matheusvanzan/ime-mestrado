{"cells":[{"cell_type":"markdown","metadata":{"id":"A1bIc0ZAumSJ"},"source":["# Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3399,"status":"ok","timestamp":1665864671259,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"},"user_tz":180},"id":"eckl1rAzruSX","outputId":"96ea13e4-0126-4a4b-8f26-d2ce3dc2a31a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["####################################\n","#\n","#  ADD THIS TO EVERY COLAB FILE!\n","#\n","####################################\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import drive.Shareddrives.GPTJ.project.settings as settings\n","\n","PATH_PROJECT = settings.PATH_PROJECT\n","PATH_DATA = settings.PATH_DATA"]},{"cell_type":"code","source":["! cd $PATH_PROJECT && pip install -q -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5zLhAxca2u4","outputId":"ad849d78-8ac0-4fae-90bd-1e70fe21031e","executionInfo":{"status":"ok","timestamp":1665864708965,"user_tz":180,"elapsed":33833,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"M5QqmMI7iYnu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665864556181,"user_tz":180,"elapsed":435,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}},"outputId":"528fe6ca-c249-43b5-f049-264dddc62a63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Oct 15 20:09:13 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P0    30W /  70W |   2332MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi\n","\n","# Standard -> Tesla T4\n","# Premium -> Tesla P100-PCIE-16GB"]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, random_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel, GPTNeoForCausalLM\n","\n","torch.manual_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124,"referenced_widgets":["975d13ab2b8b4bbf91ffc97ad7f34408","25ade29dd9804d0e9505f8075a18d6ff","2ce459454a224dfdb47c6f91c6cf2aa7","774ed9d5cd07419092ea915ccef5d2a2","e2c3afa10ec3494da8d53e00f28b8d9b","5ea9416f972547d3be45e9315ea5d208","6b817eb885404919a3870595f9dab516","ab7c2b1723104ce0951e60f1825a039d","feb345ce235e4b68bf974a16b006b3b7","031e8d57ee444da99af13775a304d742","bcdfb9d36bd943bc87e83289fe3a37aa"]},"id":"5cR4gcWosrr9","executionInfo":{"status":"ok","timestamp":1665864726197,"user_tz":180,"elapsed":6550,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}},"outputId":"a8ca767e-9c30-4896-9b43-3f1240c1bd49"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975d13ab2b8b4bbf91ffc97ad7f34408"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f257c815370>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"Ijh89fwmrkVK"}},{"cell_type":"code","source":["\n","class SimpleDataset(Dataset):\n","\n","    def __init__(self, txt_list, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","\n","        for txt in txt_list:\n","            # Encode the descriptions using the GPT-Neo tokenizer\n","            encodings_dict = tokenizer('<|startoftext|>' \n","                                        + txt +    \n","                                        '<|endoftext|>',\n","                                        truncation=True,\n","                                        max_length=max_length, \n","                                        padding='max_length')\n","            input_ids = torch.tensor(encodings_dict['input_ids'])    \n","            self.input_ids.append(input_ids)\n","            mask = torch.tensor(encodings_dict['attention_mask'])\n","            self.attn_masks.append(mask)\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]\n"],"metadata":{"id":"DXBUeyjSrmCP","executionInfo":{"status":"ok","timestamp":1665864734808,"user_tz":180,"elapsed":494,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVjnEhgiB83l"},"source":["# Treino"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuoDfJOxLeBP","outputId":"ae47b73c-2ab4-479e-876b-df80291103de","executionInfo":{"status":"ok","timestamp":1665864744664,"user_tz":180,"elapsed":6931,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(50259, 768)"]},"metadata":{},"execution_count":5}],"source":["model_name = 'gpt2'\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name, \n","    bos_token='<|startoftext|>',\n","    eos_token='<|endoftext|>', \n","    pad_token='<|pad|>'\n",")\n","model = GPT2LMHeadModel.from_pretrained(model_name).cuda()\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","source":["path = '/content/drive/Shareddrives/GPTJ/data/kaggle/proc-1/5/'\n","\n","descriptions = []\n","listdir = list(os.listdir(path))[:20]\n","for filename in listdir:\n","    filepath = os.path.join(path, filename)\n","    with open(filepath, 'r') as f:\n","        descriptions.append(f.read()[:1000])\n","\n","print('len desc', len(descriptions))\n","max_length = max([len(tokenizer.encode(description)) for description in descriptions])\n","\n","dataset = SimpleDataset(descriptions, tokenizer, max_length)\n","\n","print(len(dataset))\n","\n","train_size = int(0.9 * len(dataset))\n","train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iL1OqfiTuVLY","outputId":"b3e233d2-3d52-4a13-d4ee-904f92921fda","executionInfo":{"status":"ok","timestamp":1665864757685,"user_tz":180,"elapsed":493,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["len desc 20\n","20\n"]}]},{"cell_type":"code","source":["\n","\n","training_args = TrainingArguments(\n","    output_dir='/content/',\n","    num_train_epochs=1,\n","    # logging_steps=5000,\n","    # save_steps=5000,                                   \n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=2,\n","    warmup_steps=0,\n","    weight_decay=0.01,  \n","    # logging_dir=os.path.join(PATH_DATA, model_name, 'logs')\n",")\n","\n","trainer = Trainer(\n","    model=model, \n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset, \n","    # This custom collate function is necessary \n","    # to built batches of data\n","    data_collator=lambda data: {\n","        'input_ids': torch.stack([f[0] for f in data]),       \n","        'attention_mask': torch.stack([f[1] for f in data]),\n","        'labels': torch.stack([f[0] for f in data])\n","    }\n",")\n","# Start training process!\n","trainer.train()"],"metadata":{"id":"wlSzjzkbtXmD","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1665864768049,"user_tz":180,"elapsed":6480,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}},"outputId":"161f9f9f-4562-4b3e-ac26-3dc9c7d64c81"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 18\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:02, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=9, training_loss=20.618910047743057, metrics={'train_runtime': 6.0133, 'train_samples_per_second': 2.993, 'train_steps_per_second': 1.497, 'total_flos': 3885698304000.0, 'train_loss': 20.618910047743057, 'epoch': 1.0})"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# Complete"],"metadata":{"id":"xp0tlCKNR2e9"}},{"cell_type":"code","source":["prompt = 'mov ebx 1000h'\n","generated = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n","\n","sample_outputs = model.generate(generated, \n","    # Use sampling instead of greedy decoding \n","    do_sample=True, \n","    top_k=50, \n","    max_length=50,\n","    top_p=0.95,\n","    temperature=0.001,              \n","    num_return_sequences=5\n",")\n","\n","# Print generated descriptions\n","for i, sample_output in enumerate(sample_outputs): \n","    print('{}: {}'.format(i, tokenizer.decode(sample_output, skip_special_tokens=True)).replace('\\n', ' '))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_zB6hBNR0An","executionInfo":{"status":"ok","timestamp":1665864890444,"user_tz":180,"elapsed":2127,"user":{"displayName":"Matheus Vanzan","userId":"16733324993090982240"}},"outputId":"4d2fbe80-6738-48ee-9180-3f6b082f14be"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["0: mov ebx 1000h h h  \"  \"   \" \"\" \" \" \" \" \" \"  \" \n","1: mov ebx 1000h   1h1h1h1h1h1h1h1h1h1h1h1h1h1h1h1h1h1h1h\n","2: mov ebx 1000hh h  The number ofhh h h h h h h  The number of numberh h \n","3: mov ebx 1000hh h  h h   1h h h h h h h h h 1h\n","4: mov ebx 1000h   The The The  The The The The The  The The The The The The The\n"]}]}],"metadata":{"colab":{"collapsed_sections":["A1bIc0ZAumSJ","JuIxLRfousPd","ZZdJjTltuR4z"],"provenance":[{"file_id":"1z5YmbSqayjX1AVwNGdk4fiusOkBxa_YK","timestamp":1663640920362}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"975d13ab2b8b4bbf91ffc97ad7f34408":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ade29dd9804d0e9505f8075a18d6ff","IPY_MODEL_2ce459454a224dfdb47c6f91c6cf2aa7","IPY_MODEL_774ed9d5cd07419092ea915ccef5d2a2"],"layout":"IPY_MODEL_e2c3afa10ec3494da8d53e00f28b8d9b"}},"25ade29dd9804d0e9505f8075a18d6ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ea9416f972547d3be45e9315ea5d208","placeholder":"​","style":"IPY_MODEL_6b817eb885404919a3870595f9dab516","value":""}},"2ce459454a224dfdb47c6f91c6cf2aa7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab7c2b1723104ce0951e60f1825a039d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_feb345ce235e4b68bf974a16b006b3b7","value":0}},"774ed9d5cd07419092ea915ccef5d2a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_031e8d57ee444da99af13775a304d742","placeholder":"​","style":"IPY_MODEL_bcdfb9d36bd943bc87e83289fe3a37aa","value":" 0/0 [00:00&lt;?, ?it/s]"}},"e2c3afa10ec3494da8d53e00f28b8d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ea9416f972547d3be45e9315ea5d208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b817eb885404919a3870595f9dab516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab7c2b1723104ce0951e60f1825a039d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"feb345ce235e4b68bf974a16b006b3b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"031e8d57ee444da99af13775a304d742":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcdfb9d36bd943bc87e83289fe3a37aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}