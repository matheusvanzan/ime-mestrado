{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQQv1ybB0a8D"
   },
   "source": [
    "Adaptado de https://towardsdatascience.com/diy-ai-an-old-school-matrix-nn-401a00021a55\n",
    "\n",
    "Mas usando gradiente descendente para o treino (https://levelup.gitconnected.com/training-a-single-perceptron-405026d61f4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5509,
     "status": "ok",
     "timestamp": 1654143273307,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "cC3Y4vOvdsoZ",
    "outputId": "d37fe55f-2163-4506-ae38-9b92b9cfb783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.8/site-packages (3.1.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install terminaltables\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from terminaltables import AsciiTable\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import array\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1279,
     "status": "ok",
     "timestamp": 1654143274575,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "wdsLzlOPlO7I",
    "outputId": "da155346-0671-4e26-b5dc-63ef29205392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (1593, 256)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] (1593, 10)\n"
     ]
    }
   ],
   "source": [
    "# we need to tell numpy the dimensions of our arrays\n",
    "samples = numpy.empty([0, 256])\n",
    "results = numpy.empty([0, 10])\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/matheusvanzan/ia-datasets/master/semeion.txt'\n",
    "\n",
    "for line in urllib.request.urlopen(url):\n",
    "    # split line to array using space as separator\n",
    "    numbers = line.decode('utf-8').split(' ')\n",
    "    # as line read from the file is always is string, we need to convert first 256 parts to decimals,\n",
    "    # and following 10 to integers\n",
    "    sample = numpy.array([ float(x) for x in numbers[0:256] ])\n",
    "    result = numpy.array([ int(x) for x in numbers[256:266] ])\n",
    "\n",
    "    # print(samples.ndim, numpy.array([sample]).ndim) # 2 2\n",
    "    # print(samples.shape, numpy.array([sample]).shape) # (0, 256) (1, 256)\n",
    "    # print(type(samples), type(sample))\n",
    "\n",
    "    # after that, append freshly read sample and result to arrays\n",
    "    samples = numpy.concatenate( (samples, numpy.array([sample])), axis=0)\n",
    "    results = numpy.concatenate((results, numpy.array([result])), axis=0)\n",
    "\n",
    "\n",
    "print(samples, samples.shape)\n",
    "print(results, results.shape)\n",
    "\n",
    "X = samples\n",
    "y = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1654143274576,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "M_IalTqb2TkO",
    "outputId": "f1ebe4de-44b6-4fef-9f23-893c9d75d2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1274, 256) (319, 256)\n",
      "(1274, 10) (319, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1800,
     "status": "ok",
     "timestamp": 1654143898512,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "Ne-jEdrGGp9q",
    "outputId": "2e7bc0be-228b-48b9-d849-b448d7cba061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.7680\n",
      "Test Accuracy: 76.802510\n",
      "0:00:19\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "# define network\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(256,)),\n",
    "    layers.Dense(units=256, activation='sigmoid'),\n",
    "    layers.Dense(units=10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "model.fit(X_train, y_train, epochs=200, verbose=None)\n",
    "\n",
    "# evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %f' % (acc*100))\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "print(str(stop-start).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1654143276305,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "-7wCsCiPPb-y"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# computes result from [1x256] sample, requires first_layer and second_layer to be defined globally\n",
    "# returns single detected number\n",
    "def compute_result(model, input_sample):\n",
    "    # process input vector through both layers on NN\n",
    "    X = numpy.array([input_sample])\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    df = pandas.DataFrame(prediction)\n",
    "    return numpy.argmax(df.values)\n",
    "\n",
    "# converts [1x256] sample line into pretty 16x16 character block where 1 is * and other symbols are omitted\n",
    "def print_sample(input_sample):\n",
    "    # convert [1x256] matrix to [16x16]\n",
    "    input_sample = input_sample.reshape(16, 16).tolist()\n",
    "\n",
    "    text = []\n",
    "\n",
    "    # process sample row by row\n",
    "    for sample_row in range(16):\n",
    "        text_row = input_sample[sample_row]\n",
    "        # replace 1 with * and 0 with empty space\n",
    "        text_row = map(lambda cell: '*' if cell == 1 else ' ', text_row)\n",
    "        # join 16 characters into line\n",
    "        text_row = ''.join(text_row)\n",
    "        # line to rows array\n",
    "        text.append(text_row)\n",
    "\n",
    "    # finally, join rows with newlines\n",
    "    return '\\n'.join(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1654143276967,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "3r5kinA9Ptfm",
    "outputId": "898ee598-ce42-4601-8b6f-d782676b59a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual testing of trained NN\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "| Sample           | Digit | Sample           | Digit | Sample           | Digit | Sample           | Digit |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|            ***** |       |        ********  |       |         *******  |       |           ****** |       |\n",
      "|           ****** |       |     ******   **  |       |        ***   *** |       | **************** |       |\n",
      "|           *** ** |   1   |   ***        **  |   9   |        **    **  |   1   | *********   ***  |   7   |\n",
      "|           *** ** |       | ***          **  |       |       ***   ***  |       |            ****  |       |\n",
      "|           *** ** |       | *****       **   |       |       ***   **   |       |            **    |       |\n",
      "|           *** ** |       |            **    |       |        *******   |       |           ***    |       |\n",
      "|           *****  |       |          ***     |       |         ****     |       |          ***     |       |\n",
      "|           *****  |       |          **      |       |       *****      |       |         ***      |       |\n",
      "|           ****   |       |        ********  |       |    ***********   |       |       *******    |       |\n",
      "|           ***    |       |     ****     *** |       |  ******   ***    |       |       ********   |       |\n",
      "|          ****    |       |    ***        ** |       | ***       ****   |       |      ***         |       |\n",
      "|         *****    |       |               ** |       |  ***       ***   |       |      **          |       |\n",
      "|       **** ***   |       |               ** |       |   ***      ***   |       |     ***          |       |\n",
      "|     ****   ***   |       |              *** |       |     **      **   |       |     **           |       |\n",
      "|  ******     *    |       |     **********   |       |      *****  ***  |       |    ***           |       |\n",
      "| ****             |       |          *       |       |         ******   |       |     *            |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|         *******  |       |    ********      |       |    **            |       |     ************ |       |\n",
      "|     ******   *** |       |  ******  ***     |       |   ***            |       |    *****         |       |\n",
      "|   *******    *** |   0   | ****      **     |   7   |  ***             |   6   |     **           |   5   |\n",
      "|  *** **      *** |       | **        ***    |       | ****             |       |    ***           |       |\n",
      "| **** **      **  |       | **        ***    |       | ***              |       |    **            |       |\n",
      "| ***  *       **  |       |           ***    |       | **               |       |    **********    |       |\n",
      "| ***  *      ***  |       |           ***    |       | **    *****      |       |             ***  |       |\n",
      "| **          **   |       |           **     |       | ** **********    |       |              *** |       |\n",
      "| **         ***   |       |       **  **     |       | ******** ******  |       |               ** |       |\n",
      "| **        ***    |       |       ********** |       | ***         **** |       |               ** |       |\n",
      "| **        ***    |       |        ********* |       | ***          *** |       |               ** |       |\n",
      "| **       ***     |       |          **      |       | ****         *** |       |              *** |       |\n",
      "| ***    ****      |       |          **      |       | *******      *** |       | **          ***  |       |\n",
      "| **** *****       |       |          **      |       |    *****     *** |       | ***       ****   |       |\n",
      "|  *******         |       |          **      |       |      *********** |       | ************     |       |\n",
      "|    ***           |       |          *       |       |           **     |       |  *********       |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|             **   |       |            ***   |       |        ********  |       |   **********     |       |\n",
      "| ***       ***    |       |   ***     ****   |       |     ************ |       |           ***    |       |\n",
      "|   **********     |   7   |    ****  ****    |   1   |   ********  **** |   8   |            ***   |   7   |\n",
      "|          **      |       |     *********    |       |  *** ****        |       |            ***   |       |\n",
      "|         **       |       |           ***    |       |  *******         |       |            ***   |       |\n",
      "|         **       |       |          ***     |       |    *****         |       |           ***    |       |\n",
      "|        **        |       |          *****   |       |    *****         |       |          ***     |       |\n",
      "|        *         |       |          ******* |       |   *****          |       |          **      |       |\n",
      "|       **         |       | ****     *** *** |       |  *********       |       |  *************** |       |\n",
      "|   ************** |       | **************** |       | ***********      |       | ***    *** ****  |       |\n",
      "|      **          |       |        *****     |       | ************     |       | *     ***        |       |\n",
      "|     **           |       |          ***     |       |          ****    |       |      ***         |       |\n",
      "|     **           |       |          ***     |       |          ****    |       |      ***         |       |\n",
      "|    **            |       |          ***     |       |         ****     |       |     ***          |       |\n",
      "|    **            |       |          ***     |       |  **  ******      |       |     ***          |       |\n",
      "|    *             |       |          ***     |       | *********        |       |      **          |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "print('Actual testing of trained NN')\n",
    "\n",
    "table_data = [\n",
    "    ['Sample', 'Digit', 'Sample', 'Digit', 'Sample', 'Digit', 'Sample', 'Digit']\n",
    "]\n",
    "\n",
    "# we print three rows\n",
    "for row in range(3):\n",
    "    table_data.append([''] * 8)\n",
    "    # with 8 columns, 4 image -> result pairs\n",
    "    for col in range(4):\n",
    "        # pick one random sample between 0 and sample count\n",
    "        ri = random.randint(0, samples.shape[0] - 1)\n",
    "        sample = samples[ri]\n",
    "\n",
    "        table_data[row+1][col*2] = print_sample(sample)\n",
    "        table_data[row+1][col*2+1] = '\\n'.join([' ' * 5, ' ' * 5, '  %d' % compute_result(model, sample)])\n",
    "\n",
    "table = AsciiTable(table_data)\n",
    "table.inner_row_border = True\n",
    "\n",
    "print(table.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNumwZhSLAcfYQmyqI5uIy4",
   "name": "basic-nn-mnist-keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
