{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQQv1ybB0a8D"
   },
   "source": [
    "Adaptado de https://towardsdatascience.com/diy-ai-an-old-school-matrix-nn-401a00021a55\n",
    "\n",
    "Mas usando gradiente descendente para o treino (https://levelup.gitconnected.com/training-a-single-perceptron-405026d61f4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4892,
     "status": "ok",
     "timestamp": 1654120289651,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "cC3Y4vOvdsoZ",
    "outputId": "ddc49746-5a5c-47d7-9949-573a729aa652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: terminaltables\n",
      "Successfully installed terminaltables-3.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install terminaltables\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import random\n",
    "from terminaltables import AsciiTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1654120973281,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "wdsLzlOPlO7I",
    "outputId": "3e8b3cb3-3b8a-4bc0-c40e-ab1f3218bdc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (1593, 256)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] (1593, 10)\n"
     ]
    }
   ],
   "source": [
    "# we need to tell numpy the dimensions of our arrays\n",
    "samples = numpy.empty([0, 256])\n",
    "results = numpy.empty([0, 10])\n",
    "\n",
    "with open('sample_data/semeion.data') as file:\n",
    "    for line in file:\n",
    "        # split line to array using space as separator\n",
    "        numbers = line.split(' ')\n",
    "        # as line read from the file is always is string, we need to convert first 256 parts to decimals,\n",
    "        # and following 10 to integers\n",
    "        sample = numpy.array([ float(x) for x in numbers[0:256] ])\n",
    "        result = numpy.array([ int(x) for x in numbers[256:266] ])\n",
    "\n",
    "        # print(samples.ndim, numpy.array([sample]).ndim) # 2 2\n",
    "        # print(samples.shape, numpy.array([sample]).shape) # (0, 256) (1, 256)\n",
    "        # print(type(samples), type(sample))\n",
    "\n",
    "        # after that, append freshly read sample and result to arrays\n",
    "        samples = numpy.concatenate( (samples, numpy.array([sample])), axis=0)\n",
    "        results = numpy.concatenate((results, numpy.array([result])), axis=0)\n",
    "\n",
    "\n",
    "print(samples, samples.shape)\n",
    "print(results, results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1654120976734,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "G5JokZY3rtQW",
    "outputId": "c6b507f3-46fb-4baa-d0a1-375203e5b316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n",
      "(256, 10)\n"
     ]
    }
   ],
   "source": [
    "# logistic function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + numpy.exp(-x))\n",
    "\n",
    "# derivative of logistic function\n",
    "def dsigmoid(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "# numpy.random returns 0..1, by multiplying by 2 we get 0..2,\n",
    "# by subtracting 1 we get -1..1, and by division by 100 we get -0.01..0.01 \n",
    "first_layer = (2 * numpy.random.random((256, 256)) - 1) / 100  # (256, 256)\n",
    "second_layer = (2 * numpy.random.random((256, 10)) - 1) / 100  # (256, 10)\n",
    "\n",
    "print(first_layer.shape)\n",
    "print(second_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42395,
     "status": "ok",
     "timestamp": 1654121021771,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "fp21Xh0O4nWb",
    "outputId": "c1028de5-d780-4cf5-e482-d127fe0a8c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, error: 0.9999924047564264 (of desired < 0.1)\n"
     ]
    }
   ],
   "source": [
    "# rate defines how fast out network will change. Smaller values leads to slower but more precise training\n",
    "rate = 0.4\n",
    "# initial value of error must be high\n",
    "error = 1000.0\n",
    "# current epoch\n",
    "epoch = 1\n",
    "# limit of epochs\n",
    "epoch_limit = 100\n",
    "# we stop after error is that small\n",
    "desired_error = 0.1\n",
    "\n",
    "while epoch <= epoch_limit and error > desired_error:\n",
    "    # this array will hold all errors from the current epoch\n",
    "    errors = []\n",
    "    # loop through all samples\n",
    "    for sample_index in range(samples.shape[0]):\n",
    "        # this is a bit tricky - samples[sample_index] returns vector, but we need a matrix, so we wrap it in array\n",
    "        sample = numpy.array([samples[sample_index]])\n",
    "        result = numpy.array([results[sample_index]])\n",
    "\n",
    "        # Feed forward through both layers\n",
    "        first_output = sigmoid(numpy.dot(sample, first_layer)) # (1, 256)\n",
    "        second_output = sigmoid(numpy.dot(first_output, second_layer)) # (1, 10)\n",
    "\n",
    "        # print('--')\n",
    "        # print('first_output', first_output.shape)\n",
    "        # print('second_output', second_output.shape)\n",
    "\n",
    "        # Compute output error and add the error to current epoch errors\n",
    "        second_error = result - second_output # (1, 10)\n",
    "        errors.append(numpy.max(numpy.abs(second_error)))\n",
    "\n",
    "        # the delta represents how much each of the weights contribute to the error\n",
    "        second_delta = second_error * dsigmoid(second_output) # (1, 10)\n",
    "\n",
    "        # print('second_delta', second_delta.shape)\n",
    "        # print('second_layer', second_layer.shape)\n",
    "\n",
    "        # how much did each first layer value contribute to the second layer error (according to the weights)?\n",
    "        first_error = second_delta.dot(second_layer.T)\n",
    "\n",
    "        # the delta represents how much each of the weights contribute to the error\n",
    "        first_delta = first_error * dsigmoid(first_output)\n",
    "\n",
    "        second_layer += first_output.T.dot(second_delta) * rate # (256, 10)\n",
    "        first_layer += sample.T.dot(first_delta) * rate\n",
    "\n",
    "    # select max error found during the epoch\n",
    "    error = max(errors)\n",
    "    epoch += 1\n",
    "\n",
    "# print current epoch status\n",
    "print(f'Epoch: {epoch-1}, error: {error} (of desired < {desired_error})')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1654121061622,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "-7wCsCiPPb-y"
   },
   "outputs": [],
   "source": [
    "# computes result from [1x256] sample, requires first_layer and second_layer to be defined globally\n",
    "# returns single detected number\n",
    "def compute_result(input_sample):\n",
    "    # process input vector through both layers on NN\n",
    "    l1 = sigmoid(numpy.dot(input_sample, first_layer))\n",
    "    l2 = sigmoid(numpy.dot(l1, second_layer))\n",
    "\n",
    "    # loop through all numbers in sequence and return index of highest value\n",
    "    maximum = 0\n",
    "    selected_index = 0\n",
    "    for index in range(10):\n",
    "        if l2[index] > maximum:\n",
    "            maximum = l2[index]\n",
    "            selected_index = index\n",
    "\n",
    "    return selected_index\n",
    "\n",
    "# converts [1x256] sample line into pretty 16x16 character block where 1 is * and other symbols are omitted\n",
    "def print_sample(input_sample):\n",
    "    # convert [1x256] matrix to [16x16]\n",
    "    input_sample = input_sample.reshape(16, 16).tolist()\n",
    "\n",
    "    text = []\n",
    "\n",
    "    # process sample row by row\n",
    "    for sample_row in range(16):\n",
    "        text_row = input_sample[sample_row]\n",
    "        # replace 1 with * and 0 with empty space\n",
    "        text_row = map(lambda cell: '*' if cell == 1 else ' ', text_row)\n",
    "        # join 16 characters into line\n",
    "        text_row = ''.join(text_row)\n",
    "        # line to rows array\n",
    "        text.append(text_row)\n",
    "\n",
    "    # finally, join rows with newlines\n",
    "    return '\\n'.join(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1654121086283,
     "user": {
      "displayName": "Matheus Vanzan Pimentel de Oliveira",
      "userId": "05248490625695273722"
     },
     "user_tz": 180
    },
    "id": "3r5kinA9Ptfm",
    "outputId": "77d58497-fc1c-4d59-d548-dd94bc5335d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual testing of trained NN\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "| Sample           | Digit | Sample           | Digit | Sample           | Digit | Sample           | Digit |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|             **** |       |       ********** |       | ***         **   |       |      ****        |       |\n",
      "|            ****  |       |                  |       | **        ****   |       |      ****        |       |\n",
      "|           ****** |   1   |     ***          |   5   | *************    |   7   |     ******       |   4   |\n",
      "|           *****  |       |    ***           |       |     **  ***      |       |     ** ***       |       |\n",
      "|          *****   |       |  ****            |       |         **       |       |    *** ***       |       |\n",
      "|       *******    |       | ***              |       |        ***       |       |   ***   **       |       |\n",
      "|   **********     |       | ************     |       |        **        |       |  ****   **       |       |\n",
      "| ************     |       |          ****    |       |       ***        |       |  **     **       |       |\n",
      "|        ****      |       |            ***   |       | **************** |       | ***     ***      |       |\n",
      "|        ****      |       |             ***  |       |    *  **         |       | **      ***      |       |\n",
      "|       *****      |       |             ***  |       |      **          |       | **      ******** |       |\n",
      "|       ****       |       |            ***   |       |      **          |       | *************    |       |\n",
      "|       ****       |       |  ***      ****   |       |      **          |       |  **********      |       |\n",
      "|       ****       |       |  **      ***     |       |      **          |       |          **      |       |\n",
      "|       *****      |       |  **********      |       |      ****        |       |          **      |       |\n",
      "|         ***      |       |    *****         |       |      ****        |       |          **      |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|             **** |       |      *********   |       |    ***********   |       |   ************** |       |\n",
      "|          *****   |       |    *****    ***  |       | *******     ***  |       |   ***            |       |\n",
      "|         ***      |   6   |    ***       **  |   0   |             ***  |   3   |  ***             |   5   |\n",
      "|       ****       |       |  ****        *** |       |           ****   |       |  **              |       |\n",
      "|      ***         |       |  **           ** |       |          ***     |       | ***              |       |\n",
      "|     ***          |       | *** *         ** |       |      ******      |       | **               |       |\n",
      "|    ***           |       | ** **         ** |       |    ***           |       | **               |       |\n",
      "|   ***            |       | ** **         ** |       |    ***           |       | ***              |       |\n",
      "|  ***             |       | ** **        *** |       |    *********     |       |  ******          |       |\n",
      "| ***   ****       |       | *****        **  |       |         *****    |       |      **          |       |\n",
      "| ************     |       |  ****       ***  |       |            ****  |       |      **          |       |\n",
      "| ****      **     |       |   ***       **   |       |              *** |       |      **          |       |\n",
      "| ***       **     |       |    ***    ****   |       |             ***  |       |      **          |       |\n",
      "| ***      ***     |       |    ***   ****    |       |            ***   |       |     **           |       |\n",
      "|  **********      |       |     ********     |       |      ********    |       |    **            |       |\n",
      "|     ****         |       |      *****       |       | ********         |       |  ***             |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n",
      "|  *************** |       |       ********   |       |  ********        |       | *         ****** |       |\n",
      "| *********    *** |       |     ****    ***  |       | ***   ****       |       | ************ *** |       |\n",
      "| **          **** |   7   |   ****      **** |   0   | *      ****      |   2   |     *       **   |   7   |\n",
      "|  *          ***  |       |  ****         ** |       |        ***       |       |            **    |       |\n",
      "|           ****   |       |  ***          ** |       |       ****       |       |           **     |       |\n",
      "|          ****    |       | ****          ** |       |      ****        |       |          **      |       |\n",
      "|         ***      |       | ***           ** |       |     ****         |       |         **       |       |\n",
      "|        *****     |       | **            ** |       |     ***          |       |        ***       |       |\n",
      "|  ************    |       | **           **  |       |    ***           |       | *********        |       |\n",
      "|  **** ***        |       | **          ***  |       |    ***           |       |    ***********   |       |\n",
      "|      ***         |       | **         ***   |       |    ***           |       |      ***         |       |\n",
      "|      ***         |       | ***       ***    |       |     ***          |       |     ***          |       |\n",
      "|     ***          |       | ***     *****    |       |     ****         |       |     **           |       |\n",
      "|      ***         |       |  **** *****      |       |      ****        |       |    **            |       |\n",
      "|      *******     |       |  *********       |       |       ********** |       |    **            |       |\n",
      "|         **       |       |    ****          |       |         *******  |       |    *             |       |\n",
      "+------------------+-------+------------------+-------+------------------+-------+------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "print('Actual testing of trained NN')\n",
    "\n",
    "table_data = [\n",
    "    ['Sample', 'Digit', 'Sample', 'Digit', 'Sample', 'Digit', 'Sample', 'Digit']\n",
    "]\n",
    "\n",
    "# we print three rows\n",
    "for row in range(3):\n",
    "    table_data.append([''] * 8)\n",
    "    # with 8 columns, 4 image -> result pairs\n",
    "    for col in range(4):\n",
    "        # pick one random sample between 0 and sample count\n",
    "        ri = random.randint(0, samples.shape[0] - 1)\n",
    "        sample = samples[ri]\n",
    "\n",
    "        table_data[row+1][col*2] = print_sample(sample)\n",
    "        table_data[row+1][col*2+1] = '\\n'.join([' ' * 5, ' ' * 5, '  %d' % compute_result(sample)])\n",
    "\n",
    "table = AsciiTable(table_data)\n",
    "table.inner_row_border = True\n",
    "\n",
    "print(table.table)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPPRZWGFOBZ12OOrpa/E5H1",
   "name": "basic-nn-mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
